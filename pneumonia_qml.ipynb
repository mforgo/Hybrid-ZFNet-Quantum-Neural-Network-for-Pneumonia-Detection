{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3029006",
   "metadata": {
    "id": "e3029006"
   },
   "source": [
    "# Hybrid model for pneumonia detection\n",
    "## 1. Setup and configuration\n",
    "### 1.1. Installing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2364b28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47491,
     "status": "ok",
     "timestamp": 1760344336272,
     "user": {
      "displayName": "Michal ForgÃ³",
      "userId": "03385761472197084991"
     },
     "user_tz": -120
    },
    "id": "b2364b28",
    "outputId": "6fd1cfb2-d376-4484-b1de-cb14b666b760"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pennylane\n",
      "  Downloading pennylane-0.43.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Collecting pennylane-qiskit\n",
      "  Downloading pennylane_qiskit-0.43.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
      "Collecting pennylane-lightning-gpu\n",
      "  Downloading pennylane_lightning_gpu-0.43.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6.1)\n",
      "Collecting rustworkx>=0.14.0 (from pennylane)\n",
      "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
      "Collecting appdirs (from pennylane)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting autoray==0.8.0 (from pennylane)\n",
      "  Downloading autoray-0.8.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (6.2.4)\n",
      "Collecting pennylane-lightning>=0.43 (from pennylane)\n",
      "  Downloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
      "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
      "Collecting diastatic-malt (from pennylane)\n",
      "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
      "Collecting qiskit<2.2,>=2.0 (from pennylane-qiskit)\n",
      "  Downloading qiskit-2.1.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting qiskit-aer~=0.17.1 (from pennylane-qiskit)\n",
      "  Downloading qiskit_aer-0.17.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
      "Collecting qiskit-ibm-runtime~=0.41.1 (from pennylane-qiskit)\n",
      "  Downloading qiskit_ibm_runtime-0.41.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from pennylane-qiskit) (1.14.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.12.12)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning-gpu)\n",
      "  Downloading scipy_openblas32-0.3.30.359.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting custatevec-cu12 (from pennylane-lightning-gpu)\n",
      "  Downloading custatevec_cu12-1.11.0-py3-none-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit<2.2,>=2.0->pennylane-qiskit) (0.3.8)\n",
      "Collecting stevedore>=3.0.0 (from qiskit<2.2,>=2.0->pennylane-qiskit)\n",
      "  Downloading stevedore-5.6.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer~=0.17.1->pennylane-qiskit) (5.9.5)\n",
      "Collecting requests-ntlm>=1.1.0 (from qiskit-ibm-runtime~=0.41.1->pennylane-qiskit)\n",
      "  Downloading requests_ntlm-1.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.5.0)\n",
      "Collecting ibm-platform-services>=0.22.6 (from qiskit-ibm-runtime~=0.41.1->pennylane-qiskit)\n",
      "  Downloading ibm_platform_services-0.72.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pydantic>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.12.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->pennylane-qiskit) (1.3.0)\n",
      "Requirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
      "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.7.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Collecting ibm_cloud_sdk_core<4.0.0,>=3.24.2 (from ibm-platform-services>=0.22.6->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit)\n",
      "  Downloading ibm_cloud_sdk_core-3.24.2-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (0.4.2)\n",
      "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.12/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (43.0.3)\n",
      "Collecting pyspnego>=0.4.0 (from requests-ntlm>=1.1.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit)\n",
      "  Downloading pyspnego-0.12.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.0.0)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from ibm_cloud_sdk_core<4.0.0,>=3.24.2->ibm-platform-services>=0.22.6->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.10.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.23)\n",
      "Downloading pennylane-0.43.2-py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading autoray-0.8.0-py3-none-any.whl (934 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pennylane_qiskit-0.43.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pennylane_lightning_gpu-0.43.0-cp312-cp312-manylinux_2_28_x86_64.whl (911 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m911.3/911.3 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading qiskit-2.1.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading qiskit_aer-0.17.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m128.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading qiskit_ibm_runtime-0.41.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy_openblas32-0.3.30.359.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading custatevec_cu12-1.11.0-py3-none-manylinux2014_x86_64.whl (73.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.4/73.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ibm_platform_services-0.72.0-py3-none-any.whl (378 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m378.5/378.5 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_ntlm-1.3.0-py3-none-any.whl (6.6 kB)\n",
      "Downloading stevedore-5.6.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ibm_cloud_sdk_core-3.24.2-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyspnego-0.12.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: custatevec-cu12, appdirs, stevedore, scipy-openblas32, rustworkx, autoray, qiskit, ibm_cloud_sdk_core, diastatic-malt, qiskit-aer, pyspnego, ibm-platform-services, requests-ntlm, qiskit-ibm-runtime, pennylane-lightning, pennylane, pennylane-qiskit, pennylane-lightning-gpu\n",
      "Successfully installed appdirs-1.4.4 autoray-0.8.0 custatevec-cu12-1.11.0 diastatic-malt-2.15.2 ibm-platform-services-0.72.0 ibm_cloud_sdk_core-3.24.2 pennylane-0.43.2 pennylane-lightning-0.43.0 pennylane-lightning-gpu-0.43.0 pennylane-qiskit-0.43.0 pyspnego-0.12.0 qiskit-2.1.2 qiskit-aer-0.17.2 qiskit-ibm-runtime-0.41.1 requests-ntlm-1.3.0 rustworkx-0.17.1 scipy-openblas32-0.3.30.359.2 stevedore-5.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane scikit-learn numpy scipy matplotlib pandas pennylane-qiskit kagglehub scikit-image seaborn pillow opencv-python torch torchvision pennylane-lightning-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f966be",
   "metadata": {},
   "source": [
    "### 1.2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b322fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Global seed set to 6\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    # Experiment Metadata\n",
    "    project_name: str = \"Hybrid_ResNet50_QNN_Pneumonia\"\n",
    "    seed: int = 6\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Data Paths\n",
    "    data_root: str = \"/home/mforgo/.cache/kagglehub/datasets/paultimothymooney/chest-xray-pneumonia/versions/2/chest_xray/\"\n",
    "    output_dir: str = \"./results\"\n",
    "\n",
    "    # Classical Backbone\n",
    "    backbone_name: str = \"resnet50\"\n",
    "    feature_dim: int = 2048  # 2048 for ResNet50\n",
    "\n",
    "    # Quantum Components\n",
    "    n_qubits: int = 6\n",
    "    n_layers: int = 2\n",
    "    encoding_method: str = \"amplitude\"  # 'amplitude' or 'angle'\n",
    "\n",
    "    # Training Hyperparams\n",
    "    batch_size: int = 64\n",
    "    learning_rate: float = 0.002\n",
    "    epochs: int = 50\n",
    "    patience: int = 10\n",
    "\n",
    "    # Preprocessing\n",
    "    reduction_method: str = \"selectkbest\"  # 'pca', 'lda', or 'selectkbest'\n",
    "    target_dims: int = 32  # Dimensionality after reduction\n",
    "\n",
    "    # Quantum training mode\n",
    "    use_ensemble: bool = False      # False â†’ single model, True â†’ ensemble\n",
    "    ensemble_size: int = 3          # Number of models in ensemble\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"ğŸ”’ Global seed set to {seed}\")\n",
    "\n",
    "\n",
    "CFG = ExperimentConfig()\n",
    "seed_everything(CFG.seed)\n",
    "os.makedirs(CFG.output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7899a0",
   "metadata": {},
   "source": [
    "### 1.3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2d7fa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2701,
     "status": "ok",
     "timestamp": 1760344348669,
     "user": {
      "displayName": "Michal ForgÃ³",
      "userId": "03385761472197084991"
     },
     "user_tz": -120
    },
    "id": "5d2d7fa4",
    "outputId": "d40499d8-9e61-4069-92d1-f48e0163d886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'chest-xray-pneumonia' dataset.\n",
      "Path to dataset files: /kaggle/input/chest-xray-pneumonia/chest_xray/\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version of the dataset\n",
    "CFG.data_root = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\") + \"/chest_xray/\"\n",
    "print(\"Path to dataset files:\", CFG.data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485bfe7",
   "metadata": {
    "id": "2485bfe7"
   },
   "source": [
    "### 2. Data loading and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7949166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 196MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /kaggle/input/chest-xray-pneumonia/chest_xray/\n",
      "TRAIN - Found 5216 images\n",
      "TEST - Found 624 images\n",
      "VAL - Found 16 images\n",
      "\n",
      "ğŸš€ Starting augmented feature extraction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97acec41cac40b6956164c1d9077bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting train (Clean):   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-664970608.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6b3fd454ee4fe1ae74dfdc9c2b0394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting train (Augmented):   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-664970608.py:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55bdd3b64624ae38723eb60434c93aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting test (Clean):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd3208b4f4c4857b4e7baa252ba0366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting val (Clean):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Augmented extraction complete. Metadata saved to ./results/metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "# Deterministic transforms (no augmentation)\n",
    "def get_transforms(img_size: int = 224):\n",
    "    \"\"\"\n",
    "    Deterministic preprocessing for feature extraction.\n",
    "    \"\"\"\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dataloaders(config: ExperimentConfig):\n",
    "    \"\"\"\n",
    "    Create DataLoaders for train/val/test using ImageFolder.\n",
    "    \"\"\"\n",
    "    loaders = {}\n",
    "    splits = [\"train\", \"test\", \"val\"]\n",
    "\n",
    "    print(f\"Loading data from {config.data_root}\")\n",
    "\n",
    "    for split in splits:\n",
    "        path = os.path.join(config.data_root, split)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Warning: Split '{split}' not found at {path}\")\n",
    "            continue\n",
    "\n",
    "        dataset = datasets.ImageFolder(\n",
    "            root=path,\n",
    "            transform=get_transforms(),\n",
    "        )\n",
    "\n",
    "        loaders[split] = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=False,  # keep False to align features with filenames\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        print(f\"{split.upper()} - Found {len(dataset)} images\")\n",
    "\n",
    "    return loaders\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps ResNet50 to output raw features instead of classification scores.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Works on older and newer torchvision\n",
    "        try:\n",
    "            # New API (torchvision >= 0.13)\n",
    "            weights = models.ResNet50Weights.IMAGENET1K_V2\n",
    "            backbone = models.resnet50(weights=weights)\n",
    "        except AttributeError:\n",
    "            # Old API (torchvision < 0.13, e.g. many Colab runtimes)\n",
    "            backbone = models.resnet50(pretrained=True)\n",
    "\n",
    "        backbone.fc = nn.Identity()  # 2048-dim features\n",
    "        backbone.eval()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "def get_aug_transforms(img_size: int = 224):\n",
    "    \"\"\"\n",
    "    Augmentation used only for offline-augmented training features.\n",
    "    \"\"\"\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def run_feature_extraction_augmented(config: ExperimentConfig):\n",
    "    \"\"\"\n",
    "    Extracts ResNet50 features and saves them to disk.\n",
    "\n",
    "    - For train/val/test: saves CLEAN features.\n",
    "    - For train only: also saves AUGMENTED features.\n",
    "    \"\"\"\n",
    "    device = torch.device(config.device)\n",
    "    model = FeatureExtractor().to(device)\n",
    "\n",
    "    # Deterministic loaders\n",
    "    clean_loaders = get_dataloaders(config)\n",
    "\n",
    "    save_dir = os.path.join(config.output_dir, \"features\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    metadata = []\n",
    "\n",
    "    print(\"\\nğŸš€ Starting augmented feature extraction...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for split, loader in clean_loaders.items():\n",
    "            # 1) CLEAN features for all splits\n",
    "            for batch_idx, (images, labels) in enumerate(\n",
    "                tqdm(loader, desc=f\"Extracting {split} (Clean)\")\n",
    "            ):\n",
    "                images = images.to(device)\n",
    "                with autocast():\n",
    "                    features = model(images)\n",
    "                features = features.cpu().numpy()\n",
    "\n",
    "                start_idx = batch_idx * config.batch_size\n",
    "                for i, feat in enumerate(features):\n",
    "                    global_idx = start_idx + i\n",
    "                    original_path, label_idx = loader.dataset.samples[global_idx]\n",
    "                    filename = os.path.basename(original_path)\n",
    "                    classname = loader.dataset.classes[label_idx]\n",
    "\n",
    "                    save_name = f\"{split}_CLEAN_{classname}_{filename}.npy\"\n",
    "                    save_path = os.path.join(save_dir, save_name)\n",
    "                    np.save(save_path, feat)\n",
    "\n",
    "                    metadata.append(\n",
    "                        {\n",
    "                            \"feature_path\": save_path,\n",
    "                            \"label\": label_idx,\n",
    "                            \"classname\": classname,\n",
    "                            \"split\": split,\n",
    "                            \"original_path\": original_path,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            # 2) AUGMENTED features for train only\n",
    "            if split == \"train\":\n",
    "                aug_dataset = datasets.ImageFolder(\n",
    "                    root=os.path.join(config.data_root, split),\n",
    "                    transform=get_aug_transforms(img_size=224),\n",
    "                )\n",
    "                aug_loader = DataLoader(\n",
    "                    aug_dataset,\n",
    "                    batch_size=config.batch_size,\n",
    "                    shuffle=False,\n",
    "                    num_workers=2,\n",
    "                    pin_memory=True,\n",
    "                )\n",
    "\n",
    "                for batch_idx, (images, labels) in enumerate(\n",
    "                    tqdm(aug_loader, desc=f\"Extracting {split} (Augmented)\")\n",
    "                ):\n",
    "                    images = images.to(device)\n",
    "                    with autocast():\n",
    "                        features = model(images)\n",
    "                    features = features.cpu().numpy()\n",
    "\n",
    "                    start_idx = batch_idx * config.batch_size\n",
    "                    for i, feat in enumerate(features):\n",
    "                        global_idx = start_idx + i\n",
    "                        original_path, label_idx = aug_loader.dataset.samples[global_idx]\n",
    "                        filename = os.path.basename(original_path)\n",
    "                        classname = aug_loader.dataset.classes[label_idx]\n",
    "\n",
    "                        save_name = f\"{split}_AUG_{classname}_{filename}.npy\"\n",
    "                        save_path = os.path.join(save_dir, save_name)\n",
    "                        np.save(save_path, feat)\n",
    "\n",
    "                        metadata.append(\n",
    "                            {\n",
    "                                \"feature_path\": save_path,\n",
    "                                \"label\": label_idx,\n",
    "                                \"classname\": classname,\n",
    "                                \"split\": split,\n",
    "                                \"original_path\": original_path,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    meta_path = os.path.join(config.output_dir, \"metadata.csv\")\n",
    "    pd.DataFrame(metadata).to_csv(meta_path, index=False)\n",
    "    print(f\"âœ… Augmented extraction complete. Metadata saved to {meta_path}\")\n",
    "    return meta_path\n",
    "\n",
    "\n",
    "# Run extraction\n",
    "meta_csv_path = run_feature_extraction_augmented(CFG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e3368",
   "metadata": {},
   "source": [
    "### 3. Classical preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b2bc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading raw features...\n",
      "TRAIN: X shape = (10432, 2048), y shape = (10432,)\n",
      "VAL: X shape = (16, 2048), y shape = (16,)\n",
      "TEST: X shape = (624, 2048), y shape = (624,)\n",
      "\n",
      "âš ï¸ Fixing small validation set issue...\n",
      " Original Val size: 2090\n",
      " New Train size: 8358\n",
      "\n",
      "ğŸ”„ Fitting SELECTKBEST pipeline...\n",
      "âœ… Preprocessing complete. Data ready for quantum training.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "def load_features(config: ExperimentConfig):\n",
    "    \"\"\"\n",
    "    Load saved .npy feature files according to metadata.csv.\n",
    "    \"\"\"\n",
    "    meta_path = os.path.join(config.output_dir, \"metadata.csv\")\n",
    "    if not os.path.exists(meta_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Metadata CSV not found at {meta_path}. Run feature extraction first.\"\n",
    "        )\n",
    "\n",
    "    df = pd.read_csv(meta_path)\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    X, y = {}, {}\n",
    "\n",
    "    print(\"ğŸ“‚ Loading raw features...\")\n",
    "    for split in splits:\n",
    "        subset = df[df[\"split\"] == split]\n",
    "        if subset.empty:\n",
    "            print(f\"Warning: no rows for split='{split}' in metadata.\")\n",
    "            continue\n",
    "\n",
    "        features = [np.load(path) for path in subset[\"feature_path\"]]\n",
    "        X[split] = np.vstack(features)\n",
    "        y[split] = subset[\"label\"].values\n",
    "\n",
    "        print(f\"{split.upper()}: X shape = {X[split].shape}, y shape = {y[split].shape}\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def fix_validation_split(X, y, config: ExperimentConfig):\n",
    "    \"\"\"\n",
    "    Merge original train and val, then create a new 80/20 split.\n",
    "    \"\"\"\n",
    "    print(\"\\nâš ï¸ Fixing small validation set issue...\")\n",
    "\n",
    "    X_combined = np.concatenate([X[\"train\"], X[\"val\"]])\n",
    "    y_combined = np.concatenate([y[\"train\"], y[\"val\"]])\n",
    "\n",
    "    X_train_new, X_val_new, y_train_new, y_val_new = train_test_split(\n",
    "        X_combined,\n",
    "        y_combined,\n",
    "        test_size=0.2,\n",
    "        stratify=y_combined,\n",
    "        random_state=config.seed,\n",
    "    )\n",
    "\n",
    "    X[\"train\"], y[\"train\"] = X_train_new, y_train_new\n",
    "    X[\"val\"], y[\"val\"] = X_val_new, y_val_new\n",
    "\n",
    "    print(f\" Original Val size: {len(y['val'])}\")\n",
    "    print(f\" New Train size: {len(y['train'])}\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def build_pipeline(config: ExperimentConfig):\n",
    "    \"\"\"\n",
    "    Build sklearn preprocessing pipeline: scaling + dimensionality reduction + encoding scaling.\n",
    "    \"\"\"\n",
    "    steps = [(\"scaler\", StandardScaler())]\n",
    "\n",
    "    if config.reduction_method == \"pca\":\n",
    "        steps.append(\n",
    "            (\"reducer\", PCA(n_components=config.target_dims, random_state=config.seed))\n",
    "        )\n",
    "    elif config.reduction_method == \"lda\":\n",
    "        steps.append((\"reducer\", LDA(n_components=min(config.target_dims, 1))))\n",
    "    elif config.reduction_method == \"selectkbest\":\n",
    "        steps.append(\n",
    "            (\"selector\", SelectKBest(score_func=f_classif, k=config.target_dims))\n",
    "        )\n",
    "\n",
    "    if config.encoding_method == \"amplitude\":\n",
    "        steps.append((\"normalizer\", Normalizer(norm=\"l2\")))\n",
    "    elif config.encoding_method == \"angle\":\n",
    "        steps.append((\"minmax\", MinMaxScaler(feature_range=(0, np.pi))))\n",
    "\n",
    "    return Pipeline(steps)\n",
    "\n",
    "\n",
    "def run_classical_preprocessing(config: ExperimentConfig):\n",
    "    # 1. Load data\n",
    "    X, y = load_features(config)\n",
    "\n",
    "    # 2. Fix validation split\n",
    "    X, y = fix_validation_split(X, y, config)\n",
    "\n",
    "    # 3. Build & fit pipeline\n",
    "    pipeline = build_pipeline(config)\n",
    "    print(f\"\\nğŸ”„ Fitting {config.reduction_method.upper()} pipeline...\")\n",
    "    pipeline.fit(X[\"train\"], y[\"train\"])\n",
    "\n",
    "    # 4. Transform and save\n",
    "    X_processed = {\n",
    "        \"train\": pipeline.transform(X[\"train\"]),\n",
    "        \"val\": pipeline.transform(X[\"val\"]),\n",
    "        \"test\": pipeline.transform(X[\"test\"]),\n",
    "    }\n",
    "\n",
    "    processed_dir = os.path.join(config.output_dir, \"processed_data\")\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        np.save(os.path.join(processed_dir, f\"X_{split}.npy\"), X_processed[split])\n",
    "        np.save(os.path.join(processed_dir, f\"y_{split}.npy\"), y[split])\n",
    "\n",
    "    pipeline_path = os.path.join(config.output_dir, \"preprocessing_pipeline.joblib\")\n",
    "    joblib.dump(pipeline, pipeline_path)\n",
    "\n",
    "    print(\"âœ… Preprocessing complete. Data ready for quantum training.\")\n",
    "    return X_processed, y\n",
    "\n",
    "\n",
    "# Run preprocessing\n",
    "X_data, y_data = run_classical_preprocessing(CFG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad7599",
   "metadata": {},
   "source": [
    "### 4. Quantum model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e96e0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training single quantum model ===\n",
      "\n",
      "âš›ï¸ Initializing Quantum Model (6 qubits, 4 layers)...\n",
      "ğŸš€ Starting training for 50 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5e6f030ad94ee1877bbabff80c11f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1: Train Loss 1.6130 | Val Loss 1.5290 | Val Acc 0.4359\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb7baa84793490584dfaf799f940a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 2: Train Loss 1.4938 | Val Loss 1.4722 | Val Acc 0.4502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e30b17faabb4cc6952554d91dcbb9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 3: Train Loss 1.4510 | Val Loss 1.4501 | Val Acc 0.4823\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468a6615363249d2b57f054fd24a73ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 4: Train Loss 1.4309 | Val Loss 1.4401 | Val Acc 0.4957\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8daed3d43be246cd8f9f5263acf24510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 5: Train Loss 1.4201 | Val Loss 1.4343 | Val Acc 0.5005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4795a2e12a848f182ce17c9655f21fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 6: Train Loss 1.4140 | Val Loss 1.4310 | Val Acc 0.4876\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70daf78e93734854b6ac6be10d05224d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 7: Train Loss 1.4098 | Val Loss 1.4293 | Val Acc 0.4943\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0648e0f0657f455e932ba2d182282436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-627925783.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_ensemble\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== Training single quantum model ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_quantum_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     test_metrics, test_preds, test_probs = evaluate_model(\n\u001b[1;32m    238\u001b[0m         \u001b[0mCFG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-627925783.py\u001b[0m in \u001b[0;36mtrain_quantum_model\u001b[0;34m(config, X_data, y_data)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 params, loss = opt.step_and_cost(\n\u001b[0m\u001b[1;32m    120\u001b[0m                     \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcost_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/optimize/gradient_descent.py\u001b[0m in \u001b[0;36mstep_and_cost\u001b[0;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \"\"\"\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/optimize/gradient_descent.py\u001b[0m in \u001b[0;36mcompute_grad\u001b[0;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[1;32m    121\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_fn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"forward\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/_grad.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mgrad_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/_grad.py\u001b[0m in \u001b[0;36m_grad_with_forward\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mdifference\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;32mand\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         value.\"\"\"\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=redefined-outer-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/core.py\u001b[0m in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstart_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVJPNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mend_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstart_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mend_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_box\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36munary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0msubargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-627925783.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 params, loss = opt.step_and_cost(\n\u001b[0;32m--> 120\u001b[0;31m                     \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcost_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 )\n\u001b[1;32m    122\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-627925783.py\u001b[0m in \u001b[0;36mcost_fn\u001b[0;34m(params, x_batch, y_batch)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcost_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         targets = pnp.array(\n\u001b[1;32m     75\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcapture_qnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m_impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_program\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_classical_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         res = execute(\n\u001b[0m\u001b[1;32m    869\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/execution.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, transform_program, executor_backend)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mouter_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_informative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"should only contain device preprocessing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0muser_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouter_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trainable_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/interfaces/autograd.py\u001b[0m in \u001b[0;36mautograd_execute\u001b[0;34m(tapes, execute_fn, jpc, device)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtapes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     )\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0margnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/interfaces/autograd.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(parameters, tapes, execute_fn, jpc)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \"\"\"\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_to_autograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/jacobian_products.py\u001b[0m in \u001b[0;36mexecute_and_cache_jacobian\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEnabledFor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Forward pass called with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dev_execute_and_compute_derivatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jacs_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/jacobian_products.py\u001b[0m in \u001b[0;36m_dev_execute_and_compute_derivatives\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \"\"\"\n\u001b[1;32m    448\u001b[0m         \u001b[0mnumpy_tapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_numpy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_and_compute_derivatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_tapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dev_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtapes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQuantumScriptBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/modifiers/simulator_tracking.py\u001b[0m in \u001b[0;36mexecute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     95\u001b[0m             )\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muntracked_execute_and_compute_derivatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexecute_and_compute_derivatives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/modifiers/single_tape_support.py\u001b[0m in \u001b[0;36mexecute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mis_single_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mcircuits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_execute_and_compute_derivatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_single_circuit\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/modifiers/simulator_tracking.py\u001b[0m in \u001b[0;36mexecute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     95\u001b[0m             )\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muntracked_execute_and_compute_derivatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexecute_and_compute_derivatives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/modifiers/single_tape_support.py\u001b[0m in \u001b[0;36mexecute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mis_single_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mcircuits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_execute_and_compute_derivatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_single_circuit\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane_lightning/lightning_base/lightning_base.py\u001b[0m in \u001b[0;36mexecute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mbatch_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_obs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         results = tuple(\n\u001b[0m\u001b[1;32m    424\u001b[0m             self.simulate_and_jacobian(\n\u001b[1;32m    425\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_wires_from_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane_lightning/lightning_base/lightning_base.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mbatch_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_obs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         results = tuple(\n\u001b[0;32m--> 424\u001b[0;31m             self.simulate_and_jacobian(\n\u001b[0m\u001b[1;32m    425\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_wires_from_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_statevector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane_lightning/lightning_base/lightning_base.py\u001b[0m in \u001b[0;36msimulate_and_jacobian\u001b[0;34m(self, circuit, state, batch_obs, wire_map)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningAdjointJacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane_lightning/lightning_gpu/_adjoint_jacobian.py\u001b[0m in \u001b[0;36mcalculate_jacobian\u001b[0;34m(self, tape)\u001b[0m\n\u001b[1;32m    159\u001b[0m             )\n\u001b[1;32m    160\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             jac = self._jacobian_lightning(\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0mprocessed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_vector\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mprocessed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obs_serialized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "def get_device(config: ExperimentConfig):\n",
    "    \"\"\"Create a PennyLane device with GPU acceleration if available.\"\"\"\n",
    "    try:\n",
    "        return qml.device(\"lightning.gpu\", wires=config.n_qubits)\n",
    "    except Exception:\n",
    "        return qml.device(\"default.qubit\", wires=config.n_qubits)\n",
    "\n",
    "\n",
    "def embedding_layer(features, config: ExperimentConfig):\n",
    "    \"\"\"Encode classical features into a quantum state.\"\"\"\n",
    "    wires = range(config.n_qubits)\n",
    "\n",
    "    if config.encoding_method == \"amplitude\":\n",
    "        qml.AmplitudeEmbedding(\n",
    "            features=features, wires=wires, normalize=True, pad_with=0.0\n",
    "        )\n",
    "    elif config.encoding_method == \"angle\":\n",
    "        qml.AngleEmbedding(features=features, wires=wires, rotation=\"Y\")\n",
    "\n",
    "\n",
    "def ansatz_layer(params, config: ExperimentConfig):\n",
    "    \"\"\"Variational circuit using StronglyEntanglingLayers.\"\"\"\n",
    "    qml.StronglyEntanglingLayers(params, wires=range(config.n_qubits))\n",
    "\n",
    "\n",
    "def build_qnode(config: ExperimentConfig):\n",
    "    dev = get_device(config)\n",
    "\n",
    "    @qml.qnode(dev, interface=\"autograd\", diff_method=\"adjoint\", cache=True)\n",
    "    def qnode(inputs, params):\n",
    "        embedding_layer(inputs, config)\n",
    "        ansatz_layer(params, config)\n",
    "        return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "    return qnode\n",
    "\n",
    "\n",
    "def train_quantum_model(config: ExperimentConfig, X_data, y_data):\n",
    "    \"\"\"\n",
    "    Train a single quantum model using weighted MSE on {âˆ’1, +1} labels.\n",
    "    \"\"\"\n",
    "    print(\n",
    "        f\"\\nâš›ï¸ Initializing Quantum Model ({config.n_qubits} qubits, {config.n_layers} layers)...\"\n",
    "    )\n",
    "\n",
    "    qnode = build_qnode(config)\n",
    "\n",
    "    param_shape = qml.StronglyEntanglingLayers.shape(\n",
    "        n_layers=config.n_layers, n_wires=config.n_qubits\n",
    "    )\n",
    "    params = pnp.random.uniform(0, 2 * np.pi, size=param_shape, requires_grad=True)\n",
    "\n",
    "    opt = qml.AdamOptimizer(stepsize=config.learning_rate)\n",
    "\n",
    "    def update_lr(epoch, optimizer):\n",
    "        if epoch == 15:\n",
    "            optimizer.stepsize = 0.001\n",
    "        if epoch == 35:\n",
    "            optimizer.stepsize = 0.0005\n",
    "        return optimizer\n",
    "\n",
    "    def cost_fn(params, x_batch, y_batch):\n",
    "        preds = qnode(x_batch, params)\n",
    "        targets = pnp.array(\n",
    "            [1 if y == 1 else -1 for y in y_batch], requires_grad=False\n",
    "        )\n",
    "        w_normal = 3.5\n",
    "        w_pneumonia = 1.0\n",
    "        batch_weights = pnp.array(\n",
    "            [w_normal if t == -1 else w_pneumonia for t in targets],\n",
    "            requires_grad=False,\n",
    "        )\n",
    "        return pnp.mean(batch_weights * ((preds - targets) ** 2))\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_params = None\n",
    "\n",
    "    X_train, y_train = X_data[\"train\"], y_data[\"train\"]\n",
    "    X_val, y_val = X_data[\"val\"], y_data[\"val\"]\n",
    "\n",
    "    batch_size = config.batch_size\n",
    "    n_batches = len(X_train) // batch_size\n",
    "\n",
    "    print(f\"ğŸš€ Starting training for {config.epochs} epochs...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        opt = update_lr(epoch, opt)\n",
    "\n",
    "        perm = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[perm]\n",
    "        y_train = y_train[perm]\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        with tqdm(\n",
    "            total=n_batches,\n",
    "            desc=f\"Epoch {epoch + 1}/{config.epochs}\",\n",
    "            leave=False,\n",
    "        ) as pbar:\n",
    "            for i in range(n_batches):\n",
    "                batch_idx = slice(i * batch_size, (i + 1) * batch_size)\n",
    "                X_batch = X_train[batch_idx]\n",
    "                y_batch = y_train[batch_idx]\n",
    "\n",
    "                params, loss = opt.step_and_cost(\n",
    "                    lambda p: cost_fn(p, X_batch, y_batch), params\n",
    "                )\n",
    "                epoch_loss += loss\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\"loss\": f\"{loss:.4f}\"})\n",
    "\n",
    "        avg_train_loss = epoch_loss / n_batches\n",
    "\n",
    "        val_loss = cost_fn(params, X_val, y_val)\n",
    "        val_preds_raw = qnode(X_val, params)\n",
    "        val_preds = (val_preds_raw > 0).astype(int)\n",
    "        val_acc = accuracy_score(y_val, val_preds)\n",
    "\n",
    "        history[\"train_loss\"].append(float(avg_train_loss))\n",
    "        history[\"val_loss\"].append(float(val_loss))\n",
    "        history[\"val_acc\"].append(float(val_acc))\n",
    "\n",
    "        print(\n",
    "            f\" Epoch {epoch + 1}: \"\n",
    "            f\"Train Loss {avg_train_loss:.4f} | \"\n",
    "            f\"Val Loss {val_loss:.4f} | \"\n",
    "            f\"Val Acc {val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        improved = False\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = float(val_loss)\n",
    "            best_params = params.copy()\n",
    "            improved = True\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = float(val_acc)\n",
    "            best_params = params.copy()\n",
    "            improved = True\n",
    "\n",
    "        if improved:\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= config.patience:\n",
    "            print(f\"â¹ Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"âœ… Training done in {train_time:.1f}s. Best Val Loss: {best_val_loss:.4f}\")\n",
    "    print(f\" Best Val Acc: {best_val_acc:.4f}\")\n",
    "    return best_params, qnode, history\n",
    "\n",
    "\n",
    "def evaluate_model(config: ExperimentConfig, params, qnode, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate trained model on test set.\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ“Š Evaluating on test set...\")\n",
    "    preds_raw = np.array([qnode(x, params) for x in X_test])\n",
    "    probs = (preds_raw + 1) / 2.0\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, preds),\n",
    "        \"f1_score\": f1_score(y_test, preds, average=\"macro\"),\n",
    "        \"auc_score\": roc_auc_score(y_test, probs),\n",
    "    }\n",
    "\n",
    "    print(f\" Test Accuracy: {metrics['accuracy']:.2%}\")\n",
    "    print(f\" Test F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\" Test AUC: {metrics['auc_score']:.4f}\")\n",
    "    return metrics, preds, probs\n",
    "\n",
    "\n",
    "def train_ensemble(config: ExperimentConfig, X_data, y_data):\n",
    "    \"\"\"\n",
    "    Train an ensemble of quantum models by calling train_quantum_model\n",
    "    multiple times with different seeds.\n",
    "\n",
    "    Returns:\n",
    "        ensemble_params: list of parameter arrays\n",
    "        qnode: QNode instance (same structure for all models)\n",
    "        histories: list of training histories\n",
    "    \"\"\"\n",
    "    ensemble_params = []\n",
    "    histories = []\n",
    "    qnode = None\n",
    "\n",
    "    for i in range(config.ensemble_size):\n",
    "        print(f\"\\nğŸ¤– Training ensemble member {i + 1}/{config.ensemble_size}...\")\n",
    "        # Slightly perturb the seed for diversity\n",
    "        seed_everything(config.seed + i)\n",
    "        params_i, qnode_i, history_i = train_quantum_model(config, X_data, y_data)\n",
    "        ensemble_params.append(params_i)\n",
    "        histories.append(history_i)\n",
    "        qnode = qnode_i  # all qnodes share same structure\n",
    "\n",
    "    return ensemble_params, qnode, histories\n",
    "\n",
    "\n",
    "def predict_ensemble(X, ensemble_params, qnode):\n",
    "    \"\"\"\n",
    "    Run all ensemble members on X and average their probabilities.\n",
    "    \"\"\"\n",
    "    all_probs = []\n",
    "    for params in ensemble_params:\n",
    "        preds_raw = np.array([qnode(x, params) for x in X])  # [-1, 1]\n",
    "        probs = (preds_raw + 1) / 2.0                        # [0, 1]\n",
    "        all_probs.append(probs)\n",
    "\n",
    "    all_probs = np.stack(all_probs, axis=0)  # [n_models, n_samples]\n",
    "    avg_probs = np.mean(all_probs, axis=0)   # [n_samples]\n",
    "    return avg_probs\n",
    "\n",
    "\n",
    "# --- Execution: single model or ensemble, controlled by CFG.use_ensemble ---\n",
    "\n",
    "if not CFG.use_ensemble:\n",
    "    print(\"\\n=== Training single quantum model ===\")\n",
    "    best_params, qnode, history = train_quantum_model(CFG, X_data, y_data)\n",
    "    test_metrics, test_preds, test_probs = evaluate_model(\n",
    "        CFG, best_params, qnode, X_data[\"test\"], y_data[\"test\"]\n",
    "    )\n",
    "\n",
    "    # Save single-model results\n",
    "    results_path = os.path.join(CFG.output_dir, \"quantum_results_single.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"config\": {k: str(v) for k, v in CFG.__dict__.items()},\n",
    "                \"metrics\": test_metrics,\n",
    "                \"history\": history,\n",
    "            },\n",
    "            f,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "    np.save(os.path.join(CFG.output_dir, \"best_params_single.npy\"), best_params)\n",
    "    print(f\"ğŸ’¾ Saved single-model results to {results_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n=== Training quantum ensemble ===\")\n",
    "    ensemble_params, qnode, histories = train_ensemble(CFG, X_data, y_data)\n",
    "\n",
    "    X_test = X_data[\"test\"]\n",
    "    y_test = y_data[\"test\"]\n",
    "    final_probs = predict_ensemble(X_test, ensemble_params, qnode)\n",
    "    test_probs = final_probs  # to reuse downstream plotting code\n",
    "    test_preds = (final_probs > 0.5).astype(int)\n",
    "\n",
    "    test_metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, test_preds),\n",
    "        \"f1_score\": f1_score(y_test, test_preds, average=\"macro\"),\n",
    "        \"auc_score\": roc_auc_score(y_test, final_probs),\n",
    "    }\n",
    "\n",
    "    print(f\" Ensemble Test Accuracy: {test_metrics['accuracy']:.2%}\")\n",
    "    print(f\" Ensemble Test F1 Score: {test_metrics['f1_score']:.4f}\")\n",
    "    print(f\" Ensemble Test AUC: {test_metrics['auc_score']:.4f}\")\n",
    "\n",
    "    # Save ensemble results\n",
    "    results_path = os.path.join(CFG.output_dir, \"quantum_results_ensemble.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"config\": {k: str(v) for k, v in CFG.__dict__.items()},\n",
    "                \"metrics\": test_metrics,\n",
    "                \"histories\": histories,\n",
    "            },\n",
    "            f,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(CFG.output_dir, \"ensemble_params.npy\"),\n",
    "        np.array(ensemble_params, dtype=object),\n",
    "    )\n",
    "    print(f\"ğŸ’¾ Saved ensemble results to {results_path}\")\n",
    "\n",
    "\n",
    "# Save results\n",
    "results_path = os.path.join(CFG.output_dir, \"quantum_results.json\")\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"config\": {k: str(v) for k, v in CFG.__dict__.items()},\n",
    "            \"metrics\": test_metrics,\n",
    "            \"history\": history,\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )\n",
    "\n",
    "np.save(os.path.join(CFG.output_dir, \"best_params.npy\"), best_params)\n",
    "print(f\"ğŸ’¾ Saved results to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6201d8",
   "metadata": {},
   "source": [
    "### 5. Post processing: Threshold scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ecad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def binary_search_threshold(y_true, probs, metric=\"balanced_acc\", tol=1e-6, max_iter=50):\n",
    "    \"\"\"\n",
    "    Binary search for optimal threshold using any metric.\n",
    "    \n",
    "    Args:\n",
    "        y_true: ground truth labels\n",
    "        probs: predicted probabilities [0,1]\n",
    "        metric: 'balanced_acc', 'accuracy', 'f1_macro', etc.\n",
    "        tol: convergence tolerance\n",
    "        max_iter: max iterations\n",
    "    \n",
    "    Returns:\n",
    "        best_threshold, best_metric_value\n",
    "    \"\"\"\n",
    "    low, high = 0.1, 0.95\n",
    "    best_threshold = 0.5\n",
    "    best_metric = 0.0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        mid = (low + high) / 2\n",
    "        preds_mid = (probs > mid).astype(int)\n",
    "        \n",
    "        # Compute metric\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, preds_mid).ravel()\n",
    "        sens = tp / (tp + fn + 1e-10)\n",
    "        spec = tn / (tn + fp + 1e-10)\n",
    "        \n",
    "        if metric == \"balanced_acc\":\n",
    "            current_metric = (sens + spec) / 2\n",
    "        elif metric == \"accuracy\":\n",
    "            current_metric = accuracy_score(y_true, preds_mid)\n",
    "        elif metric == \"f1_macro\":\n",
    "            current_metric = f1_score(y_true, preds_mid, average=\"macro\")\n",
    "        \n",
    "        # Update best\n",
    "        if current_metric > best_metric:\n",
    "            best_metric = current_metric\n",
    "            best_threshold = mid\n",
    "        \n",
    "        # Binary search logic\n",
    "        if current_metric > best_metric:  # Still improving, search finer\n",
    "            high = mid\n",
    "        else:\n",
    "            low = mid\n",
    "        \n",
    "        if high - low < tol:\n",
    "            break\n",
    "    \n",
    "    return best_threshold, best_metric\n",
    "\n",
    "# Run binary search\n",
    "y_test = y_data[\"test\"]\n",
    "probs = test_probs\n",
    "\n",
    "print(\"ğŸ” Binary search for optimal threshold...\")\n",
    "best_thresh, best_bal_acc = binary_search_threshold(y_test, probs, metric=\"balanced_acc\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"ğŸ† Optimal Threshold: {best_thresh:.6f}\")\n",
    "print(f\"   Balanced Accuracy: {best_bal_acc:.4f}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Verify with exact computation\n",
    "preds_opt = (probs > best_thresh).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_opt).ravel()\n",
    "sens = tp / (tp + fn)\n",
    "spec = tn / (tn + fp)\n",
    "acc = accuracy_score(y_test, preds_opt)\n",
    "\n",
    "print(f\"Verification:\")\n",
    "print(f\"  Accuracy: {acc:.4f}\")\n",
    "print(f\"  Sensitivity: {sens:.4f}\")\n",
    "print(f\"  Specificity: {spec:.4f}\")\n",
    "print(f\"  Balanced Acc: {(sens+spec)/2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22aca5",
   "metadata": {},
   "source": [
    "### 6. Evaluation plots and SOÄŒ metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ac3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.rcParams.update({\"font.size\": 12, \"figure.dpi\": 300})\n",
    "\n",
    "\n",
    "def plot_training_history(history, save_dir: str):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    ax1.plot(epochs, history[\"train_loss\"], \"b-\", label=\"Training loss\", linewidth=2)\n",
    "    ax1.plot(epochs, history[\"val_loss\"], \"r--\", label=\"Validation loss\", linewidth=2)\n",
    "    ax1.set_title(\"Loss during training\", fontweight=\"bold\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss (MSE)\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2.plot(epochs, history[\"val_acc\"], \"g-\", label=\"Validation accuracy\", linewidth=2)\n",
    "    ax2.set_title(\"Validation accuracy\", fontweight=\"bold\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.set_ylim(0, 1.0)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, \"training_history.png\")\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    print(f\"ğŸ“ˆ Training history saved to: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_evaluation_metrics(y_true, y_pred, y_probs, save_dir: str):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        ax=ax1,\n",
    "        xticklabels=[\"Normal\", \"Pneumonia\"],\n",
    "        yticklabels=[\"Normal\", \"Pneumonia\"],\n",
    "        annot_kws={\"size\": 14, \"weight\": \"bold\"},\n",
    "    )\n",
    "    ax1.set_title(\"Confusion matrix\", fontweight=\"bold\")\n",
    "    ax1.set_ylabel(\"True class\")\n",
    "    ax1.set_xlabel(\"Predicted class\")\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    ax2.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC (AUC = {roc_auc:.2f})\")\n",
    "    ax2.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "    ax2.set_ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "    ax2.set_title(\"ROC curve\", fontweight=\"bold\")\n",
    "    ax2.legend(loc=\"lower right\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, \"evaluation_metrics.png\")\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    print(f\"ğŸ“Š Evaluation plots saved to: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"=== Visualization for SOÄŒ ===\")\n",
    "plot_training_history(history, CFG.output_dir)\n",
    "plot_evaluation_metrics(y_data[\"test\"], test_preds, test_probs, CFG.output_dir)\n",
    "\n",
    "cm = confusion_matrix(y_data[\"test\"], test_preds)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nğŸ“ Numbers for SOÄŒ table:\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Number of test images: {len(y_data['test'])}\")\n",
    "print(f\"TP (Correct Pneumonia): {tp}\")\n",
    "print(f\"TN (Correct Normal): {tn}\")\n",
    "print(f\"FP (False alarm): {fp}\")\n",
    "print(f\"FN (Missed disease): {fn}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"AUC: {roc_auc_score(y_data['test'], test_probs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac97de",
   "metadata": {},
   "source": [
    "### 7. Quick local download of all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Download all results to your local machine ====\n",
    "from google.colab import files\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "results_dir = CFG.output_dir          # e.g. \"./results\"\n",
    "zip_name = \"results_archive\"          # base name without .zip\n",
    "zip_path = f\"./{zip_name}.zip\" # zip must live under /content for download\n",
    "\n",
    "# Create ZIP from results_dir\n",
    "if os.path.exists(results_dir):\n",
    "    shutil.make_archive(zip_name, \"zip\", results_dir)\n",
    "    print(f\"Created archive: {zip_path}\")\n",
    "    files.download(zip_path)\n",
    "else:\n",
    "    print(f\"Results directory not found: {results_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
