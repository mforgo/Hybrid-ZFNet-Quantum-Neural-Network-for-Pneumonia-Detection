{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3029006",
   "metadata": {
    "id": "e3029006"
   },
   "source": [
    "# Hybrid model for pneumonia detection\n",
    "## 1. Setup and configuration\n",
    "### 1.1. Installing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2364b28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47491,
     "status": "ok",
     "timestamp": 1760344336272,
     "user": {
      "displayName": "Michal Forg√≥",
      "userId": "03385761472197084991"
     },
     "user_tz": -120
    },
    "id": "b2364b28",
    "outputId": "6fd1cfb2-d376-4484-b1de-cb14b666b760"
   },
   "outputs": [],
   "source": [
    "# 1. Setup and configuration\n",
    "\n",
    "!pip install pennylane scikit-learn numpy scipy matplotlib pandas pennylane-qiskit kagglehub scikit-image seaborn pillow opencv-python torch torchvision pennylane-lightning-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f966be",
   "metadata": {},
   "source": [
    "### 1.2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b322fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    # Experiment Metadata\n",
    "    project_name: str = \"Hybrid_ResNet50_QNN_Pneumonia\"\n",
    "    seed: int = 6\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Data Paths\n",
    "    data_root: str = \"/\"\n",
    "    output_dir: str = \"./results\"\n",
    "\n",
    "    # Classical Backbone\n",
    "    backbone_name: str = \"resnet50\"\n",
    "    feature_dim: int = 2048  # 2048 for ResNet50\n",
    "\n",
    "    # Quantum Components\n",
    "    n_qubits: int = 6\n",
    "    n_layers: int = 4\n",
    "    encoding_method: str = \"amplitude\"  # 'amplitude' or 'angle'\n",
    "\n",
    "    # Training Hyperparams\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 0.002\n",
    "    epochs: int = 50\n",
    "    patience: int = 10\n",
    "\n",
    "    # Preprocessing\n",
    "    reduction_method: str = \"selectkbest\"  # 'pca', 'lda', or 'selectkbest'\n",
    "    target_dims: int = 64  # Dimensionality after reduction\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"üîí Global seed set to {seed}\")\n",
    "\n",
    "\n",
    "CFG = ExperimentConfig()\n",
    "seed_everything(CFG.seed)\n",
    "os.makedirs(CFG.output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d7fa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2701,
     "status": "ok",
     "timestamp": 1760344348669,
     "user": {
      "displayName": "Michal Forg√≥",
      "userId": "03385761472197084991"
     },
     "user_tz": -120
    },
    "id": "5d2d7fa4",
    "outputId": "d40499d8-9e61-4069-92d1-f48e0163d886"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version of the dataset\n",
    "CFG.data_root = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\") + \"/chest_xray/\"\n",
    "print(\"Path to dataset files:\", CFG.data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485bfe7",
   "metadata": {
    "id": "2485bfe7"
   },
   "source": [
    "## 2. Hybrid model\n",
    "### 2.1. Classical preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7949166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "# --- Original deterministic transforms (kept as in notebook) ---\n",
    "def get_transforms(img_size=224, split=\"train\"):\n",
    "    \"\"\"\n",
    "    Standardize all input for feature extraction.\n",
    "    We REMOVE random augmentation here to ensure we capture\n",
    "    the highest quality features from the backbone first.\n",
    "    \"\"\"\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "\n",
    "    # Use the same deterministic transform for ALL splits\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "def get_dataloaders(config):\n",
    "    \"\"\"\n",
    "    Creates DataLoaders for Train/Test/Val using ImageFolder.\n",
    "    This replaces manual os.listdir loops.\n",
    "    \"\"\"\n",
    "    loaders = {}\n",
    "    sets = [\"train\", \"test\", \"val\"]\n",
    "\n",
    "    print(f\"Loading data from {config.dataroot}\")\n",
    "\n",
    "    for split in sets:\n",
    "        path = os.path.join(config.dataroot, split)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Warning: Split '{split}' not found at {path}\")\n",
    "            continue\n",
    "\n",
    "        # ImageFolder automatically handles class labels based on folder names\n",
    "        dataset = datasets.ImageFolder(\n",
    "            root=path,\n",
    "            transform=get_transforms(split=split),\n",
    "        )\n",
    "\n",
    "        loaders[split] = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=config.batchsize,\n",
    "            shuffle=False,          # Important: Keep False to match features with filenames later\n",
    "            num_workers=2,          # Parallel loading\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        print(f\"{split.upper()} - Found {len(dataset)} images\")\n",
    "\n",
    "    return loaders\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps ResNet50 to output raw features instead of classification scores.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load modern V2 weights for better performance\n",
    "        weights = models.ResNet50Weights.IMAGENET1K_V2\n",
    "        self.backbone = models.resnet50(weights=weights)\n",
    "\n",
    "        # Replace the final classification layer (fc) with Identity\n",
    "        # This allows us to get the 2048‚Äëdim feature vector directly\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.backbone.eval()  # Set to evaluation mode, freezes BatchNorm\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# --- NEW: Augmentation transforms for offline feature extraction ---\n",
    "def get_aug_transforms(img_size=224):\n",
    "    \"\"\"Adds noise/rotation to create 'new' training data.\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomRotation(15),             # Rotate +/- 15 degrees\n",
    "        transforms.RandomHorizontalFlip(p=0.5),    # 50% chance to flip\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.1,\n",
    "            contrast=0.1\n",
    "        ),                                         # Slight lighting change\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "# --- ORIGINAL clean-only extraction (kept for reference / backward compatibility) ---\n",
    "def run_feature_extraction(config):\n",
    "    \"\"\"\n",
    "    The Engine: Loads data, passes it through ResNet, and saves features.\n",
    "    \"\"\"\n",
    "    device = torch.device(config.device)\n",
    "    model = FeatureExtractor().to(device)\n",
    "    loaders = get_dataloaders(config)\n",
    "\n",
    "    # Create directory for saved features\n",
    "    save_dir = os.path.join(config.outputdir, \"features\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    metadata = []\n",
    "\n",
    "    print(f\"Starting extraction with {config.backbonename} on {device}...\")\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for speed\n",
    "        for split, loader in loaders.items():\n",
    "            for batch_idx, (images, labels) in enumerate(\n",
    "                tqdm(loader, desc=f\"Extracting {split}\")\n",
    "            ):\n",
    "                images = images.to(device)\n",
    "\n",
    "                # Forward pass: Get features [BatchSize, 2048]\n",
    "                with autocast():  # Mixed precision for speed\n",
    "                    features = model(images)\n",
    "\n",
    "                features = features.cpu().numpy()\n",
    "\n",
    "                # Match features back to original filenames\n",
    "                # We calculate the global index based on batch size\n",
    "                start_idx = batch_idx * config.batchsize\n",
    "\n",
    "                for i, feat in enumerate(features):\n",
    "                    global_idx = start_idx + i\n",
    "\n",
    "                    # Retrieve path from dataset.samples, which is (path, class_idx)\n",
    "                    original_path, label_idx = loader.dataset.samples[global_idx]\n",
    "                    filename = os.path.basename(original_path)\n",
    "                    classname = loader.dataset.classes[label_idx]\n",
    "\n",
    "                    # Save individual feature file\n",
    "                    save_name = f\"{split}_{classname}_{filename}.npy\"\n",
    "                    save_path = os.path.join(save_dir, save_name)\n",
    "                    np.save(save_path, feat)\n",
    "\n",
    "                    metadata.append({\n",
    "                        \"feature_path\": save_path,\n",
    "                        \"label\": label_idx,      # 0 or 1\n",
    "                        \"classname\": classname,\n",
    "                        \"split\": split,\n",
    "                        \"original_path\": original_path,\n",
    "                    })\n",
    "\n",
    "    # Save metadata CSV for easy loading later\n",
    "    meta_path = os.path.join(config.outputdir, \"metadata.csv\")\n",
    "    pd.DataFrame(metadata).to_csv(meta_path, index=False)\n",
    "    print(f\"Extraction complete. Metadata saved to {meta_path}\")\n",
    "    return meta_path\n",
    "\n",
    "# --- UPGRADE 1: Offline Augmentation Extraction ---\n",
    "# This creates a \"Clean\" version AND an \"Augmented\" version of the training set\n",
    "def run_feature_extraction_augmented(config):\n",
    "    \"\"\"\n",
    "    Extended extraction:\n",
    "    - For all splits (train/val/test): extract CLEAN features as before\n",
    "    - For TRAIN split only: extract additional AUGMENTED features using on‚Äëthe‚Äëfly transforms\n",
    "    \"\"\"\n",
    "    device = torch.device(config.device)\n",
    "    model = FeatureExtractor().to(device)\n",
    "\n",
    "    # Standard loaders with deterministic transforms\n",
    "    clean_loaders = get_dataloaders(config)\n",
    "\n",
    "    save_dir = os.path.join(config.outputdir, \"features\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    metadata = []\n",
    "\n",
    "    print(\"\\nüöÄ Starting Augmented Extraction...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for split, loader in clean_loaders.items():\n",
    "            # 1. Extract CLEAN data (Train, Val, Test)\n",
    "            for batch_idx, (images, labels) in enumerate(\n",
    "                tqdm(loader, desc=f\"Extracting {split} (Clean)\")\n",
    "            ):\n",
    "                images = images.to(device)\n",
    "                with autocast():\n",
    "                    features = model(images)\n",
    "                features = features.cpu().numpy()\n",
    "\n",
    "                # Save\n",
    "                start_idx = batch_idx * config.batchsize\n",
    "                for i, feat in enumerate(features):\n",
    "                    global_idx = start_idx + i\n",
    "                    original_path, label_idx = loader.dataset.samples[global_idx]\n",
    "                    filename = os.path.basename(original_path)\n",
    "                    classname = loader.dataset.classes[label_idx]\n",
    "\n",
    "                    save_name = f\"{split}_CLEAN_{classname}_{filename}.npy\"\n",
    "                    save_path = os.path.join(save_dir, save_name)\n",
    "                    np.save(save_path, feat)\n",
    "\n",
    "                    metadata.append({\n",
    "                        \"feature_path\": save_path,\n",
    "                        \"label\": label_idx,\n",
    "                        \"classname\": classname,\n",
    "                        \"split\": split,\n",
    "                        \"original_path\": original_path,\n",
    "                    })\n",
    "\n",
    "            # 2. Extract AUGMENTED data (TRAIN ONLY)\n",
    "            if split == \"train\":\n",
    "                # Create a temporary loader with augmentation\n",
    "                aug_dataset = datasets.ImageFolder(\n",
    "                    root=os.path.join(config.dataroot, split),\n",
    "                    transform=get_aug_transforms(img_size=224),\n",
    "                )\n",
    "                aug_loader = DataLoader(\n",
    "                    aug_dataset,\n",
    "                    batch_size=config.batchsize,\n",
    "                    shuffle=False,\n",
    "                    num_workers=2,\n",
    "                    pin_memory=True,\n",
    "                )\n",
    "\n",
    "                for batch_idx, (images, labels) in enumerate(\n",
    "                    tqdm(aug_loader, desc=f\"Extracting {split} (Augmented)\")\n",
    "                ):\n",
    "                    images = images.to(device)\n",
    "                    with autocast():\n",
    "                        features = model(images)\n",
    "                    features = features.cpu().numpy()\n",
    "\n",
    "                    start_idx = batch_idx * config.batchsize\n",
    "                    for i, feat in enumerate(features):\n",
    "                        global_idx = start_idx + i\n",
    "                        original_path, label_idx = aug_loader.dataset.samples[global_idx]\n",
    "                        filename = os.path.basename(original_path)\n",
    "                        classname = aug_loader.dataset.classes[label_idx]\n",
    "\n",
    "                        # Save with _AUG suffix\n",
    "                        save_name = f\"{split}_AUG_{classname}_{filename}.npy\"\n",
    "                        save_path = os.path.join(save_dir, save_name)\n",
    "                        np.save(save_path, feat)\n",
    "\n",
    "                        metadata.append({\n",
    "                            \"feature_path\": save_path,\n",
    "                            \"label\": label_idx,\n",
    "                            \"classname\": classname,\n",
    "                            \"split\": split,\n",
    "                            \"original_path\": original_path,\n",
    "                        })\n",
    "\n",
    "    meta_path = os.path.join(config.outputdir, \"metadata.csv\")\n",
    "    pd.DataFrame(metadata).to_csv(meta_path, index=False)\n",
    "    print(f\"‚úÖ Augmented Extraction Complete. Metadata saved to {meta_path}\")\n",
    "    return meta_path\n",
    "\n",
    "# Run the new extraction instead of the old one\n",
    "meta_csv_path = run_feature_extraction_augmented(CFG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def load_features(config):\n",
    "    \"\"\"\n",
    "    Loads features from .npy files based on the metadata CSV.\n",
    "    \"\"\"\n",
    "    meta_path = os.path.join(config.output_dir, \"metadata.csv\")\n",
    "    if not os.path.exists(meta_path):\n",
    "        raise FileNotFoundError(f\"Metadata CSV not found at {meta_path}. Run Step 3 first.\")\n",
    "    \n",
    "    df = pd.read_csv(meta_path)\n",
    "    splits = ['train', 'val', 'test']\n",
    "    \n",
    "    X, y = {}, {}\n",
    "    \n",
    "    print(f\"üìÇ Loading raw features...\")\n",
    "    for split in splits:\n",
    "        subset = df[df['split'] == split]\n",
    "        features = [np.load(path) for path in subset['feature_path']]\n",
    "        X[split] = np.vstack(features)\n",
    "        y[split] = subset['label'].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def fix_validation_split(X, y, config):\n",
    "    \"\"\"\n",
    "    OPRAVA: Slouƒç√≠ Train (5216) a Val (16) a vytvo≈ô√≠ nov√© rozdƒõlen√≠ 80/20.\n",
    "    T√≠m z√≠sk√°me cca 1000 validaƒçn√≠ch sn√≠mk≈Ø m√≠sto 16.\n",
    "    \"\"\"\n",
    "    print(\"\\n‚ö†Ô∏è Fixing small validation set issue...\")\n",
    "    \n",
    "    # 1. Slouƒçen√≠\n",
    "    X_combined = np.concatenate([X['train'], X['val']])\n",
    "    y_combined = np.concatenate([y['train'], y['val']])\n",
    "    \n",
    "    # 2. Nov√© rozdƒõlen√≠ (stratify zajist√≠ spr√°vn√Ω pomƒõr t≈ô√≠d)\n",
    "    X_train_new, X_val_new, y_train_new, y_val_new = train_test_split(\n",
    "        X_combined, y_combined, \n",
    "        test_size=0.2, \n",
    "        stratify=y_combined, \n",
    "        random_state=config.seed\n",
    "    )\n",
    "    \n",
    "    # 3. Aktualizace slovn√≠k≈Ø\n",
    "    X['train'], y['train'] = X_train_new, y_train_new\n",
    "    X['val'], y['val']     = X_val_new, y_val_new\n",
    "    \n",
    "    print(f\"   Original Val size: 16 -> New Val size: {len(X_val_new)}\")\n",
    "    print(f\"   New Train size:    {len(X_train_new)}\")\n",
    "    return X, y\n",
    "\n",
    "def build_pipeline(config):\n",
    "    steps = [('scaler', StandardScaler())]\n",
    "    \n",
    "    if config.reduction_method == 'pca':\n",
    "        steps.append(('reducer', PCA(n_components=config.target_dims, random_state=config.seed)))\n",
    "    elif config.reduction_method == 'lda':\n",
    "        steps.append(('reducer', LDA(n_components=min(config.target_dims, 1))))\n",
    "    elif config.reduction_method == 'selectkbest':\n",
    "        steps.append(('selector', SelectKBest(score_func=f_classif, k=config.target_dims)))\n",
    "        \n",
    "    if config.encoding_method == 'amplitude':\n",
    "        steps.append(('normalizer', Normalizer(norm='l2')))\n",
    "    elif config.encoding_method == 'angle':\n",
    "        steps.append(('minmax', MinMaxScaler(feature_range=(0, np.pi))))\n",
    "        \n",
    "    return Pipeline(steps)\n",
    "\n",
    "def run_classical_preprocessing(config):\n",
    "    # 1. Load Data\n",
    "    X, y = load_features(config)\n",
    "    \n",
    "    # 2. FIX DATA SPLIT (Tohle je ta kl√≠ƒçov√° oprava)\n",
    "    X, y = fix_validation_split(X, y, config)\n",
    "    \n",
    "    # 3. Build & Fit Pipeline\n",
    "    pipeline = build_pipeline(config)\n",
    "    print(f\"\\nüîÑ Fitting {config.reduction_method.upper()} Pipeline...\")\n",
    "    \n",
    "    pipeline.fit(X['train'], y['train'])\n",
    "    \n",
    "    # 4. Transform & Save\n",
    "    X_processed = {\n",
    "        'train': pipeline.transform(X['train']),\n",
    "        'val':   pipeline.transform(X['val']),\n",
    "        'test':  pipeline.transform(X['test'])\n",
    "    }\n",
    "    \n",
    "    processed_dir = os.path.join(config.output_dir, \"processed_data\")\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        np.save(os.path.join(processed_dir, f\"X_{split}.npy\"), X_processed[split])\n",
    "        np.save(os.path.join(processed_dir, f\"y_{split}.npy\"), y[split])\n",
    "        \n",
    "    pipeline_path = os.path.join(config.output_dir, \"preprocessing_pipeline.joblib\")\n",
    "    joblib.dump(pipeline, pipeline_path)\n",
    "    \n",
    "    print(f\"‚úÖ Preprocessing complete. Data ready for Quantum Training.\")\n",
    "    return X_processed, y\n",
    "\n",
    "# Spu≈°tƒõn√≠ opraven√©ho kroku\n",
    "X_data, y_data = run_classical_preprocessing(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# --- 1. Modular Quantum Layers ---\n",
    "\n",
    "def get_device(config):\n",
    "    \"\"\"Creates a PennyLane device with GPU acceleration.\"\"\"\n",
    "    try:\n",
    "        # This uses NVIDIA cuQuantum for massive speedups on A100/L4\n",
    "        return qml.device(\"lightning.gpu\", wires=config.n_qubits)\n",
    "    except:\n",
    "        # Fallback if GPU is not available\n",
    "        return qml.device(\"default.qubit\", wires=config.n_qubits)\n",
    "\n",
    "def embedding_layer(features, config):\n",
    "    \"\"\"\n",
    "    Encodes a BATCH of classical data into quantum states.\n",
    "    \"\"\"\n",
    "    wires = range(config.n_qubits)\n",
    "    \n",
    "    if config.encoding_method == 'amplitude':\n",
    "        # PennyLane will detect if features has a batch dimension (e.g., shape 32, 64)\n",
    "        qml.AmplitudeEmbedding(features=features, wires=wires, normalize=True, pad_with=0.0)\n",
    "        \n",
    "    elif config.encoding_method == 'angle':\n",
    "        qml.AngleEmbedding(features=features, wires=wires, rotation='Y')\n",
    "\n",
    "def ansatz_layer(params, config):\n",
    "    \"\"\"\n",
    "    Strongly Entangling Layers:\n",
    "    More effective at capturing complex data patterns than basic CNOT rings.\n",
    "    \"\"\"\n",
    "    # Using PennyLane's built-in optimized template\n",
    "    qml.StronglyEntanglingLayers(params, wires=range(config.n_qubits))\n",
    "\n",
    "# --- 2. The QNode Builder ---\n",
    "\n",
    "def build_qnode(config):\n",
    "    dev = get_device(config)\n",
    "    \n",
    "    @qml.qnode(dev, interface=\"autograd\", diff_method=\"adjoint\", cache=True)\n",
    "    def qnode(inputs, params):\n",
    "        embedding_layer(inputs, config)\n",
    "        ansatz_layer(params, config)\n",
    "        # When inputs is batched, this returns a batch of expectation values\n",
    "        return qml.expval(qml.PauliZ(0))\n",
    "        \n",
    "    return qnode \n",
    "\n",
    "# --- 3. Training Engine ---\n",
    "\n",
    "def train_quantum_model(config, X_data, y_data):\n",
    "    \"\"\"\n",
    "    Main training loop using Autograd.\n",
    "    \"\"\"\n",
    "    print(f\"\\n‚öõÔ∏è Initializing Quantum Model ({config.n_qubits} Qubits, {config.n_layers} Layers)...\")\n",
    "    \n",
    "    # Initialize QNode\n",
    "    qnode = build_qnode(config)\n",
    "    \n",
    "    # Initialize Parameters (Random weights)\n",
    "    # Shape matching our manual ansatz: (L, N_wires, 3)\n",
    "    param_shape = qml.StronglyEntanglingLayers.shape(n_layers=config.n_layers, n_wires=config.n_qubits)\n",
    "    params = pnp.random.uniform(0, 2*np.pi, size=param_shape, requires_grad=True)\n",
    "    \n",
    "    # Optimizer\n",
    "    opt = qml.AdamOptimizer(stepsize=config.learning_rate)\n",
    "\n",
    "    def update_lr(epoch, optimizer):\n",
    "        if epoch == 15: optimizer.stepsize = 0.001\n",
    "        if epoch == 35: optimizer.stepsize = 0.0005\n",
    "        return optimizer\n",
    "    \n",
    "    # Cost Function (MSE)\n",
    "    def cost_fn(params, x_batch, y_batch):\n",
    "        preds = qnode(x_batch, params)\n",
    "        targets = pnp.array([1 if y == 1 else -1 for y in y_batch], requires_grad=False)\n",
    "        w_normal = 3.5    # Increased penalty slightly\n",
    "        w_pneumonia = 1.0 \n",
    "        batch_weights = pnp.array([w_normal if t == -1 else w_pneumonia for t in targets], requires_grad=False)\n",
    "        return pnp.mean(batch_weights * ((preds - targets) ** 2))\n",
    "\n",
    "    # Tracking\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_params = None\n",
    "    best_val_acc = 0.0 # Track Accuracy instead of Loss for saving   \n",
    "\n",
    "    # Data Setup\n",
    "    X_train, y_train = X_data['train'], y_data['train']\n",
    "    X_val, y_val = X_data['val'], y_data['val']\n",
    "    \n",
    "    batch_size = config.batch_size\n",
    "    n_batches = len(X_train) // batch_size\n",
    "\n",
    "    \n",
    "    print(f\"üöÄ Starting training for {config.epochs} epochs...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        opt = update_lr(epoch, opt)\n",
    "\n",
    "        # Shuffle\n",
    "        perm = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[perm]\n",
    "        y_train = y_train[perm]\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # Batch Loop\n",
    "        with tqdm(total=n_batches, desc=f\"Epoch {epoch+1}/{config.epochs}\", leave=False) as pbar:\n",
    "            for i in range(n_batches):\n",
    "                batch_idx = slice(i * batch_size, (i + 1) * batch_size)\n",
    "                X_batch = X_train[batch_idx]\n",
    "                y_batch = y_train[batch_idx]\n",
    "                \n",
    "                # Step\n",
    "                params, loss = opt.step_and_cost(lambda p: cost_fn(p, X_batch, y_batch), params)\n",
    "                epoch_loss += loss\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({'loss': f\"{loss:.4f}\"})\n",
    "        \n",
    "        avg_train_loss = epoch_loss / n_batches\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = cost_fn(params, X_val, y_val)\n",
    "        \n",
    "        # Val Accuracy (threshold at 0.0 because PauliZ is [-1, 1])\n",
    "        # Faster Validation in the training loop\n",
    "        val_preds_raw = qnode(X_val, params) # Pass all validation data at once if memory allows\n",
    "        val_preds = (val_preds_raw > 0).astype(int) \n",
    "        val_acc = accuracy_score(y_val, val_preds)\n",
    "        \n",
    "        history['train_loss'].append(float(avg_train_loss))\n",
    "        history['val_loss'].append(float(val_loss))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"   Epoch {epoch+1}: Train Loss {avg_train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f}\")\n",
    "        \n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_params = params.copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_params = params.copy()\n",
    "\n",
    "        if patience_counter >= config.patience:\n",
    "            print(f\"‚èπ Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "            \n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Training done in {train_time:.1f}s. Best Val Loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    return best_params, qnode, history\n",
    "\n",
    "# --- 4. Evaluation Function ---\n",
    "\n",
    "def evaluate_model(config, params, qnode, X_test, y_test):\n",
    "    print(\"\\nüìä Evaluating on Test Set...\")\n",
    "    preds_raw = np.array([qnode(x, params) for x in X_test])\n",
    "    \n",
    "    # Map [-1, 1] -> [0, 1]\n",
    "    probs = (preds_raw + 1) / 2\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, preds),\n",
    "        'f1_score': f1_score(y_test, preds, average='macro'),\n",
    "        'auc_score': roc_auc_score(y_test, probs)\n",
    "    }\n",
    "    \n",
    "    print(f\"   Test Accuracy: {metrics['accuracy']:.2%}\")\n",
    "    print(f\"   Test F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"   Test AUC:      {metrics['auc_score']:.4f}\")\n",
    "    return metrics, preds, probs\n",
    "\n",
    "# --- UPGRADE 2: Ensemble Training ---\n",
    "\n",
    "\n",
    "def train_ensemble(config, X_data, y_data, n_models=3):\n",
    "    \"\"\"\n",
    "    Trains an ensemble of quantum models by reusing train_quantummodel\n",
    "    and varying the random seed for diversity.\n",
    "    Returns:\n",
    "        - ensemble_params: list of parameter tensors (one per model)\n",
    "        - qnode: the (shared) QNode instance from the last run\n",
    "    \"\"\"\n",
    "    ensemble_params = []\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        print(f\"\\nü§ñ Training Model {i+1}/{n_models}...\")\n",
    "        \n",
    "        # Perturb the seed slightly for diversity\n",
    "        seed_everything(config.seed + i)\n",
    "        \n",
    "        # Reuse your existing quantum training function\n",
    "        # train_quantummodel(config, Xdata, ydata) -> bestparams, qnode, history\n",
    "        params, qnode, _ = train_quantummodel(config, X_data, y_data)\n",
    "        ensemble_params.append(params)\n",
    "        \n",
    "    return ensemble_params, qnode\n",
    "\n",
    "# 1. Train the Ensemble\n",
    "# Assumes Xdata and ydata are dicts: {'train': ..., 'val': ..., 'test': ...}\n",
    "ensemble_weights, qnode = train_ensemble(CFG, Xdata, ydata, n_models=3)\n",
    "\n",
    "# 2. Ensemble Prediction Function\n",
    "def predict_ensemble(X, ensemble_weights, qnode):\n",
    "    \"\"\"\n",
    "    Runs all ensemble members on a given feature set X\n",
    "    and returns averaged probabilities in [0, 1].\n",
    "    \"\"\"\n",
    "    all_probs = []\n",
    "    for params in ensemble_weights:\n",
    "        # Get raw expectations [-1, 1] for all samples in X\n",
    "        preds = np.array([qnode(x, params) for x in X])\n",
    "        # Convert to probability [0, 1]\n",
    "        probs = (preds + 1) / 2.0\n",
    "        all_probs.append(probs)\n",
    "    \n",
    "    # Shape: (n_models, n_samples) -> average over models\n",
    "    avg_probs = np.mean(all_probs, axis=0)\n",
    "    return avg_probs\n",
    "\n",
    "# 3. Evaluate Ensemble on TEST split\n",
    "print(\"\\nüó≥Ô∏è Evaluating Ensemble...\")\n",
    "X_test = Xdata[\"test\"]\n",
    "y_test = ydata[\"test\"]\n",
    "\n",
    "final_probs = predict_ensemble(X_test, ensemble_weights, qnode)\n",
    "\n",
    "# Threshold optimization loop (soft voting output)\n",
    "best_acc = 0.0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for t in np.arange(0.5, 0.95, 0.05):\n",
    "    preds_t = (final_probs > t).astype(int)\n",
    "    acc = accuracy_score(y_test, preds_t)\n",
    "    print(f\"Threshold {t:.2f} -> Accuracy {acc:.4f}\")\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"\\nüèÜ Ensemble Test Accuracy: {best_acc:.2%} at threshold {best_thresh:.2f}\")\n",
    "1\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "\n",
    "# 1. Train\n",
    "best_params, qnode, history = train_quantum_model(CFG, X_data, y_data)\n",
    "\n",
    "# 2. Evaluate\n",
    "test_metrics, test_preds, test_probs = evaluate_model(CFG, best_params, qnode, X_data['test'], y_data['test'])\n",
    "\n",
    "# 3. Save\n",
    "results_path = os.path.join(CFG.output_dir, \"quantum_results.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'config': {k: str(v) for k, v in CFG.__dict__.items()},\n",
    "        'metrics': test_metrics,\n",
    "        'history': history\n",
    "    }, f, indent=4)\n",
    "np.save(os.path.join(CFG.output_dir, \"best_params.npy\"), best_params)\n",
    "print(f\"üíæ Saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ecad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# ‚öñÔ∏è POST-PROCESSING: Threshold Optimization\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the probabilities you already generated\n",
    "# (Assuming 'test_probs' and 'y_data' are still in memory from the previous cell)\n",
    "y_test = y_data['test']\n",
    "probs = test_probs\n",
    "\n",
    "print(f\"{'Threshold':<10} | {'Acc':<8} | {'Sens.':<8} | {'Spec.':<8} | {'Balanced Acc':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_balanced_acc = 0.0\n",
    "\n",
    "for t in np.arange(0.5, 0.95, 0.05):\n",
    "    # Apply threshold\n",
    "    preds_t = (probs > t).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds_t).ravel()\n",
    "    sens = tp / (tp + fn)\n",
    "    spec = tn / (tn + fp)\n",
    "    acc = accuracy_score(y_test, preds_t)\n",
    "    bal_acc = (sens + spec) / 2\n",
    "    \n",
    "    print(f\"{t:.2f}       | {acc:.4f}   | {sens:.4f}   | {spec:.4f}   | {bal_acc:.4f}\")\n",
    "    \n",
    "    if bal_acc > best_balanced_acc:\n",
    "        best_balanced_acc = bal_acc\n",
    "        best_threshold = t\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"üèÜ Best Threshold found: {best_threshold:.2f}\")\n",
    "print(f\"   (Maximizes average of Sensitivity and Specificity)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ac3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Nastaven√≠ profesion√°ln√≠ho vzhledu graf≈Ø\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 12, 'figure.dpi': 300}) # 300 DPI pro tiskovou kvalitu\n",
    "\n",
    "def plot_training_history(history, save_dir):\n",
    "    \"\"\"\n",
    "    Vykresl√≠ v√Ωvoj chyby (Loss) a p≈ôesnosti (Accuracy) bƒõhem tr√©ninku.\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 1. Graf Chyby (Loss)\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', label='Tr√©novac√≠ chyba', linewidth=2)\n",
    "    ax1.plot(epochs, history['val_loss'], 'r--', label='Validaƒçn√≠ chyba', linewidth=2)\n",
    "    ax1.set_title('V√Ωvoj chybov√© funkce (Loss)', fontweight='bold')\n",
    "    ax1.set_xlabel('Epocha')\n",
    "    ax1.set_ylabel('Loss (MSE)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Graf P≈ôesnosti (Accuracy)\n",
    "    ax2.plot(epochs, history['val_acc'], 'g-', label='Validaƒçn√≠ p≈ôesnost', linewidth=2)\n",
    "    ax2.set_title('V√Ωvoj p≈ôesnosti na validaƒçn√≠ sadƒõ', fontweight='bold')\n",
    "    ax2.set_xlabel('Epocha')\n",
    "    ax2.set_ylabel('P≈ôesnost (0-1)')\n",
    "    ax2.set_ylim(0, 1.0)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, \"training_history.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    print(f\"üìà Graf tr√©ninku ulo≈æen: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_evaluation_metrics(y_true, y_pred, y_probs, save_dir):\n",
    "    \"\"\"\n",
    "    Vykresl√≠ Matici z√°mƒõn a ROC k≈ôivku.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 1. Matice z√°mƒõn (Confusion Matrix)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                xticklabels=['Normal', 'Pneumonia'],\n",
    "                yticklabels=['Normal', 'Pneumonia'],\n",
    "                annot_kws={\"size\": 14, \"weight\": \"bold\"})\n",
    "    ax1.set_title('Matice z√°mƒõn (Confusion Matrix)', fontweight='bold')\n",
    "    ax1.set_ylabel('Skuteƒçn√° t≈ô√≠da')\n",
    "    ax1.set_xlabel('Predikovan√° t≈ô√≠da')\n",
    "    \n",
    "    # 2. ROC K≈ôivka\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    ax2.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC k≈ôivka (AUC = {roc_auc:.2f})')\n",
    "    ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_xlabel('False Positive Rate (1 - Specificita)')\n",
    "    ax2.set_ylabel('True Positive Rate (Senzitivita)')\n",
    "    ax2.set_title('ROC K≈ôivka', fontweight='bold')\n",
    "    ax2.legend(loc=\"lower right\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, \"evaluation_metrics.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    print(f\"üìä Grafy metrik ulo≈æeny: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# --- Spu≈°tƒõn√≠ vizualizace ---\n",
    "\n",
    "# Pou≈æ√≠v√°me promƒõnn√© z p≈ôedchoz√≠ch krok≈Ø:\n",
    "# history (z kroku 5)\n",
    "# y_data['test'] (z kroku 4/5 - skuteƒçn√© hodnoty)\n",
    "# test_preds (z kroku 5 - predikovan√© 0/1)\n",
    "# test_probs (z kroku 5 - pravdƒõpodobnosti)\n",
    "\n",
    "print(f\"=== VIZUALIZACE V√ùSLEDK≈Æ PRO SOƒå ===\")\n",
    "plot_training_history(history, CFG.output_dir)\n",
    "plot_evaluation_metrics(y_data['test'], test_preds, test_probs, CFG.output_dir)\n",
    "\n",
    "# Bonus: V√Ωpis fin√°ln√≠ch ƒç√≠sel pro text pr√°ce\n",
    "cm = confusion_matrix(y_data['test'], test_preds)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nüìù Data pro tabulku v√Ωsledk≈Ø v SOƒå:\")\n",
    "print(f\"-----------------------------------\")\n",
    "print(f\"Poƒçet testovac√≠ch sn√≠mk≈Ø: {len(y_data['test'])}\")\n",
    "print(f\"TP (Spr√°vnƒõ Pneumonie):   {tp}\")\n",
    "print(f\"TN (Spr√°vnƒõ Zdrav√≠):      {tn}\")\n",
    "print(f\"FP (Fale≈°n√Ω poplach):     {fp}\")\n",
    "print(f\"FN (P≈ôehl√©dnut√° nemoc):   {fn}\")\n",
    "print(f\"-----------------------------------\")\n",
    "print(f\"Senzitivita (Recall):     {sensitivity:.4f}\")\n",
    "print(f\"Specificita:              {specificity:.4f}\")\n",
    "print(f\"AUC:                      {roc_auc_score(y_data['test'], test_probs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cceec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# üîç Single Image Evaluation\n",
    "# ==========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import pennylane as qml\n",
    "\n",
    "print(\"=== Single Image Test Mode ===\")\n",
    "img_path = input(\"Enter path to an image (.jpeg/.jpg/.png): \").strip()\n",
    "metadata_path = \"./data/features/metadata.csv\"\n",
    "\n",
    "# --- Load metadata to identify label ---\n",
    "meta = pd.read_csv(metadata_path)\n",
    "meta['image_ref'] = meta['image_path'].astype(str).str.lower()\n",
    "img_name = os.path.basename(img_path).lower()\n",
    "true_label = None\n",
    "\n",
    "for _, row in meta.iterrows():\n",
    "    if img_name in os.path.basename(row['image_ref']):\n",
    "        true_label = \"PNEUMONIA\" if int(row['label']) == 1 else \"NORMAL\"\n",
    "        break\n",
    "\n",
    "# --- Load and preprocess image ---\n",
    "img = Image.open(img_path).convert('L').resize((224,224))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"Input Image: {os.path.basename(img_path)}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "\n",
    "# --- Load same CNN as used in feature extraction ---\n",
    "model = models.resnet50(weights='IMAGENET1K_V2')\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))  # remove final FC\n",
    "model.eval()\n",
    "\n",
    "# --- Define same preprocessing as training pipeline ---\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# --- Run CNN feature extraction ---\n",
    "img_rgb = Image.open(img_path).convert('RGB')\n",
    "input_tensor = preprocess(img_rgb).unsqueeze(0)  # shape (1,3,224,224)\n",
    "with torch.no_grad():\n",
    "    features_cnn = model(input_tensor).squeeze().numpy()  # shape (2048,)\n",
    "\n",
    "img_flat = features_cnn.reshape(1, -1)\n",
    "\n",
    "\n",
    "# --- Load reducer from training (e.g., PCA joblib) ---\n",
    "reducer_path = f\"./results/{REDUCTION_METHOD}_reducer_{ACTUAL_DIMS}d.joblib\"\n",
    "if os.path.exists(reducer_path):\n",
    "    reducer = joblib.load(reducer_path)\n",
    "    img_reduced = reducer.transform(img_flat)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Reducer not found at {reducer_path}, reusing mean/std from training.\")\n",
    "    img_reduced = img_flat[:, :ACTUAL_DIMS]\n",
    "\n",
    "# --- Prepare for quantum encoding ---\n",
    "if ENCODING == \"amplitude\":\n",
    "    vec = np.zeros(2**N_QUBITS)\n",
    "    vec[:len(img_reduced[0])] = img_reduced[0]\n",
    "    q_input = vec / np.linalg.norm(vec)\n",
    "else:\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    sc = MinMaxScaler((0, 2*np.pi))\n",
    "    q_input = sc.fit_transform(img_reduced)[0]\n",
    "\n",
    "# --- Define quantum circuit ---\n",
    "dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode_predict(x, theta):\n",
    "    if ENCODING == \"amplitude\":\n",
    "        qml.AmplitudeEmbedding(x, wires=range(N_QUBITS), normalize=True, pad_with=0.0)\n",
    "    else:\n",
    "        for i, val in enumerate(x):\n",
    "            qml.RY(val, wires=i)\n",
    "    p = theta.reshape(N_LAYERS, N_QUBITS, 3)\n",
    "    for l in range(N_LAYERS):\n",
    "        for w in range(N_QUBITS):\n",
    "            qml.RX(p[l,w,0], wires=w)\n",
    "            qml.RY(p[l,w,1], wires=w)\n",
    "            qml.RZ(p[l,w,2], wires=w)\n",
    "        for w in range(N_QUBITS):\n",
    "            qml.CNOT(wires=[w, (w+1)%N_QUBITS])\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "# --- Load trained quantum parameters ---\n",
    "param_path = f\"./results/params_{ENCODING}_{REDUCTION_METHOD}{ACTUAL_DIMS}d_{N_LAYERS}L.npy\"\n",
    "if not os.path.exists(param_path):\n",
    "    raise FileNotFoundError(f\"Trained quantum parameters not found: {param_path}\")\n",
    "params_final = np.load(param_path)\n",
    "\n",
    "# --- Predict ---\n",
    "prediction = qnode_predict(q_input, params_final)\n",
    "prob_pneumonia = (1 + prediction) / 2\n",
    "pred_label = \"PNEUMONIA\" if prob_pneumonia > 0.5 else \"NORMAL\"\n",
    "\n",
    "print(\"\\nüß† Model Prediction:\")\n",
    "print(f\"  ‚Üí Predicted: {pred_label} (probability={prob_pneumonia:.3f})\")\n",
    "if true_label:\n",
    "    print(f\"  ‚Üí Actual Label: {true_label}\")\n",
    "    print(\"‚úÖ Correct!\" if pred_label == true_label else \"‚ùå Incorrect.\")\n",
    "\n",
    "plt.title(f\"Prediction: {pred_label}  |  Actual: {true_label or 'Unknown'}\")\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
