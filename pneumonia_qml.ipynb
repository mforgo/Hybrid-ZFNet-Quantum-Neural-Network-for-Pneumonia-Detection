{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3029006",
   "metadata": {
    "id": "e3029006"
   },
   "source": [
    "# Hybrid model for pneumonia detection\n",
    "## 1. Setup\n",
    "### 1.1. Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2364b28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47491,
     "status": "ok",
     "timestamp": 1760344336272,
     "user": {
      "displayName": "Michal Forg√≥",
      "userId": "03385761472197084991"
     },
     "user_tz": -120
    },
    "id": "b2364b28",
    "outputId": "6fd1cfb2-d376-4484-b1de-cb14b666b760"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pennylane in /usr/local/lib/python3.12/dist-packages (0.43.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: pennylane-qiskit in /usr/local/lib/python3.12/dist-packages (0.43.0)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6.1)\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.17.1)\n",
      "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.4.4)\n",
      "Requirement already satisfied: autoray==0.8.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.8.0)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (6.2.2)\n",
      "Requirement already satisfied: pennylane-lightning>=0.43 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.43.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
      "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
      "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: qiskit<2.2,>=2.0 in /usr/local/lib/python3.12/dist-packages (from pennylane-qiskit) (2.1.2)\n",
      "Requirement already satisfied: qiskit-aer~=0.17.1 in /usr/local/lib/python3.12/dist-packages (from pennylane-qiskit) (0.17.2)\n",
      "Requirement already satisfied: qiskit-ibm-runtime~=0.41.1 in /usr/local/lib/python3.12/dist-packages (from pennylane-qiskit) (0.41.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from pennylane-qiskit) (1.14.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning>=0.43->pennylane) (0.3.30.0.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit<2.2,>=2.0->pennylane-qiskit) (0.3.8)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit<2.2,>=2.0->pennylane-qiskit) (5.6.0)\n",
      "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer~=0.17.1->pennylane-qiskit) (5.9.5)\n",
      "Requirement already satisfied: requests-ntlm>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (1.3.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.5.0)\n",
      "Requirement already satisfied: ibm-platform-services>=0.22.6 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (0.72.0)\n",
      "Requirement already satisfied: pydantic>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.12.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->pennylane-qiskit) (1.3.0)\n",
      "Requirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
      "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.7.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: ibm_cloud_sdk_core<4.0.0,>=3.24.2 in /usr/local/lib/python3.12/dist-packages (from ibm-platform-services>=0.22.6->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (3.24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (0.4.2)\n",
      "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.12/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (43.0.3)\n",
      "Requirement already satisfied: pyspnego>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (0.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.0.0)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from ibm_cloud_sdk_core<4.0.0,>=3.24.2->ibm-platform-services>=0.22.6->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.10.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime~=0.41.1->pennylane-qiskit) (2.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane scikit-learn numpy scipy matplotlib pandas pennylane-qiskit kagglehub scikit-image seaborn pillow opencv-python torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b322fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    # Experiment Metadata\n",
    "    project_name: str = \"Hybrid_ResNet50_QNN_Pneumonia\"\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Data Paths\n",
    "    data_root: str = \"/home/mforgo/.cache/kagglehub/datasets/paultimothymooney/chest-xray-pneumonia/versions/2/chest_xray/\"\n",
    "    output_dir: str = \"./results\"\n",
    "    \n",
    "    # Classical Backbone\n",
    "    backbone_name: str = \"resnet50\"  # Fixed naming consistency\n",
    "    feature_dim: int = 2048          # 2048 for ResNet50\n",
    "    \n",
    "    # Quantum Components\n",
    "    n_qubits: int = 8                # Determined by PCA components\n",
    "    n_layers: int = 2\n",
    "    encoding_method: str = \"amplitude\" # 'amplitude' or 'angle'\n",
    "    \n",
    "    # Training Hyperparams\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 0.005\n",
    "    epochs: int = 50\n",
    "    patience: int = 10\n",
    "\n",
    "    # Preprocessing\n",
    "    reduction_method: str = \"lda\"    # 'pca' or 'lda'\n",
    "    target_dims: int = 256             # Dimensionality after reduction\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"üîí Global seed set to {seed}\")\n",
    "\n",
    "CFG = ExperimentConfig()\n",
    "seed_everything(CFG.seed)\n",
    "os.makedirs(CFG.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2d7fa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2701,
     "status": "ok",
     "timestamp": 1760344348669,
     "user": {
      "displayName": "Michal Forg√≥",
      "userId": "03385761472197084991"
     },
     "user_tz": -120
    },
    "id": "5d2d7fa4",
    "outputId": "d40499d8-9e61-4069-92d1-f48e0163d886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'chest-xray-pneumonia' dataset.\n",
      "Path to dataset files: /kaggle/input/chest-xray-pneumonia/chest_xray/\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "CFG.data_root = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\") + \"/chest_xray/\"\n",
    "print(\"Path to dataset files:\", CFG.data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485bfe7",
   "metadata": {
    "id": "2485bfe7"
   },
   "source": [
    "## 2. Hybrid model\n",
    "### 2.1. Classical preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7949166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading data from: /kaggle/input/chest-xray-pneumonia/chest_xray/\n",
      "   ‚Ä¢ TRAIN: Found 5216 images\n",
      "   ‚Ä¢ TEST: Found 624 images\n",
      "   ‚Ä¢ VAL: Found 16 images\n",
      "\n",
      "üöÄ Starting extraction with resnet50 on cuda...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fc6d3dc14a418aa577ecb759ccffae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting train:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c09a8e3cace47f1b97dd7ebee9bd1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting test:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366b76787db545dc986eea28377df25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting val:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extraction complete. Metadata saved to ./results/metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "def get_transforms(img_size=224):\n",
    "    \"\"\"\n",
    "    Standard ImageNet normalization. \n",
    "    Using standard stats ensures the pre-trained ResNet works as intended.\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_dataloaders(config):\n",
    "    \"\"\"\n",
    "    Creates DataLoaders for Train/Test/Val using ImageFolder.\n",
    "    This replaces manual os.listdir loops.\n",
    "    \"\"\"\n",
    "    loaders = {}\n",
    "    sets = ['train', 'test', 'val']\n",
    "    \n",
    "    print(f\"üìÇ Loading data from: {config.data_root}\")\n",
    "    \n",
    "    for split in sets:\n",
    "        path = os.path.join(config.data_root, split)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"‚ö†Ô∏è Warning: Split '{split}' not found at {path}\")\n",
    "            continue\n",
    "            \n",
    "        # ImageFolder automatically handles class labels based on folder names\n",
    "        dataset = datasets.ImageFolder(root=path, transform=get_transforms())\n",
    "        \n",
    "        loaders[split] = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=config.batch_size, \n",
    "            shuffle=False, # Important: Keep False to match features with filenames later\n",
    "            num_workers=2, # Parallel loading\n",
    "            pin_memory=True\n",
    "        )\n",
    "        print(f\"   ‚Ä¢ {split.upper()}: Found {len(dataset)} images\")\n",
    "        \n",
    "    return loaders\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps ResNet50 to output raw features instead of classification scores.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load modern V2 weights for better performance\n",
    "        weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "        self.backbone = models.resnet50(weights=weights)\n",
    "        \n",
    "        # Replace the final classification layer (fc) with Identity\n",
    "        # This allows us to get the 2048 feature vector directly\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.backbone.eval() # Set to evaluation mode (freezes BatchNorm)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "def run_feature_extraction(config):\n",
    "    \"\"\"\n",
    "    The Engine: Loads data, passes it through ResNet, and saves features.\n",
    "    \"\"\"\n",
    "    device = torch.device(config.device)\n",
    "    model = FeatureExtractor().to(device)\n",
    "    loaders = get_dataloaders(config)\n",
    "    \n",
    "    # Create directory for saved features\n",
    "    save_dir = os.path.join(config.output_dir, \"features\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    metadata = []\n",
    "    \n",
    "    print(f\"\\nüöÄ Starting extraction with {config.backbone_name} on {device}...\")\n",
    "    \n",
    "    with torch.no_grad(): # Disable gradient calculation for speed\n",
    "        for split, loader in loaders.items():\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(tqdm(loader, desc=f\"Extracting {split}\")):\n",
    "                images = images.to(device)\n",
    "                \n",
    "                # Forward pass: Get features (Batch_Size, 2048)\n",
    "                features = model(images).cpu().numpy()\n",
    "                \n",
    "                # Match features back to original filenames\n",
    "                # We calculate the global index based on batch size\n",
    "                start_idx = batch_idx * config.batch_size\n",
    "                \n",
    "                for i, feat in enumerate(features):\n",
    "                    global_idx = start_idx + i\n",
    "                    # Retrieve path from dataset.samples which is [(path, class_idx), ...]\n",
    "                    original_path, label_idx = loader.dataset.samples[global_idx]\n",
    "                    filename = os.path.basename(original_path)\n",
    "                    classname = loader.dataset.classes[label_idx]\n",
    "                    \n",
    "                    # Save individual feature file\n",
    "                    save_name = f\"{split}_{classname}_{filename}.npy\"\n",
    "                    save_path = os.path.join(save_dir, save_name)\n",
    "                    np.save(save_path, feat)\n",
    "                    \n",
    "                    metadata.append({\n",
    "                        'feature_path': save_path,\n",
    "                        'label': label_idx, # 0 or 1\n",
    "                        'classname': classname,\n",
    "                        'split': split,\n",
    "                        'original_path': original_path\n",
    "                    })\n",
    "    \n",
    "    # Save metadata CSV for easy loading later\n",
    "    meta_path = os.path.join(config.output_dir, \"metadata.csv\")\n",
    "    pd.DataFrame(metadata).to_csv(meta_path, index=False)\n",
    "    print(f\"‚úÖ Extraction complete. Metadata saved to {meta_path}\")\n",
    "    return meta_path\n",
    "\n",
    "# Execute the pipeline using our Config\n",
    "meta_csv_path = run_feature_extraction(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2bc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading raw features...\n",
      "\n",
      "‚ö†Ô∏è Fixing small validation set issue...\n",
      "   Original Val size: 16 -> New Val size: 1047\n",
      "   New Train size:    4185\n",
      "\n",
      "üîÑ Fitting PCA Pipeline...\n",
      "‚úÖ Preprocessing complete. Data ready for Quantum Training.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def load_features(config):\n",
    "    \"\"\"\n",
    "    Loads features from .npy files based on the metadata CSV.\n",
    "    \"\"\"\n",
    "    meta_path = os.path.join(config.output_dir, \"metadata.csv\")\n",
    "    if not os.path.exists(meta_path):\n",
    "        raise FileNotFoundError(f\"Metadata CSV not found at {meta_path}. Run Step 3 first.\")\n",
    "    \n",
    "    df = pd.read_csv(meta_path)\n",
    "    splits = ['train', 'val', 'test']\n",
    "    \n",
    "    X, y = {}, {}\n",
    "    \n",
    "    print(f\"üìÇ Loading raw features...\")\n",
    "    for split in splits:\n",
    "        subset = df[df['split'] == split]\n",
    "        features = [np.load(path) for path in subset['feature_path']]\n",
    "        X[split] = np.vstack(features)\n",
    "        y[split] = subset['label'].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def fix_validation_split(X, y, config):\n",
    "    \"\"\"\n",
    "    OPRAVA: Slouƒç√≠ Train (5216) a Val (16) a vytvo≈ô√≠ nov√© rozdƒõlen√≠ 80/20.\n",
    "    T√≠m z√≠sk√°me cca 1000 validaƒçn√≠ch sn√≠mk≈Ø m√≠sto 16.\n",
    "    \"\"\"\n",
    "    print(\"\\n‚ö†Ô∏è Fixing small validation set issue...\")\n",
    "    \n",
    "    # 1. Slouƒçen√≠\n",
    "    X_combined = np.concatenate([X['train'], X['val']])\n",
    "    y_combined = np.concatenate([y['train'], y['val']])\n",
    "    \n",
    "    # 2. Nov√© rozdƒõlen√≠ (stratify zajist√≠ spr√°vn√Ω pomƒõr t≈ô√≠d)\n",
    "    X_train_new, X_val_new, y_train_new, y_val_new = train_test_split(\n",
    "        X_combined, y_combined, \n",
    "        test_size=0.2, \n",
    "        stratify=y_combined, \n",
    "        random_state=config.seed\n",
    "    )\n",
    "    \n",
    "    # 3. Aktualizace slovn√≠k≈Ø\n",
    "    X['train'], y['train'] = X_train_new, y_train_new\n",
    "    X['val'], y['val']     = X_val_new, y_val_new\n",
    "    \n",
    "    print(f\"   Original Val size: 16 -> New Val size: {len(X_val_new)}\")\n",
    "    print(f\"   New Train size:    {len(X_train_new)}\")\n",
    "    return X, y\n",
    "\n",
    "def build_pipeline(config):\n",
    "    steps = [('scaler', StandardScaler())]\n",
    "    \n",
    "    if config.reduction_method == 'pca':\n",
    "        steps.append(('reducer', PCA(n_components=config.target_dims, random_state=config.seed)))\n",
    "    elif config.reduction_method == 'lda':\n",
    "        steps.append(('reducer', LDA(n_components=min(config.target_dims, 1))))\n",
    "    \n",
    "    if config.encoding_method == 'amplitude':\n",
    "        steps.append(('normalizer', Normalizer(norm='l2')))\n",
    "    elif config.encoding_method == 'angle':\n",
    "        steps.append(('minmax', MinMaxScaler(feature_range=(0, np.pi))))\n",
    "        \n",
    "    return Pipeline(steps)\n",
    "\n",
    "def run_classical_preprocessing(config):\n",
    "    # 1. Load Data\n",
    "    X, y = load_features(config)\n",
    "    \n",
    "    # 2. FIX DATA SPLIT (Tohle je ta kl√≠ƒçov√° oprava)\n",
    "    X, y = fix_validation_split(X, y, config)\n",
    "    \n",
    "    # 3. Build & Fit Pipeline\n",
    "    pipeline = build_pipeline(config)\n",
    "    print(f\"\\nüîÑ Fitting {config.reduction_method.upper()} Pipeline...\")\n",
    "    \n",
    "    pipeline.fit(X['train'], y['train'])\n",
    "    \n",
    "    # 4. Transform & Save\n",
    "    X_processed = {\n",
    "        'train': pipeline.transform(X['train']),\n",
    "        'val':   pipeline.transform(X['val']),\n",
    "        'test':  pipeline.transform(X['test'])\n",
    "    }\n",
    "    \n",
    "    processed_dir = os.path.join(config.output_dir, \"processed_data\")\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        np.save(os.path.join(processed_dir, f\"X_{split}.npy\"), X_processed[split])\n",
    "        np.save(os.path.join(processed_dir, f\"y_{split}.npy\"), y[split])\n",
    "        \n",
    "    pipeline_path = os.path.join(config.output_dir, \"preprocessing_pipeline.joblib\")\n",
    "    joblib.dump(pipeline, pipeline_path)\n",
    "    \n",
    "    print(f\"‚úÖ Preprocessing complete. Data ready for Quantum Training.\")\n",
    "    return X_processed, y\n",
    "\n",
    "# Spu≈°tƒõn√≠ opraven√©ho kroku\n",
    "X_data, y_data = run_classical_preprocessing(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öõÔ∏è Initializing Quantum Model (8 Qubits, 2 Layers)...\n",
      "üöÄ Starting training for 50 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6112c8f8bf452c8ebd8edf046d2675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train Loss 0.9854 | Val Loss 0.9679 | Val Acc 0.5950\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603ed93ce0f64193b76f3640693f3afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train Loss 0.8949 | Val Loss 0.7650 | Val Acc 0.7421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcddd6b00493449983d1aec3153dac2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train Loss 0.7378 | Val Loss 0.6869 | Val Acc 0.7431\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195f1e58ab6946b98fd543ecdd2131c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train Loss 0.7004 | Val Loss 0.6760 | Val Acc 0.7421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3333349f54ed416eaf895b0ec46b446f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train Loss 0.6948 | Val Loss 0.6756 | Val Acc 0.7421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71508d9490c4959a089ce2b25b3ccf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# --- 1. Modular Quantum Layers ---\n",
    "\n",
    "def get_device(config):\n",
    "    \"\"\"Creates a PennyLane device.\"\"\"\n",
    "    # Using default.qubit (CPU) which is stable for <20 qubits\n",
    "    return qml.device(\"default.qubit\", wires=config.n_qubits)\n",
    "\n",
    "def embedding_layer(features, config):\n",
    "    \"\"\"\n",
    "    Encodes classical data into quantum states.\n",
    "    \"\"\"\n",
    "    wires = range(config.n_qubits)\n",
    "    \n",
    "    if config.encoding_method == 'amplitude':\n",
    "        # Pou≈æ√≠v√°me top-level qml.AmplitudeEmbedding (nejstabilnƒõj≈°√≠ import)\n",
    "        qml.AmplitudeEmbedding(features=features, wires=wires, normalize=False, pad_with=0.0)\n",
    "        \n",
    "    elif config.encoding_method == 'angle':\n",
    "        qml.AngleEmbedding(features=features, wires=wires, rotation='Y')\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown encoding: {config.encoding_method}\")\n",
    "\n",
    "def ansatz_layer(params, config):\n",
    "    \"\"\"\n",
    "    Manual implementation of a Hardware-Efficient Ansatz.\n",
    "    Structure: Layers of arbitrary rotations (Rot) followed by a CNOT ring.\n",
    "    Replaces 'StrongEntanglingLayers' to avoid version conflicts.\n",
    "    \"\"\"\n",
    "    wires = range(config.n_qubits)\n",
    "    n_wires = config.n_qubits\n",
    "    \n",
    "    # params shape: (n_layers, n_qubits, 3)\n",
    "    for l in range(config.n_layers):\n",
    "        # 1. Parameterized Rotations (Euler angles)\n",
    "        for w in range(n_wires):\n",
    "            theta = params[l, w]\n",
    "            # Rot(phi, theta, omega)\n",
    "            qml.Rot(theta[0], theta[1], theta[2], wires=w)\n",
    "            \n",
    "        # 2. Entangling Layer (Ring CNOTs)\n",
    "        # Connect qubit i with i+1 (wrapping around)\n",
    "        for w in range(n_wires):\n",
    "            qml.CNOT(wires=[w, (w + 1) % n_wires])\n",
    "\n",
    "# --- 2. The QNode Builder ---\n",
    "\n",
    "def build_qnode(config):\n",
    "    dev = get_device(config)\n",
    "    \n",
    "    @qml.qnode(dev, interface=\"autograd\")\n",
    "    def qnode(inputs, params):\n",
    "        embedding_layer(inputs, config)\n",
    "        ansatz_layer(params, config)\n",
    "        return qml.expval(qml.PauliZ(0)) # Measuring Z expectation on first qubit\n",
    "        \n",
    "    return qnode\n",
    "\n",
    "# --- 3. Training Engine ---\n",
    "\n",
    "def train_quantum_model(config, X_data, y_data):\n",
    "    \"\"\"\n",
    "    Main training loop using Autograd.\n",
    "    \"\"\"\n",
    "    print(f\"\\n‚öõÔ∏è Initializing Quantum Model ({config.n_qubits} Qubits, {config.n_layers} Layers)...\")\n",
    "    \n",
    "    # Initialize QNode\n",
    "    qnode = build_qnode(config)\n",
    "    \n",
    "    # Initialize Parameters (Random weights)\n",
    "    # Shape matching our manual ansatz: (L, N_wires, 3)\n",
    "    param_shape = (config.n_layers, config.n_qubits, 3)\n",
    "    params = pnp.random.uniform(0, 2*np.pi, size=param_shape, requires_grad=True)\n",
    "    \n",
    "    # Optimizer\n",
    "    opt = qml.AdamOptimizer(stepsize=config.learning_rate)\n",
    "    \n",
    "    # Cost Function (MSE)\n",
    "    def cost_fn(params, x_batch, y_batch):\n",
    "        preds = [qnode(x, params) for x in x_batch]\n",
    "        preds = pnp.stack(preds)\n",
    "        # Transform labels: 0/1 -> -1/1 for PauliZ\n",
    "        targets = pnp.array([1 if y == 1 else -1 for y in y_batch], requires_grad=False)\n",
    "        return pnp.mean((preds - targets) ** 2)\n",
    "\n",
    "    # Tracking\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_params = None\n",
    "    \n",
    "    # Data Setup\n",
    "    X_train, y_train = X_data['train'], y_data['train']\n",
    "    X_val, y_val = X_data['val'], y_data['val']\n",
    "    \n",
    "    batch_size = config.batch_size\n",
    "    n_batches = len(X_train) // batch_size\n",
    "    \n",
    "    print(f\"üöÄ Starting training for {config.epochs} epochs...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        # Shuffle\n",
    "        perm = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[perm]\n",
    "        y_train = y_train[perm]\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # Batch Loop\n",
    "        with tqdm(total=n_batches, desc=f\"Epoch {epoch+1}/{config.epochs}\", leave=False) as pbar:\n",
    "            for i in range(n_batches):\n",
    "                batch_idx = slice(i * batch_size, (i + 1) * batch_size)\n",
    "                X_batch = X_train[batch_idx]\n",
    "                y_batch = y_train[batch_idx]\n",
    "                \n",
    "                # Step\n",
    "                params, loss = opt.step_and_cost(lambda p: cost_fn(p, X_batch, y_batch), params)\n",
    "                epoch_loss += loss\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({'loss': f\"{loss:.4f}\"})\n",
    "        \n",
    "        avg_train_loss = epoch_loss / n_batches\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = cost_fn(params, X_val, y_val)\n",
    "        \n",
    "        # Val Accuracy (threshold at 0.0 because PauliZ is [-1, 1])\n",
    "        val_preds_raw = np.array([qnode(x, params) for x in X_val])\n",
    "        val_preds = (val_preds_raw > 0).astype(int) \n",
    "        val_acc = accuracy_score(y_val, val_preds)\n",
    "        \n",
    "        history['train_loss'].append(float(avg_train_loss))\n",
    "        history['val_loss'].append(float(val_loss))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"   Epoch {epoch+1}: Train Loss {avg_train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f}\")\n",
    "        \n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_params = params.copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= config.patience:\n",
    "            print(f\"‚èπ Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "            \n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Training done in {train_time:.1f}s. Best Val Loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    return best_params, qnode, history\n",
    "\n",
    "# --- 4. Evaluation Function ---\n",
    "\n",
    "def evaluate_model(config, params, qnode, X_test, y_test):\n",
    "    print(\"\\nüìä Evaluating on Test Set...\")\n",
    "    preds_raw = np.array([qnode(x, params) for x in X_test])\n",
    "    \n",
    "    # Map [-1, 1] -> [0, 1]\n",
    "    probs = (preds_raw + 1) / 2\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, preds),\n",
    "        'f1_score': f1_score(y_test, preds, average='macro'),\n",
    "        'auc_score': roc_auc_score(y_test, probs)\n",
    "    }\n",
    "    \n",
    "    print(f\"   Test Accuracy: {metrics['accuracy']:.2%}\")\n",
    "    print(f\"   Test F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"   Test AUC:      {metrics['auc_score']:.4f}\")\n",
    "    return metrics, preds, probs\n",
    "\n",
    "# --- Execution ---\n",
    "\n",
    "# 1. Train\n",
    "best_params, qnode, history = train_quantum_model(CFG, X_data, y_data)\n",
    "\n",
    "# 2. Evaluate\n",
    "test_metrics, test_preds, test_probs = evaluate_model(CFG, best_params, qnode, X_data['test'], y_data['test'])\n",
    "\n",
    "# 3. Save\n",
    "results_path = os.path.join(CFG.output_dir, \"quantum_results.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'config': {k: str(v) for k, v in CFG.__dict__.items()},\n",
    "        'metrics': test_metrics,\n",
    "        'history': history\n",
    "    }, f, indent=4)\n",
    "np.save(os.path.join(CFG.output_dir, \"best_params.npy\"), best_params)\n",
    "print(f\"üíæ Saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ac3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Nastaven√≠ profesion√°ln√≠ho vzhledu graf≈Ø\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 12, 'figure.dpi': 300}) # 300 DPI pro tiskovou kvalitu\n",
    "\n",
    "def plot_training_history(history, save_dir):\n",
    "    \"\"\"\n",
    "    Vykresl√≠ v√Ωvoj chyby (Loss) a p≈ôesnosti (Accuracy) bƒõhem tr√©ninku.\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 1. Graf Chyby (Loss)\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', label='Tr√©novac√≠ chyba', linewidth=2)\n",
    "    ax1.plot(epochs, history['val_loss'], 'r--', label='Validaƒçn√≠ chyba', linewidth=2)\n",
    "    ax1.set_title('V√Ωvoj chybov√© funkce (Loss)', fontweight='bold')\n",
    "    ax1.set_xlabel('Epocha')\n",
    "    ax1.set_ylabel('Loss (MSE)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Graf P≈ôesnosti (Accuracy)\n",
    "    ax2.plot(epochs, history['val_acc'], 'g-', label='Validaƒçn√≠ p≈ôesnost', linewidth=2)\n",
    "    ax2.set_title('V√Ωvoj p≈ôesnosti na validaƒçn√≠ sadƒõ', fontweight='bold')\n",
    "    ax2.set_xlabel('Epocha')\n",
    "    ax2.set_ylabel('P≈ôesnost (0-1)')\n",
    "    ax2.set_ylim(0, 1.0)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, \"training_history.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    print(f\"üìà Graf tr√©ninku ulo≈æen: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_evaluation_metrics(y_true, y_pred, y_probs, save_dir):\n",
    "    \"\"\"\n",
    "    Vykresl√≠ Matici z√°mƒõn a ROC k≈ôivku.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 1. Matice z√°mƒõn (Confusion Matrix)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                xticklabels=['Normal', 'Pneumonia'],\n",
    "                yticklabels=['Normal', 'Pneumonia'],\n",
    "                annot_kws={\"size\": 14, \"weight\": \"bold\"})\n",
    "    ax1.set_title('Matice z√°mƒõn (Confusion Matrix)', fontweight='bold')\n",
    "    ax1.set_ylabel('Skuteƒçn√° t≈ô√≠da')\n",
    "    ax1.set_xlabel('Predikovan√° t≈ô√≠da')\n",
    "    \n",
    "    # 2. ROC K≈ôivka\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    ax2.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC k≈ôivka (AUC = {roc_auc:.2f})')\n",
    "    ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_xlabel('False Positive Rate (1 - Specificita)')\n",
    "    ax2.set_ylabel('True Positive Rate (Senzitivita)')\n",
    "    ax2.set_title('ROC K≈ôivka', fontweight='bold')\n",
    "    ax2.legend(loc=\"lower right\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, \"evaluation_metrics.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    print(f\"üìä Grafy metrik ulo≈æeny: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# --- Spu≈°tƒõn√≠ vizualizace ---\n",
    "\n",
    "# Pou≈æ√≠v√°me promƒõnn√© z p≈ôedchoz√≠ch krok≈Ø:\n",
    "# history (z kroku 5)\n",
    "# y_data['test'] (z kroku 4/5 - skuteƒçn√© hodnoty)\n",
    "# test_preds (z kroku 5 - predikovan√© 0/1)\n",
    "# test_probs (z kroku 5 - pravdƒõpodobnosti)\n",
    "\n",
    "print(f\"=== VIZUALIZACE V√ùSLEDK≈Æ PRO SOƒå ===\")\n",
    "plot_training_history(history, CFG.output_dir)\n",
    "plot_evaluation_metrics(y_data['test'], test_preds, test_probs, CFG.output_dir)\n",
    "\n",
    "# Bonus: V√Ωpis fin√°ln√≠ch ƒç√≠sel pro text pr√°ce\n",
    "cm = confusion_matrix(y_data['test'], test_preds)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nüìù Data pro tabulku v√Ωsledk≈Ø v SOƒå:\")\n",
    "print(f\"-----------------------------------\")\n",
    "print(f\"Poƒçet testovac√≠ch sn√≠mk≈Ø: {len(y_data['test'])}\")\n",
    "print(f\"TP (Spr√°vnƒõ Pneumonie):   {tp}\")\n",
    "print(f\"TN (Spr√°vnƒõ Zdrav√≠):      {tn}\")\n",
    "print(f\"FP (Fale≈°n√Ω poplach):     {fp}\")\n",
    "print(f\"FN (P≈ôehl√©dnut√° nemoc):   {fn}\")\n",
    "print(f\"-----------------------------------\")\n",
    "print(f\"Senzitivita (Recall):     {sensitivity:.4f}\")\n",
    "print(f\"Specificita:              {specificity:.4f}\")\n",
    "print(f\"AUC:                      {roc_auc_score(y_data['test'], test_probs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cceec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# üîç Single Image Evaluation\n",
    "# ==========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import pennylane as qml\n",
    "\n",
    "print(\"=== Single Image Test Mode ===\")\n",
    "img_path = input(\"Enter path to an image (.jpeg/.jpg/.png): \").strip()\n",
    "metadata_path = \"./data/features/metadata.csv\"\n",
    "\n",
    "# --- Load metadata to identify label ---\n",
    "meta = pd.read_csv(metadata_path)\n",
    "meta['image_ref'] = meta['image_path'].astype(str).str.lower()\n",
    "img_name = os.path.basename(img_path).lower()\n",
    "true_label = None\n",
    "\n",
    "for _, row in meta.iterrows():\n",
    "    if img_name in os.path.basename(row['image_ref']):\n",
    "        true_label = \"PNEUMONIA\" if int(row['label']) == 1 else \"NORMAL\"\n",
    "        break\n",
    "\n",
    "# --- Load and preprocess image ---\n",
    "img = Image.open(img_path).convert('L').resize((224,224))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"Input Image: {os.path.basename(img_path)}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "\n",
    "# --- Load same CNN as used in feature extraction ---\n",
    "model = models.resnet50(weights='IMAGENET1K_V2')\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))  # remove final FC\n",
    "model.eval()\n",
    "\n",
    "# --- Define same preprocessing as training pipeline ---\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# --- Run CNN feature extraction ---\n",
    "img_rgb = Image.open(img_path).convert('RGB')\n",
    "input_tensor = preprocess(img_rgb).unsqueeze(0)  # shape (1,3,224,224)\n",
    "with torch.no_grad():\n",
    "    features_cnn = model(input_tensor).squeeze().numpy()  # shape (2048,)\n",
    "\n",
    "img_flat = features_cnn.reshape(1, -1)\n",
    "\n",
    "\n",
    "# --- Load reducer from training (e.g., PCA joblib) ---\n",
    "reducer_path = f\"./results/{REDUCTION_METHOD}_reducer_{ACTUAL_DIMS}d.joblib\"\n",
    "if os.path.exists(reducer_path):\n",
    "    reducer = joblib.load(reducer_path)\n",
    "    img_reduced = reducer.transform(img_flat)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Reducer not found at {reducer_path}, reusing mean/std from training.\")\n",
    "    img_reduced = img_flat[:, :ACTUAL_DIMS]\n",
    "\n",
    "# --- Prepare for quantum encoding ---\n",
    "if ENCODING == \"amplitude\":\n",
    "    vec = np.zeros(2**N_QUBITS)\n",
    "    vec[:len(img_reduced[0])] = img_reduced[0]\n",
    "    q_input = vec / np.linalg.norm(vec)\n",
    "else:\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    sc = MinMaxScaler((0, 2*np.pi))\n",
    "    q_input = sc.fit_transform(img_reduced)[0]\n",
    "\n",
    "# --- Define quantum circuit ---\n",
    "dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode_predict(x, theta):\n",
    "    if ENCODING == \"amplitude\":\n",
    "        qml.AmplitudeEmbedding(x, wires=range(N_QUBITS), normalize=True, pad_with=0.0)\n",
    "    else:\n",
    "        for i, val in enumerate(x):\n",
    "            qml.RY(val, wires=i)\n",
    "    p = theta.reshape(N_LAYERS, N_QUBITS, 3)\n",
    "    for l in range(N_LAYERS):\n",
    "        for w in range(N_QUBITS):\n",
    "            qml.RX(p[l,w,0], wires=w)\n",
    "            qml.RY(p[l,w,1], wires=w)\n",
    "            qml.RZ(p[l,w,2], wires=w)\n",
    "        for w in range(N_QUBITS):\n",
    "            qml.CNOT(wires=[w, (w+1)%N_QUBITS])\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "# --- Load trained quantum parameters ---\n",
    "param_path = f\"./results/params_{ENCODING}_{REDUCTION_METHOD}{ACTUAL_DIMS}d_{N_LAYERS}L.npy\"\n",
    "if not os.path.exists(param_path):\n",
    "    raise FileNotFoundError(f\"Trained quantum parameters not found: {param_path}\")\n",
    "params_final = np.load(param_path)\n",
    "\n",
    "# --- Predict ---\n",
    "prediction = qnode_predict(q_input, params_final)\n",
    "prob_pneumonia = (1 + prediction) / 2\n",
    "pred_label = \"PNEUMONIA\" if prob_pneumonia > 0.5 else \"NORMAL\"\n",
    "\n",
    "print(\"\\nüß† Model Prediction:\")\n",
    "print(f\"  ‚Üí Predicted: {pred_label} (probability={prob_pneumonia:.3f})\")\n",
    "if true_label:\n",
    "    print(f\"  ‚Üí Actual Label: {true_label}\")\n",
    "    print(\"‚úÖ Correct!\" if pred_label == true_label else \"‚ùå Incorrect.\")\n",
    "\n",
    "plt.title(f\"Prediction: {pred_label}  |  Actual: {true_label or 'Unknown'}\")\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
