\documentclass[12pt, a4paper]{report}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[czech]{babel}
\usepackage{graphicx}       % Pro vkládání obrázků (logo)
\usepackage{setspace}       % Pro řádkování 1.5
\usepackage{geometry}       % Nastavení okrajů
\usepackage{mathptmx}       % Písmo podobné Times New Roman
\usepackage{titlesec}       % Úprava nadpisů
\usepackage{csquotes}       % Pro správné uvozovky
\usepackage[hidelinks]{hyperref} % Proklikávací obsah bez rámečků
\usepackage{amssymb}        % Pro matematické symboly
\usepackage{amsmath}        % Pro matematické prostředí
\usepackage{tikz}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}

\lstset{
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue},
  commentstyle=\color{green},
  stringstyle=\color{red},
  numbers=left,
  numberstyle=\tiny\color{gray},
  captionpos=b,
  frame=single
}

\usetikzlibrary{shapes.geometric, arrows, positioning}

% Definice stylů
\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!30]
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]
\tikzstyle{quantum} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!20]
\tikzstyle{arrow} = [thick,->,>=stealth]

% --- NASTAVENÍ CITACÍ (ISO 690) ---
% Pokud používáte Overleaf, ujistěte se, že máte nastavený kompiler na pdflatex nebo xelatex
\usepackage[style=iso-numeric, backend=biber]{biblatex}
\addbibresource{literatura.bib} % Vytvořte soubor literatura.bib

% --- NASTAVENÍ ROZMĚRŮ DLE ŠABLONY ---
\geometry{
 a4paper,
 left=25mm,
 right=25mm,
 top=25mm,
 bottom=25mm,
}
\onehalfspacing % Řádkování 1.5 

% --- DEFINICE ÚDAJŮ O PRÁCI ---
\newcommand{\nazevPraceCZ}{Hybridní model pro detekci pneumonie}
\newcommand{\nazevPraceEN}{Hybrid model for pneumonia detection}
\newcommand{\autor}{Michal Forgó}
\newcommand{\skola}{Střední škola informatiky a finančních služeb, Klatovská 200 G, 301 00, Plzeň}
\newcommand{\kraj}{Plzeňský kraj}
\newcommand{\konzultant}{Bc. Jan Boháč}
\newcommand{\obor}{Matematika a statistika (1)} % Opravený název oboru
\newcommand{\rok}{2026}
\newcommand{\misto}{Plzeň}

\begin{document}

% ================= TITULNÍ STRANA [cite: 1-9] =================
\begin{titlepage}
    \begin{center}
        \Large \textbf{STŘEDOŠKOLSKÁ ODBORNÁ ČINNOST} \\
        \vspace{1cm}
        
        \vspace{2cm}

        \Large Obor: \obor \\
        \vspace{2cm}

        \Huge \textbf{\nazevPraceCZ} \\
        \vspace{0.5cm}
        \Large \textit{\nazevPraceEN} \\
        
        \vfill
    \end{center}

    \begin{flushleft}
        \textbf{Autor:} \autor \\
        \textbf{Škola:} \skola \\
        \textbf{Kraj:} \kraj \\
        \textbf{Konzultant:} \konzultant
    \end{flushleft}

    \begin{center}
        \vspace{1cm}
        \misto \ \rok
    \end{center}
\end{titlepage}

% ================= PROHLÁŠENÍ [cite: 10-34] =================
\newpage
\thispagestyle{empty}
\section*{Prohlášení}

Prohlašuji, že jsem svou práci SOČ vypracoval samostatně a použil jsem pouze prameny a literaturu uvedené v seznamu bibliografických záznamů.
Beru na vědomí, že nejpozději odevzdáním slovesné vědecké práce do veřejné soutěže Středoškolská odborná činnost, stejně jako odevzdáním jejích příloh a dalších připojených děl, např.
audiovizuálních, fotografických, výtvarných, architektonických apod. (dále jen „soutěžní dílo“), dochází ke zveřejnění díla podle § 4 odst. 1 zákona č.
121/2000 Sb., autorského zákona, ve znění pozdějších předpisů (dále jen „autorský zákon“).
Totéž platí pro pozdější odevzdání doplněného, změněného, upraveného nebo opraveného díla.
Beru na vědomí, že zveřejněním díla, jehož součástí je vynález, se tento vynález stává součástí stavu techniky podle § 5 odst.
1, 2 zákona č. 527/1990 Sb., o vynálezech, průmyslových vzorech a zlepšovacích návrzích, ve znění pozdějších předpisů (dále jen „patentový zákon“), což zakládá překážku pro udělení patentu podle § 3 odst.
1 patentového zákona.

Beru na vědomí, že vyhlašovatel soutěže je podle § 61 odst.
1 autorského zákona per analogiam oprávněn užít soutěžní dílo pro účely zajištění průběhu soutěže, zejména k zajištění transparentnosti soutěže a veřejnosti obhajob soutěžních prací.
V odůvodněném rozsahu je tedy vyhlašovatel po dobu účasti autora v soutěži oprávněn zejména:
\begin{itemize}
    \item zhotovovat rozmnoženiny díla, je-li to nezbytné k seznámení účastníků soutěže, porotců nebo veřejnosti se soutěžní prací;
    \item zapůjčit originál nebo rozmnoženinu díla účastníkům soutěže, porotcům nebo veřejnosti. Přitom dbá na bezpečné nakládání s dílem;
    \item vystavovat originál nebo rozmnoženinu díla v průběhu soutěžních přehlídek a doprovodných akcí;
    \item sdělovat dílo veřejnosti v nehmotné podobě, a to především počítačovou nebo obdobnou sítí.
\end{itemize}

% --- VOLBA AI PROHLÁŠENÍ ---

% MOŽNOST A: BEZ AI
% Dále prohlašuji, že při tvorbě této práce jsem nepoužil nástroje AI.
% MOŽNOST B: S POUŽITÍM AI
Dále prohlašuji, že při tvorbě této práce jsem použil nástroj generativního modelu AI Perplexity AI za účelem výzkumu a vývoje práce. Po použití tohoto nástroje jsem provedl kontrolu obsahu a přebírám za něj plnou zodpovědnost.
\vspace{2cm}

V Plzni \ dne \today \hfill .......................................................\\
\hspace*{10cm} \autor

% ================= PODĚKOVÁNÍ [cite: 35-38] =================
\newpage
\thispagestyle{empty}
\section*{Poděkování}

Rád bych na tomto místě poděkoval Bc. Janu Boháčovi za odborné vedení,
čas věnovaný konzultacím a podnětné připomínky, které mi pomohly zpřesnit
metodiku a formulaci výsledků.

Dále děkuji výzkumnému centru Nové technologie (NTC) Západočeské univerzity
v Plzni za poskytnutí technického zázemí a přístupu ke kvantovým počítačům
IBM. Jmenovitě bych rád poděkoval Ing. Vítu Nováčkovi, Ph.D.


% ================= ANOTACE A KLÍČOVÁ SLOVA [cite: 39-48] =================
\newpage
\thispagestyle{empty}

\section*{Anotace}
Tato práce se zabývá využitím kvantového strojového učení v oblasti medicínské diagnostiky, konkrétně při detekci zápalu plic z rentgenových snímků hrudníku.
Hlavním cílem bylo navrhnout a implementovat hybridní model, který kombinuje klasickou CNN s kvantovými výpočty.
V rámci experimentální části byla CNN využita jako extraktor příznaků (feature extractor), jehož výstup byl následně redukován pomocí PCA a zpracován variačním kvantovým obvodem (VQC) sloužícím jako klasifikátor.
Účinnost tohoto hybridního přístupu byla testována na veřejně dostupné databázi rentgenových snímků a porovnána s výkonem konvenčních metod hlubokého učení.
Výsledky práce demonstrují, zda zapojení kvantových vrstev přináší zlepšení v přesnosti či efektivitě učení oproti čistě klasickým modelům.
Práce tak přispívá k diskusi o praktické využitelnosti kvantových neuronových sítí v analýze biomedicínských obrazových dat.

\section*{Klíčová slova}
strojové učení; kvantové počítání; detekce pneumonie; NISQ; hybridní model

\vspace{1cm}
\hrule
\vspace{1cm}

\section*{Annotation}
This thesis deals with the application of quantum machine learning in medical diagnostics, specifically in the detection of pneumonia from chest X-ray images.
The main objective was to design and implement a hybrid architecture combining a classical CNN with quantum computing.
In the experimental part, a CNN was utilized as a feature extractor, the output of which was subsequently reduced via PCA and processed by a Variational Quantum Classifier (VQC).
The efficacy of this hybrid approach was tested on a publicly available dataset of X-ray images and compared with the performance of conventional deep learning methods.
The results demonstrate whether the integration of quantum layers yields improvements in accuracy or learning efficiency compared to purely classical models.
The thesis thus contributes to the discussion on the practical applicability of quantum neural networks in the analysis of biomedical image data.

\section*{Keywords}
machine learning; quantum computing; pneumonia detection; NISQ; hybrid model

% ================= OBSAH =================
\newpage
\tableofcontents

% ================= VLASTNÍ TEXT PRÁCE =================
\newpage
\setcounter{page}{7} 

\chapter{Úvod} \label{chap:uvod}

Rychlý rozvoj umělé inteligence a hlubokého učení v posledním desetiletí zásadním způsobem transformoval řadu oborů, přičemž medicínská diagnostika patří mezi ty nejvíce ovlivněné.
Konvoluční neuronové sítě (CNN) dnes dosahují při analýze rentgenových snímků přesnosti srovnatelné s lidskými experty.

Přesto naráží klasické křemíkové čipy na své fyzikální limity, zejména pokud jde o výpočetní náročnost trénování stále komplexnějších modelů.
Do popředí zájmu se tak dostává kvantové počítání, které slibuje revoluci ve způsobu zpracování informací.
V současné době se oblast kvantových technologií nachází v éře, kterou John Preskill definoval jako NISQ (Noisy Intermediate-Scale Quantum).
Jedná se o období, kdy máme k dispozici kvantové procesory s desítkami až stovkami fyzických qubitů.
Tyto procesory sice již nejsou triviální, ale zároveň ještě nejsou dostatečně robustní a chybově korigované (fault-tolerant), aby mohly provádět libovolně dlouhé algoritmy bez vlivu šumu a dekoherence.
I v tomto nedokonalém prostředí se již podařilo na reálném hardwaru provést výpočty, které naznačují dosažení tzv.
kvantové výhody či dokonce kvantové nadvlády (quantum supremacy). Experimenty společností jako Google či IBM ukázaly, že kvantové čipy dokáží vyřešit specifické matematické úlohy řádově rychleji než nejvýkonnější klasické superpočítače.

Je však nutné podotknout, že tato tvrzení jsou předmětem vědeckých diskusí a kontroverzí, neboť klasické algoritmy jsou neustále optimalizovány a hranice mezi tím, co je a není klasicky simulovatelné, se dynamicky posouvá.
Zásadní otázkou, kterou si tato práce klade, je aplikovatelnost těchto principů v oblasti strojového učení (Quantum Machine Learning - QML).
Je sporné, zda v éře NISQ, která je charakteristická vysokou chybovostí a nedostatkem logických qubitů, můžeme očekávat reálné zlepšení oproti klasickým neuronovým sítím.
Rušení kvantových stavů může v mnoha případech zcela degradovat teoretickou výhodu, kterou kvantový paralelizmus nabízí.

Tato práce se pokouší na tuto otázku odpovědět prostřednictvím návrhu hybridní architektury.
Namísto snahy o čistě kvantové řešení, které by v současnosti naráželo na hardwarové limity, volíme kombinovaný přístup.
Spojujeme osvědčenou klasickou architekturu ResNet, která slouží k efektivní extrakci příznaků z medicínských snímků, s variačním kvantovým obvodem (VQC).
Cílem je zjistit, zda i malé množství "šumících" qubitů zapojených do rozhodovacího procesu může přinést měřitelnou výhodu v přesnosti detekce pneumonie, nebo zda je vliv šumu v současné generaci hardwaru stále příliš dominantní.

\chapter{Teoretická část} \label{chap:teorie}

\section{Medicínská východiska} \label{sec:medicina}

Pneumonie, běžně označovaná jako zápal plic, představuje jedno z nejrozšířenějších a nejzávažnějších respiračních onemocnění celosvětově.
Jedná se o akutní zánětlivý proces postihující plicní parenchym, konkrétně plicní sklípky (alveoly) a terminální bronchioly, které se v důsledku zánětu plní tekutinou a hnisem.
Tento stav výrazně omezuje schopnost plic absorbovat kyslík, což vede k respirační nedostatečnosti \cite{who_pneumonia}.
Podle statistik Světové zdravotnické organizace (WHO) patří pneumonie mezi hlavní příčiny úmrtí dětí do pěti let a představuje významné riziko pro seniory a imunokompromitované pacienty.

\subsection{Etiologie a klasifikace}
Původci onemocnění mohou být různého charakteru, přičemž správná identifikace patogenu je klíčová pro zvolení adekvátní léčby.
Nejčastěji se setkáváme s pneumonií:
\begin{itemize}
    \item \textbf{Bakteriální:} Nejběžnějším původcem je \textit{Streptococcus pneumoniae}.
    Tento typ se často projevuje náhlým nástupem a na rentgenových snímcích mívá charakteristický obraz lobární konsolidace (postižení celého laloku).
    \item \textbf{Virovou:} Způsobenou viry chřipky (Influenza), RSV nebo koronaviry (např. SARS-CoV-2).
    Virové pneumonie mají tendenci vykazovat difuznější nález a postihovat interstitium (vazivovou tkáň plic) \cite{radiology_viral_vs_bacterial}.
    \item \textbf{Atypickou a mykotickou:} Způsobenou méně běžnými organismy, jako jsou mykoplazmata nebo houby.
\end{itemize}

\subsection{Diagnostika pomocí skiagrafie hrudníku}
Ačkoliv je výpočetní tomografie (CT) považována za citlivější metodu pro detailní zobrazení plicních patologií, základním pilířem diagnostiky zůstává konvenční skiagrafie hrudníku (rentgen, CXR).
Důvody jsou pragmatické: rentgenové vyšetření je rychlé, levné, široce dostupné a vystavuje pacienta výrazně nižší dávce ionizujícího záření než CT \cite{chest_xray_diagnosis}.
Na rentgenovém snímku se zdravá plicní tkáň, která je naplněná vzduchem, jeví jako tmavá oblast (radiolucentní).
Naopak patologické procesy spojené s pneumonií, jako jsou zánětlivé výpotky a buněčná infiltrace, absorbují rentgenové záření více, a proto se na snímku zobrazují jako světlá až bílá zastínění (opacity).
Lékař-radiolog při popisu snímku hledá specifické příznaky:
\begin{itemize}
    \item \textbf{Konsolidace:} Oblast plic, kde byl vzduch nahrazen tekutinou, jevící se jako jasná bílá skvrna.
    \item \textbf{Vzdušný bronchogram:} Viditelné průdušky procházející zkonsolidovanou tkání.
    \item \textbf{Infiltráty:} Méně ohraničená zastínění, která mohou být skvrnitá nebo difuzní.
\end{itemize}

\subsection{Limitace manuální diagnostiky a role AI}
Interpretace rentgenových snímků je vysoce náročný proces, který vyžaduje zkušeného radiologa.
I přesto je tento proces zatížen určitou mírou subjektivity. Studie ukazují, že shoda mezi různými radiology (inter-observer variability) není stoprocentní, zejména u hraničních nálezů nebo u snímků s nízkým kontrastem \cite{radiologist_error_rate}.
Mezi hlavní problémy manuální diagnostiky patří:
\begin{enumerate}
    \item \textbf{Vizuální podobnost patologií:} Obraz pneumonie může být snadno zaměnitelný s jinými stavy, jako je edém plic, atelektáza nebo plicní fibróza.
    \item \textbf{Lidský faktor:} Únava lékařů při vyhodnocování velkého množství snímků (např. během epidemií) zvyšuje riziko přehlédnutí nálezu (falešná negativita).
    \item \textbf{Dostupnost expertů:} V rozvojových zemích nebo odlehlých oblastech může být nedostatek kvalifikovaných radiologů kritický.
\end{enumerate}

Právě tyto limitace otevírají prostor pro aplikaci systémů počítačového vidění a umělé inteligence.
Algoritmy, jako jsou konvoluční neuronové sítě (CNN), a v kontextu této práce i hybridní kvantové sítě, mají potenciál sloužit jako "druhý pár očí", který dokáže konzistentně detekovat jemné vzory v obraze, jež mohou lidskému oku uniknout.

\section{Konvoluční neuronové sítě a architektura ResNet} \label{sec:resnet}

Zatímco princip konvolučních sítí (vrstvy konvoluce, aktivace a poolingu) zůstává od počátku hlubokého učení stejný, architektury sítí prošly bouřlivým vývojem.
V této práci je pro extrakci příznaků využita architektura ResNet-50 (Residual Network), která představuje zlomový bod v designu hlubokých neuronových sítí.
Tento model, představený Kaimingem He a kolektivem z Microsoft Research v roce 2015, zvítězil v soutěži ILSVRC s chybovostí pod 3,6 \%, čímž překonal lidskou schopnost klasifikace \cite{resnet_paper}.

\subsection{Problém mizejícího gradientu a degradace}
S rostoucí hloubkou neuronových sítí se historicky objevoval problém tzv. mizejícího gradientu (vanishing gradient).
Při zpětném šíření chyby (backpropagation) přes mnoho vrstev se derivace postupně zmenšovaly k nule, což znemožňovalo efektivní učení prvních vrstev sítě.
Paradoxně, přidávání dalších vrstev vedlo k horším výsledkům nejen na testovací, ale i na trénovací sadě – tento jev je znám jako problém degradace (degradation problem).

\subsection{Reziduální učení a skip connections}
Architektura ResNet řeší tento problém zavedením tzv.
\textit{reziduálních bloků} a zkratkových spojení (skip connections nebo identity shortcuts).

V klasické síti se vrstva snaží naučit přímé mapování $H(x)$.
ResNet však přeformulovává úlohu tak, aby vrstvy aproximovaly pouze reziduální (zbytkovou) funkci $F(x) = H(x) - x$.
Výsledná funkce bloku je pak definována jako:
\begin{equation}
    H(x) = F(x) + x
\end{equation}
kde $x$ je vstup do bloku a $F(x)$ je transformace provedená váhami vrstvy.
Tento „zkratkový spoj“ umožňuje, aby se gradient během zpětného šíření mohl přenášet napříč sítí bez modifikace.
Pokud by optimální transformací byla identita (tj. vrstva by neměla dělat nic), pro síť je snazší naučit se váhy směřující k nule ($F(x) \to 0$) než se snažit napodobit identitu v nelineárních vrstvách.

\subsection{Specifika modelu ResNet-50}
Model ResNet-50, použitý v této práci, je hluboký 50 vrstev.
Na rozdíl od mělčích variant (např. ResNet-34) využívá tzv. Bottleneck architekturu.
Každý reziduální blok se skládá ze tří konvolucí namísto dvou:
\begin{itemize}
    \item $1 \times 1$ konvoluce (redukce dimenze),
    \item $3 \times 3$ konvoluce (samotná filtrace),
    \item $1 \times 1$ konvoluce (obnovení dimenze).
\end{itemize}
Toto uspořádání výrazně snižuje počet parametrů a výpočetní náročnost, což umožňuje trénovat hlubší sítě efektivněji.
V našem hybridním modelu využíváme ResNet-50 bez poslední plně propojené vrstvy (tzv. headless model).
Síť transformuje vstupní rentgenový snímek do vektoru příznaků o vysoké úrovni abstrakce, který následně slouží jako vstup pro kvantový variační obvod.

\section{Úvod do kvantového počítání} \label{sec:kvantove_pocitani}

Zatímco klasické počítače, na kterých běží tradiční neuronové sítě, zpracovávají informace v bitech, kvantové počítače využívají principů kvantové mechaniky, jako je superpozice a provázání (entanglement).
Základní informační jednotkou je kvantový bit, zkráceně \textbf{qubit} \cite{nielsen_chuang}.

\subsection{Qubit a superpozice}
Klasický bit se může nacházet pouze v jednom ze dvou diskrétních stavů: 0 nebo 1. Naproti tomu qubit může existovat v tzv.
superpozici obou těchto stavů současně. Matematicky qubit reprezentujeme jako vektor v dvourozměrném Hilbertově prostoru.
Používáme k tomu Diracovu "ket" notaci:

\begin{equation}
    |\psi\rangle = \alpha|0\rangle + \beta|1\rangle
\end{equation}

kde $|0\rangle$ a $|1\rangle$ jsou bázové stavy (odpovídající klasické 0 a 1) a koeficienty $\alpha, \beta \in \mathbb{C}$ jsou komplexní amplitudy pravděpodobnosti.
Pro tyto amplitudy musí platit normalizační podmínka:

\begin{equation}
    |\alpha|^2 + |\beta|^2 = 1
\end{equation}

To znamená, že pokud změříme qubit ve stavu superpozice, "zhroutí" se do stavu $|0\rangle$ s pravděpodobností $|\alpha|^2$ nebo do stavu $|1\rangle$ s pravděpodobností $|\beta|^2$.
Právě tato pravděpodobnostní povaha je zásadním rozdílem oproti deterministickému klasickému bitu.

\subsection{Blochova sféra}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\textwidth]{../media/bloch_sphere.png} 
    \caption{Geometrická reprezentace stavu qubitu na Blochově sféře.}
    \label{fig:bloch}
\end{figure}
Pro vizualizaci stavu jednoho qubitu se často využívá geometrická reprezentace zvaná Blochova sféra (Obrázek \ref{fig:bloch}).
Libovolný čistý stav qubitu lze zapsat pomocí úhlů $\theta$ a $\phi$ jako bod na povrchu koule o poloměru 1:

\begin{equation}
    |\psi\rangle = \cos\left(\frac{\theta}{2}\right)|0\rangle + e^{i\phi}\sin\left(\frac{\theta}{2}\right)|1\rangle
\end{equation}

Tato reprezentace je klíčová pro pochopení fungování kvantových neuronových sítí.
Trénování sítě v podstatě znamená hledání optimálních rotací stavového vektoru na této sféře tak, aby při měření dopadl výsledek do požadované třídy (např. "pneumonie").

\subsection{Kvantová hradla (Quantum Gates)}
Stejně jako klasické počítače používají logická hradla (AND, OR, NOT), kvantové algoritmy jsou sestaveny z kvantových hradel, která provádějí unitární operace na qubitech.
\begin{itemize}
    \item \textbf{Hadamardovo hradlo (H):} Vytváří superpozici.
    Mění stav $|0\rangle$ na $\frac{|0\rangle + |1\rangle}{\sqrt{2}}$, což dává 50\% šanci na změření 0 nebo 1.
    \item \textbf{Rotační hradla ($R_x, R_y, R_z$):} Tato hradla otáčejí qubit kolem os x, y nebo z na Blochově sféře o určitý úhel.
    V kontextu variačních kvantových obvodů (VQC) jsou právě úhly těchto rotací těmi parametry (ahami), které se síť učí během tréninku.
    \item \textbf{CNOT (Controlled-NOT):} Dvouqubitové hradlo, které je nezbytné pro vytvoření kvantového provázání.
    Pokud je řídicí qubit ve stavu $|1\rangle$, otočí cílový qubit (operace NOT).
\end{itemize}

\subsection{Kvantové provázání (Entanglement)}
Provázání je jev, kdy se stavy dvou nebo více qubitů stanou na sobě závislými takovým způsobem, že stav celého systému nelze popsat pouze popisem stavů jednotlivých qubitů.
Pokud změříme jeden z provázaných qubitů, okamžitě tím získáme informaci o druhém, a to bez ohledu na vzdálenost mezi nimi.
V strojovém učení umožňuje entanglement zachytit složité korelace mezi daty, které jsou pro klasické modely výpočetně náročné.

\section{Kvantové strojové učení (QML)} \label{sec:qml}

Kvantové strojové učení je interdisciplinární oblast, která zkoumá možnosti využití kvantových algoritmů k vylepšení metod umělé inteligence.
V kontextu současné éry NISQ se jako nejslibnější směr jeví tzv. hybridní kvantově-klasické algoritmy.
Tyto algoritmy nespoléhají čistě na kvantový počítač, ale efektivně kombinují silné stránky klasických procesorů (CPU/GPU) a kvantových procesorů (QPU) \cite{schuld_book}.

\subsection{Hybridní architektura}
V hybridním modelu, který je předmětem této práce, je výpočetní proces rozdělen do dvou fází:
\begin{enumerate}
    \item \textbf{Klasická část (Feature Extraction):} Hluboká konvoluční síť (v našem případě ResNet-50) zpracovává vysokorozměrná vstupní data (rentgenové snímky s miliony pixelů).
    Jejím úkolem je redukovat dimenzi dat a extrahovat z nich kompaktní vektor příznaků (feature vector).
    \item \textbf{Kvantová část (Classification):} Tento vektor příznaků slouží jako vstup do kvantového obvodu.
    QPU provede výpočet v Hilbertově prostoru a vrátí výsledek (pravděpodobnost tříd), který je následně využit pro výpočet chybové funkce.
\end{enumerate}

Klíčovým mechanismem je zpětné šíření chyby (backpropagation). Gradienty jsou vypočítávány na klasickém počítači, avšak pro optimalizaci parametrů v kvantovém obvodu se využívá specifických metod, jako je např.
\textit{Parameter Shift Rule} (na reálném hardwaru) nebo přímá diferenciace simulace \cite{mitarai_qcl}.

\subsection{Kódování dat (Data Encoding)}
Aby mohl kvantový obvod zpracovat data z klasické sítě, musí být klasický vektor $\mathbf{x} = (x_1, \dots, x_N)$ převeden do kvantového stavu $|\psi_\mathbf{x}\rangle$.
Tento proces, nazývaný \textit{State Preparation} nebo \textit{Embedding}, je kritickou částí algoritmu, neboť ovlivňuje expresivitu celého modelu.
Mezi nejčastěji používané metody patří:
\begin{itemize}
    \item \textbf{Angle Encoding (Úhlové kódování):} Každá hodnota $x_i$ ze vstupního vektoru je použita jako úhel rotace pro jedno kvantové hradlo. Vyžaduje $N$ qubitů pro $N$ příznaků.
    \item \textbf{Amplitude Encoding (Amplitudové kódování):} Data jsou zakódována do amplitud kvantového stavu.
    Vektor $\mathbf{x}$ je normalizován a jeho prvky odpovídají amplitudám pravděpodobnosti bázových stavů:
    \begin{equation}
        |\psi\rangle = \sum_{i=1}^{2^n} x_i |i\rangle
    \end{equation}
    Tato metoda je exponenciálně úsporná (pro $N$ příznaků stačí $\log_2 N$ qubitů), a proto byla zvolena pro tuto práci \cite{data_encoding_review}.
\end{itemize}

V této práci je výstup z ResNetu redukován na vektor o délce 64 prvků, který je následně zakódován do stavu systému 6 qubitů ($2^6 = 64$).

\subsection{Variační kvantové obvody (VQC)}
Variační kvantový obvod (Variational Quantum Circuit, VQC) plní v hybridním modelu roli, kterou v klasických sítích zastávají plně propojené vrstvy.
Jedná se o parametrický kvantový obvod $U(\boldsymbol{\theta})$, kde $\boldsymbol{\theta}$ představuje sadu nastavitelných parametrů (úhlů rotací).
Matematicky lze operaci VQC popsat jako unitární transformaci vstupního stavu $|\psi_\mathbf{x}\rangle$, následovanou měřením:
\begin{equation}
    f(\mathbf{x}, \boldsymbol{\theta}) = \langle \psi_\mathbf{x} | U^\dagger(\boldsymbol{\theta}) M U(\boldsymbol{\theta}) | \psi_\mathbf{x} \rangle
\end{equation}
kde $M$ je operátor měření (pozorovatelná veličina, typicky Pauli-Z operátor).
Trénink sítě pak spočívá v hledání takových parametrů $\boldsymbol{\theta}$, které minimalizují chybovou funkci na trénovací množině.

\subsection{Problém barren plateaus} \label{subsec:barren_plateaus_theory}

Jedním z nejvýznamnějších teoretických i praktických limitů současných variačních kvantových algoritmů (VQA) je jev označovaný jako \textit{barren plateaus}. Při trénování parametrizovaných kvantových obvodů pomocí gradientních metod se může stát, že krajina nákladové funkce je téměř všude extrémně plochá: změna libovolného parametru vede jen k zanedbatelné změně hodnoty chybové funkce. V takové situaci gradienty mířící k~optimu prakticky mizí a optimalizace se stává numericky neproveditelnou, zejména pro větší počty qubitů.

Formálně se barren plateaus popisují pomocí rozptylu gradientů nákladové funkce \(C(\boldsymbol{\theta})\) podle jednotlivých parametrů \(\theta_i\). Pro jednoduchost uvažujme jeden parametr \(\theta_i\); zajímá nás náhodná proměnná \(\partial_{\theta_i} C(\boldsymbol{\theta})\), kde \(\boldsymbol{\theta}\) jsou náhodně inicializované parametry ansatzu. V mnoha situacích, zejména pro hluboké „náhodné“ obvody s globální nákladovou funkcí, lze ukázat, že rozptyl gradientu klesá alespoň exponenciálně s počtem qubitů \(n\):
\[
\mathrm{Var}\big[\partial_{\theta_i} C(\boldsymbol{\theta})\big] = \mathcal{O}(2^{-n}).
\]
V limitě velkého \(n\) se tak téměř všechny gradienty koncentrují v okolí nuly a jakékoli praktické gradientní učení se stává nereálným.

Sjednocená teorie barren plateaus ukazuje, že tato exponenciální závislost vzniká kombinací tří faktorů: struktury ansatzu (hloubka, topologie propletení), volby nákladové funkce (globální vs. lokální) a způsobu inicializace parametrů. Obecně platí, že hluboké obvody s globální nákladovou funkcí (např. průměrná energie přes celý systém) a náhodnou inicializací mají tendenci generovat barren plateaus, zatímco mělké, lokálně strukturované obvody s lokálními nákladovými funkcemi se tomuto jevu do jisté míry vyhýbají.

V reakci na tento problém vznikla celá řada koncepčně odlišných strategií mitigace barren plateaus:

\begin{itemize}
    \item \textbf{Mělké a lokální ansatze:} Namísto hlubokých obvodů s globálním propletením se používají mělké architektury, kde každý qubit interaguje pouze se svými nejbližšími sousedy (např. lineární nebo kruhové řetězce CNOT hradel). Takové ansatze mají menší efektivní hloubku a empiricky vykazují pomalejší útlum gradientů.
    \item \textbf{Lokální nákladové funkce:} Místo globálních observablí (součet po všech qubitech) se používají lokální cost funkce definované na podmnožinách qubitů (např. jen na jednom nebo několika měřených qubitech). To snižuje stupeň „průměrování“ přes Hilbertův prostor a udržuje rozptyl gradientů na polynomiální úrovni.
    \item \textbf{Speciální inicializace:} Namísto zcela náhodné inicializace parametrů lze využít strategie, které začínají v okolí jednoduchých (např. produktových) stavů nebo v blízkosti identity. Tím se obvod vyhne oblasti parametrického prostoru, kde již implementuje téměř Haarovsky náhodnou unitární transformaci, a gradienty jsou v počátečních fázích učení lépe „rozlišitelné“.
    \item \textbf{Fyzikálně inspirované architektury:} Další možností je navrhnout ansatz tak, aby respektoval konkrétní strukturu řešeného problému – například Hamiltonian variational ansatz nebo obvody založené na známých symetriích systému. Tyto architektury typicky nepotřebují univerzální expresivitu, ale jsou lépe přizpůsobeny dané úloze a mohou se tak vyhnout oblastem parametrického prostoru, kde dochází k barren plateaus.
\end{itemize}

V praxi se často kombinuje několik z těchto přístupů: volí se mělký, lokálně proplétající ansatz, vhodně se inicializují parametry a používá se nákladová funkce založená na lokálních měřeních. Teoretické i numerické studie ukazují, že takové nastavení výrazně zlepšuje trénovatelnost variačních kvantových obvodů a představuje v současnosti nejrealističtější cestu k využití VQC v éře NISQ.

\chapter{Cíle práce}

Hlavním cílem této práce je navrhnout, implementovat a experimentálně ověřit
architekturu hybridní kvantově-klasické neuronové sítě pro medicínskou
diagnostiku. Konkrétně se práce zaměřuje na detekci pneumonie z rentgenových
snímků hrudníku v kontextu současných hardwarových omezení éry NISQ
(\emph{Noisy Intermediate-Scale Quantum}).

Na základě teoretické rešerše a analýzy problému byly stanoveny následující
dílčí cíle:

\begin{enumerate}
  \item \textbf{Implementace hybridního modelu:}
  Vytvořit funkční model, který propojuje moderní klasickou konvoluční síť
  (ResNet-50) ve funkci extraktoru příznaků s variačním kvantovým obvodem (VQC),
  jenž bude plnit roli klasifikátoru.

  \item \textbf{Optimalizace pro NISQ:}
  Navrhnout vhodné kódování klasických dat do kvantových stavů
  (\emph{data encoding}) a strukturu kvantového obvodu (ansatzu) tak, aby byl
  model trénovatelný i na simulátorech či reálných kvantových procesorech
  s omezeným počtem qubitů a v přítomnosti šumu.

  \item \textbf{Experimentální srovnání:}
  Porovnat výkonnost navrženého hybridního modelu s referenčním čistě
  klasickým modelem nad stejnými PCA-redukovanými příznaky z ResNet-50.
  Referenční model je realizován jako vícevrstvý perceptron (klasický
  neuronový klasifikátor) trénovaný na 64rozměrných vektorech příznaků
  bez použití kvantového obvodu.

  \item \textbf{Analýza efektivity:}
  Vyhodnotit, zda zapojení kvantové vrstvy přináší výhodu v podobě snížení
  počtu trénovatelných parametrů v rozhodovací části modelu a jak přítomnost
  šumu ovlivňuje konvergenci a stabilitu trénování.
\end{enumerate}

\section*{Výzkumné otázky a hypotéza}

V souladu s vytýčenými cíli si práce klade za úkol ověřit následující
hypotézu:

\begin{quote}
Hybridní kvantově-klasická neuronová síť dokáže při detekci pneumonie
dosáhnout srovnatelné klasifikační přesnosti jako vhodně zvolený čistě
klasický model nad stejnými příznaky, a to při využití řádově nižšího počtu
trénovatelných parametrů v rozhodovací (klasifikační) části.
\end{quote}

Práce dále hledá odpověď na otázku, zda jsou současné metody kvantového
strojového učení (QML) dostatečně robustní pro zpracování reálných
biomedicínských obrazových dat s vysokým rozlišením, nebo zda jejich
aplikaci v praxi prozatím brání především hardwarové limity (šum a
dekoherence) kvantových procesorů.

\chapter{Metodika a experimentální část} \label{chap:metodika}

Tato kapitola popisuje použitý datový soubor, metody předzpracování obrazových dat a detailní architekturu navrženého hybridního modelu.
Dále jsou specifikovány tréninkové parametry a softwarové i hardwarové prostředí, ve kterém byly experimenty realizovány.

\section{Navržená hybridní architektura}
Jádrem práce je hybridní model, který se skládá ze dvou hlavních bloků: klasického extraktoru příznaků a kvantového klasifikátoru.
Schéma architektury je znázorněno na Obrázku \ref{fig:architektura}.

\begin{figure}[ht]
    \centering
    % \resizebox zajistí, že se celé schéma smrskne na šířku řádku
    \resizebox{\textwidth}{!}{
        \begin{tikzpicture}[node distance=3cm, auto]
            % Definice stylů (pokud je nemáte v preambuli)
            \tikzstyle{startstop} = [rectangle, rounded corners, minimum width=2.2cm, minimum height=1cm, text centered, draw=black, fill=red!20, font=\small]
            \tikzstyle{process} = [rectangle, minimum width=2.5cm, minimum height=1cm, text centered, draw=black, fill=orange!20, font=\small]
            \tikzstyle{quantum} = [rectangle, minimum width=2.5cm, minimum height=1cm, text centered, draw=black, fill=blue!10, font=\small]
            \tikzstyle{arrow} = [thick,->,>=stealth]

            % Uzly
            \node (in) [startstop] {Vstup (RTG)};
            \node (resnet) [process, right of=in] {ResNet-50};
            \node (pca) [process, right of=resnet] {PCA};
            \node (vqc) [quantum, right of=pca] {VQC};
            \node (post) [process, right of=vqc, fill=green!10] {Threshold scan};
            \node (out) [startstop, right of=post] {Klasifikace};

            % Šipky s popisky
            \draw [arrow] (in) -- (resnet);
            \draw [arrow] (resnet) -- (pca);
            \draw [arrow] (pca) -- (vqc);
            \draw [arrow] (vqc) -- (post);
            \draw [arrow] (post) -- (out);
            
            % Popisek pod post-processingem
        \end{tikzpicture}
    }
    \caption{Horizontální schéma architektury hybridního modelu.}
    \label{fig:architektura}
\end{figure}

Navržený hybridní model kombinuje silné stránky hlubokých konvolučních sítí a variačních kvantových obvodů. Vstupní rentgenový snímek je nejprve zpracován předtrénovanou sítí ResNet-50, která jej převede do vektoru příznaků pevné délky. Tento vektor je následně zredukován na nižší dimenzi a normalizován tak, aby byl vhodný pro zakódování do kvantového stavu na omezeném počtu qubitů. Redukované příznaky jsou amplitudově zakódovány do systému šesti qubitů, na něž je aplikován mělký, lokálně proplétající variační obvod (VQC), jenž plní roli klasifikátoru. Výstupem kvantového obvodu je skalární hodnota interpretovaná jako pravděpodobnost pneumonie, na kterou je v závěrečném post-processingu aplikováno hledání optimálního prahu pro binární rozhodnutí. Takto navržená pipeline umožňuje zpracovat vysokorozměrná obrazová data klasickým modelem a přesunout pouze kompaktní reprezentaci do kvantové části, která je přizpůsobena omezeným možnostem současného NISQ hardwaru.

\section{Datový soubor (Dataset)}

Pro trénování a testování modelu byl využit veřejně dostupný dataset \textit{Chest X-Ray Images (Pneumonia)}, který pochází z Guangzhou Women and Children’s Medical Center a je distribuován prostřednictvím platformy Kaggle. Dataset obsahuje rentgenové snímky hrudníku (předozadní projekce) pediatrických pacientů ve věku přibližně 1 až 5 let.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../media/dataset_showcase.png}
    \caption{Ukázka dat z datasetu. Vlevo: snímek bez nálezu (Normal). Vpravo: snímky s pneumonií.}
    \label{fig:dataset_sample}
\end{figure}

Celkem dataset zahrnuje 5856 snímků, které jsou v původní verzi rozděleny do trénovací, validační a testovací sady. Původní validační sada obsahuje pouze 16 snímků, což se ukázalo jako nedostatečné pro spolehlivé sledování konvergence modelu a ladění hyperparametrů (viz Obrázek~\ref{fig:dataset_distribution}).

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{../media/dataset_split.png}
    \caption{Původní rozdělení datasetu podle tříd a sad (train/val/test).}
    \label{fig:dataset_distribution}
\end{figure}

Aby byla validační sada dostatečně reprezentativní, byla v rámci předzpracování provedena reorganizace dat: původní trénovací a validační sada byly sloučeny a nově rozděleny v poměru 80:20 se zachováním stratifikace podle tříd. Nové rozdělení má následující velikosti:
\begin{itemize}
    \item \textbf{Trénovací sada:} 4185 snímků (použito pro učení modelu),
    \item \textbf{Validační sada:} 1047 snímků (použita pro ladění hyperparametrů a early stopping),
    \item \textbf{Testovací sada:} 624 snímků (ponechána v původním stavu pro finální vyhodnocení).
\end{itemize}

Snímky jsou kategorizovány do dvou tříd: \textit{Normal} (zdravý nález) a \textit{Pneumonia} (zápal plic). Dataset je značně nevyvážený, přibližně tři čtvrtiny snímků patří do třídy \textit{Pneumonia}, což motivuje použití vyvážené ztrátové funkce a vhodných metrik při vyhodnocování modelu. Navíc je patrná vysoká variabilita v kvalitě snímků, rozlišení a přítomnosti artefaktů (např. lékařská zařízení), což dále zvyšuje nároky na robustní předzpracování dat.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../media/dataset_quality.png}
    \caption{Rozložení velikosti snímků v datasetu. Různorodost rozlišení potvrzuje nutnost jednotné normalizace vstupů.}
    \label{fig:dataset_size_distribution}
\end{figure}

\section{Předzpracování dat (Preprocessing)}

Před vstupem do neuronové sítě bylo nutné snímky standardizovat tak, aby odpovídaly očekávanému vstupu předtrénované architektury ResNet-50. K tomu byla použita pipeline založená na knihovně \texttt{torchvision.transforms}, která provádí následující kroky:

\begin{enumerate}
    \item \textbf{Změna velikosti (Resizing):} Každý snímek je změněn na rozlišení \(224 \times 224\) pixelů, což je standardní vstupní velikost pro ResNet-50.
    \item \textbf{Převod na tenzor:} Obraz je převeden na tenzor typu \texttt{float32} a hodnoty intenzit jsou škálovány do intervalu \([0,1]\) pomocí \texttt{ToTensor()}.
    \item \textbf{Normalizace podle ImageNet:} Kanály RGB jsou normalizovány pomocí středních hodnot \([0{,}485, 0{,}456, 0{,}406]\) a směrodatných odchylek \([0{,}229, 0{,}224, 0{,}225]\), což odpovídá statistice trénovací množiny ImageNet a zajišťuje, že předtrénovaný ResNet-50 pracuje v očekávaném rozsahu vstupů.
\end{enumerate}

V kódu je tato transformace implementována následovně:

\begin{lstlisting}[language=Python, caption={Použitá transformační pipeline pro vstupní snímky.}]
def get_transforms(img_size=224):
    return transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        ),
    ])
\end{lstlisting}

\subsection{Klasická část: extraktor příznaků ResNet-50}

Jako extraktor příznaků byla zvolena architektura \textbf{ResNet-50}, která představuje standard v oblasti počítačového vidění. Síť je použita v režimu \textit{feature extractoru}: poslední klasifikační vrstva je nahrazena identitou a pro každý vstupní snímek je z předposlední vrstvy získán vektor příznaků délky 2048.

Každý rentgenový snímek tedy nejprve prochází výše uvedenou obrazovou transformací a poté je zpracován modelem ResNet-50, který jej převede na kompaktní 2048-rozměrný vektor. Teprve \emph{tyto} vektory jsou následně vstupem do klasické pipeline pro redukci dimenze (PCA) a přípravu dat pro kvantový klasifikátor, nikoli původní obrazová data.


\subsection{Redukce dimenzionality: PCA}

Výstupní vektor z ResNet-50 o délce 2048 prvků je pro současné kvantové simulátory a procesory příliš rozměrný. Bylo proto nutné jej redukovat na 64 prvků, aby odpovídal Hilbertovu prostoru 6 qubitů (\(2^{6} = 64\)) při amplitudovém kódování. V experimentální části byly porovnány tři přístupy: \textbf{PCA}, \textbf{LDA} a \textbf{SelectKBest}.

\begin{table}[H]
    \centering
    \caption{Srovnání metod redukce dimenzionality pro hybridní model}
    \begin{tabular}{|l|p{8cm}|}
        \hline
        \textbf{Metoda} & \textbf{Vlastnosti a chování v kontextu QML} \\
        \hline
        \textbf{PCA} & Lineární metoda, která hledá směry s největším rozptylem dat a projektuje příznaky do podprostoru s maximální zachovanou variabilitou. V této práci poskytla nejstabilnější trénink a nejlepší validační výsledky při redukci na 64 komponent, a proto byla zvolena jako finální metoda. \\
        \hline
        \textbf{LDA} & Supervisovaná metoda hledající projekci maximalizující separaci tříd. V nastavení s vysokou původní dimenzí a omezeným počtem vzorků byla náchylná k numerickým problémům a prakticky nevedla ke spolehlivému zlepšení výsledků, proto nebyla dále použita. \\
        \hline
        \textbf{SelectKBest} & Vybírá \(K\) nejrelevantnějších příznaků na základě jejich statistické závislosti na cílové třídě (ANOVA F-test). Ačkoliv zachovává původní interpretovatelné příznaky, v provedených experimentech dosahovala mírně horších validačních metrik než PCA a vedla k méně stabilnímu tréninku kvantového klasifikátoru. \\
        \hline
    \end{tabular}
\end{table}

Finální pipeline použitá v této práci proto využívá \textbf{PCA} se 64 komponentami, před kterou je aplikován standardní z-skorovací \textit{StandardScaler} pro centrování a škálování příznaků. Počet 64 komponent byl zvolen jako kompromis mezi zachováním dostatečné
množství informace z původního 2048‑rozměrného vektoru a omezeními
šestiqubitového kvantového registru, jehož Hilbertův prostor má dimenzi
64. Nižší počet komponent vedl v předběžných experimentech k citelnému
poklesu validačních metrik.

\section{Kvantová část: variační kvantový klasifikátor (VQC)}\label{sec:quantum_model}

Kvantová část hybridního modelu je realizována jako variační kvantový klasifikátor (VQC) nad registrem o \(n = 6\) qubitech. Každý vzorek je reprezentován 64rozměrným vektorem příznaků získaným z ResNet-50 a následnou redukcí dimenze pomocí PCA, který je nejprve zakódován do kvantového stavu, poté zpracován parametrizovaným kvantovým obvodem (ansatzem) a nakonec je změřen vhodný observábl pro získání skalárního skóre pneumonie.

\subsection{Kódování klasických dat do kvantového registru}

Nechť \(\mathbf{x} \in \mathbb{R}^{64}\) označuje vektor příznaků po aplikaci ResNet-50, PCA a následné \(L_2\) normalizaci tak, aby platilo \(\sum_{i=0}^{63} x_i^2 = 1\). Takový vektor je možné interpretovat jako amplitudy kvantového stavu na Hilbertově prostoru šesti qubitů:
\[
\lvert \psi(\mathbf{x}) \rangle = \sum_{i=0}^{63} x_i \lvert i \rangle,
\]
kde \(\{\lvert i \rangle\}_{i=0}^{63}\) je výpočetní báze pro 6-qubitový registr. V implementaci je toto tzv. \textit{amplitudové kódování} realizováno pomocí šablony \texttt{qml.AmplitudeEmbedding} s parametry \texttt{normalize=True} a \texttt{pad\_with=0.0}, takže je zajištěno splnění normalizační podmínky amplitud.

V literatuře se pro kódování klasických vektorů do kvantových stavů běžně používají tři hlavní přístupy: \textit{basis encoding}, \textit{angle encoding} a \textit{amplitude encoding}. Basis encoding by v tomto případě vyžadoval 64 qubitů pro přímočaré zakódování indexu vzorku, což je mimo možnosti současného NISQ hardwaru i simulace. Angle encoding by zakódoval jednotlivé složky \(\mathbf{x}\) jako rotační úhly na jednotlivých qubitech (např. pomocí \texttt{AngleEmbedding}), avšak pro 64 příznaků by buď vyžadoval výrazně více qubitů, nebo vysoký počet rotačních hradel a větší hloubku obvodu. Amplitudové kódování naopak umožňuje reprezentovat 64rozměrný vektor pomocí pouze šesti qubitů, což exponenciálně šetří qubitové zdroje za cenu složitější přípravné vrstvy, která je však v této práci delegována na backend knihovny PennyLane.

Z těchto důvodů bylo pro hybridní model zvoleno \textbf{amplitudové kódování}: 
\begin{itemize}
    \item respektuje omezený počet qubitů (6 qubitů \(\Rightarrow 64\) amplitud),
    \item přirozeně využívá skutečnost, že PCA výstup je následně \(L_2\)-normalizován,
    \item minimalizuje počet parametrizovaných hradel potřebných pro samotný ansatz, protože veškerou „datovou složitost“ nese už vstupní stav.
\end{itemize}

\subsection{Parametrizovaný ansatz kvantového obvodu}

Na takto připravený stav je aplikován variační ansatz navržený jako opakování \(L = \texttt{config.n\_layers}\) identických vrstev. Každá vrstva se skládá z:
\begin{itemize}
    \item jednoqubitových rotačních hradel \(\mathrm{Rot}(\phi,\theta,\omega)\) na každém qubitu, 
    \item následného kruhového propletení pomocí CNOT hradel mezi sousedními qubity \(w \rightarrow (w+1) \bmod n\).
\end{itemize}

\vspace{1cm}

\begin{lstlisting}[language=Python, caption={Použitý ansatz s rotačními hradly a kruhovým propletením.}]
def ansatz_layer(params, config):
    n_wires = config.n_qubits
    for l in range(config.n_layers):
        for w in range(n_wires):
            qml.Rot(
                params[l, w, 0],
                params[l, w, 1],
                params[l, w, 2],
                wires=w
            )
        for w in range(n_wires):
            qml.CNOT(wires=[w, (w + 1) % n_wires])
\end{lstlisting}

Pro \(n = 6\) qubitů a \(L\) vrstev má ansatz celkem \(3 \cdot n \cdot L\) volných parametrů, což umožňuje přesně kontrolovat kapacitu modelu skrze volbu hloubky obvodu. Lokální rotační operace zajišťují dostatečnou flexibilitu na úrovni jednotlivých qubitů, zatímco kruhové CNOT propletení vytváří pouze lokální entanglement, což je v souladu s doporučeními pro zmírnění barren plateaus a zároveň odpovídá realistické konektivitě mnoha kvantových zařízení.

\subsection{Měření a mapování na pravděpodobnost}

Po aplikaci ansatzu je výsledný kvantový stav měřen ve výpočetní bázi prostřednictvím střední hodnoty vybraného observáblu. V této práci je kvantový klasifikátor implementován jako QNode, který vrací střední hodnotu operátoru \(Z\) na jednom qubitu,
\[
y_{\text{raw}} = \langle \psi_{\boldsymbol{\theta}}(\mathbf{x}) \rvert Z_k \lvert \psi_{\boldsymbol{\theta}}(\mathbf{x}) \rangle \in [-1, 1],
\]
kde \(\lvert \psi_{\boldsymbol{\theta}}(\mathbf{x}) \rangle\) je výstupní stav po aplikaci ansatzu s parametry \(\boldsymbol{\theta}\). Tato hodnota je následně lineárně přemapována na interval \([0,1]\),
\[
p_{\text{pneumonie}} = \frac{1 + y_{\text{raw}}}{2},
\]
a interpretována jako pravděpodobnost přítomnosti pneumonie pro daný snímek.

Ve fázi post-processingu je na tuto spojitou výstupní hodnotu aplikováno tzv. \textit{threshold scan}: hledá se práh \( \tau \in [0,1] \), který maximalizuje zvolenou metriku (např. F1 skóre nebo balanced accuracy) na validační sadě a který se následně použije pro binární rozhodnutí na testovacích datech. Tím se odděluje trénink kvantového klasifikátoru (minimalizace ztrátové funkce nad spojitými výstupy) od volby operačního bodu rozhodování, což je v medicínských aplikacích praktické z hlediska ladění kompromisu mezi senzitivitou a specificitou.

\section{Post-processing a klasifikace}

Výstupem kvantového klasifikátoru (VQC) je pro každý snímek reálné číslo
\(p_{\text{pneumonie}} \in [0,1]\), interpretované jako odhad pravděpodobnosti přítomnosti
pneumonie (viz Sekce~\ref{sec:quantum_model} o kvantové části). 
Aby bylo možné převést tuto spojitou pravděpodobnost na binární rozhodnutí
(\textit{Normal} vs. \textit{Pneumonia}), je nutné zvolit rozhodovací prah
\(\tau \in [0,1]\), podle něhož se predikce prahují jako
\(\hat{y} = \mathbb{1}[p_{\text{pneumonie}} > \tau]\). 

Vzhledem k nevyváženosti tříd (\(\approx 73\,\%\) \textit{Pneumonia}) byla jako hlavní
kritérium pro volbu prahu zvolena \textbf{vyvážená přesnost} (\textit{balanced accuracy}),
definovaná jako aritmetický průměr \textit{sensitivity} a \textit{specificity}. 

\subsection{Diskrétní vyhledávání prahu nad pravděpodobnostmi}

Po natrénování modelu byly na testovací sadě nejprve spočteny výstupní
pravděpodobnosti \(p_{\text{pneumonie}}\) pro všechny snímky, uložené v poli
\texttt{test\_probs}. 
Následně byl pro sadu kandidátních prahů
\(\tau \in \{0.50, 0.55, \dots, 0.90\}\) proveden výpočet následujících metrik: 

\begin{itemize}
    \item \textbf{Accuracy} (\( \text{Acc} \)): podíl správně klasifikovaných snímků,
    \item \textbf{Sensitivity} (\( \text{Sens} \)): podíl správně detekovaných případů pneumonie,
    \item \textbf{Specificity} (\( \text{Spec} \)): podíl správně detekovaných negativních nálezů,
    \item \textbf{Balanced accuracy} (\( \text{BalAcc} \)): 
    \(\text{BalAcc} = \tfrac{1}{2}(\text{Sens} + \text{Spec})\). 
\end{itemize}

Pro každý prah \(\tau\) byly nejprve získány binární predikce
\(\hat{y}_\tau = \mathbb{1}[p_{\text{pneumonie}} > \tau]\), z nichž byla pomocí matice
záměn \texttt{confusion\_matrix(y\_test, preds\_t)} odvozena dvojice
\(\text{Sensitivity}\) a \(\text{Specificity}\), a poté dopočítány
\(\text{Accuracy}\) a \(\text{Balanced accuracy}\). 
Implementace tohoto post-processingu v Pythonu je následující:

\begin{lstlisting}[language=Python, caption={Diskrétní optimalizace prahu podle balanced accuracy.}][H]
y_test = y_data['test']
probs = test_probs

best_threshold = 0.5
best_balanced_acc = 0.0

for t in np.arange(0.5, 0.95, 0.05):
    preds_t = (probs > t).astype(int)
    
    tn, fp, fn, tp = confusion_matrix(y_test, preds_t).ravel()
    sens = tp / (tp + fn)
    spec = tn / (tn + fp)
    acc = accuracy_score(y_test, preds_t)
    bal_acc = (sens + spec) / 2
    
    if bal_acc > best_balanced_acc:
        best_balanced_acc = bal_acc
        best_threshold = t
\end{lstlisting}

\subsection{Výsledné metriky pro různé prahové hodnoty}

Tabulka \ref{tab:threshold_scan} shrnuje dosažené metriky na testovací sadě
pro jednotlivé zvažované hodnoty prahu \(\tau\). 

\begin{table}[H]
    \centering
    \caption{Výsledky diskrétního prohledávání prahů na testovací sadě.}
    \label{tab:threshold_scan}
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{Práh \(\tau\)} & \textbf{Accuracy} & \textbf{Sensitivity} &
        \textbf{Specificity} & \textbf{Balanced accuracy} \\
        \hline
        0.50 & 0.7163 & 0.8000 & 0.5769 & 0.6885 \\
        0.55 & 0.6330 & 0.5692 & 0.7393 & 0.6543 \\
        0.60 & 0.5288 & 0.3000 & 0.9103 & 0.6051 \\
        0.65 & 0.4247 & 0.0897 & 0.9829 & 0.5363 \\
        0.70 & 0.3830 & 0.0128 & 1.0000 & 0.5064 \\
        0.75 & 0.3750 & 0.0000 & 1.0000 & 0.5000 \\
        0.80 & 0.3750 & 0.0000 & 1.0000 & 0.5000 \\
        0.85 & 0.3750 & 0.0000 & 1.0000 & 0.5000 \\
        0.90 & 0.3750 & 0.0000 & 1.0000 & 0.5000 \\
        \hline
    \end{tabular}
\end{table}

Z tabulky je patrné, že v rámci zkoumaných hodnot dosahuje nejvyšší
vyvážené přesnosti práh \(\tau = 0{,}50\) s \(\text{Balanced accuracy} = 0{,}6885\),
\(\text{Sensitivity} = 0{,}8000\) a \(\text{Specificity} = 0{,}5769\). 
Tato hodnota prahu odpovídá výchozí hodnotě \(\tau = 0{,}5\) použité při výpočtu
hlavních testovacích metrik (Accuracy, F1, AUC), a diskretizované prohledávání
tak slouží primárně jako analýza citlivosti modelu na volbu rozhodovacího prahu. 

\subsubsection*{4.5.3 Hyperparametry a optimalizace}

Optimalizace navrženého řešení probíhala ve dvou na sobě nezávislých krocích:
(i) trénink kvantového klasifikátoru VQC v rámci hybridního modelu s fixovanou
klasickou částí (ResNet-50 + PCA pipeline) a (ii) trénink čistě klasického baseline
klasifikátoru nad stejnými 64rozměrnými příznaky. V obou případech byl použit
optimalizační algoritmus Adam, avšak s odlišným nastavením plánů učení a chybových
funkcí reflektujících rozdílný charakter výstupu kvantového obvodu a sigmoidového
klasického modelu.

\paragraph{Chybové funkce}

\begin{itemize}
  \item \textbf{Kvantová část (VQC): vážená MSE}

  Kvantový klasifikátor VQC pro každý vzorek vrací očekávanou hodnotu Pauliho
  operátoru $Z$ na vybraném qubitu
  \[
    z_i = \langle Z_0 \rangle_i \in [-1,1],
  \]
  která je následně interpretována jako skóre pneumonie po lineárním přemapování
  na interval $[0,1]$ až ve fázi vyhodnocení. Aby bylo možné přímo optimalizovat
  kvantové parametry na výstupu v intervalu $[-1,1]$, jsou binární labely
  $y_i \in \{0,1\}$ nejprve převedeny na cílové hodnoty
  \[
    t_i =
    \begin{cases}
      -1, & y_i = 0 \;(\text{Normal}), \\
      +1, & y_i = 1 \;(\text{Pneumonia}),
    \end{cases}
  \]
  a používá se vážená střední kvadratická chyba
  \[
    L_{\mathrm{QMSE}} = \frac{1}{N} \sum_{i=1}^{N} w(t_i)\,\bigl(z_i - t_i\bigr)^2.
  \]
  Váhy $w(t_i)$ jsou odvozeny z poměru tříd v trénovací sadě tak, aby byly chyby
  na minoritní třídě \emph{Normal} penalizovány výrazněji a kompenzovala se
  výrazná nevyváženost dat (přibližně $74{,}2\,\%$ snímků s pneumonií). Tato volba
  MSE (namísto například BCE) je motivována plynulými gradienty v prostoru
  parametrů ansatzu a dobrou podporou v autograd backendu knihovny PennyLane.

  \item \textbf{Klasický baseline: vážená Binary Cross-Entropy (BCE)}

  Čistě klasický baseline model nad 64rozměrnými příznaky z PCA vrací pro každý
  vzorek pravděpodobnost pneumonie $\hat{p}_i \in [0,1]$ pomocí sigmoidové
  výstupní neurony. Pro trénink je použita vážená binární cross–entropie
  \[
    L_{\mathrm{WBCE}} = -\frac{1}{N} \sum_{i=1}^{N}
      w(y_i)\,\bigl[
        y_i \log(\hat{p}_i) +
        (1-y_i)\,\log(1-\hat{p}_i)
      \bigr],
  \]
  kde funkce $w(y_i)$ nastavuje vyšší váhu vzorkům třídy \emph{Normal}, aby se
  zmírnil vliv nevyváženosti a model nebyl příliš „přesvědčen“ o přítomnosti
  pneumonie. V implementaci je použito jednoduché schéma vah $w(0) > w(1)$,
  což vede ke snížení počtu falešně negativních případů pneumonie při zachování
  rozumné specificity.
\end{itemize}

Na rozdíl od původního návrhu není v této práci minimalizována jediná sdílená
kombinovaná ztráta $L = \alpha L_{\mathrm{QMSE}} + (1-\alpha)L_{\mathrm{WBCE}}$,
ale kvantový a klasický model jsou optimalizovány odděleně se svými vlastními
chybovými funkcemi a hyperparametry.

\paragraph{Optimalizační hyperparametry a plány učení}

V obou tréninkových scénářích je použit společný základní soubor
hyperparametrů:
\begin{itemize}
  \item počet epoch $E = 50$ (s early stoppingem na validační ztrátě),
  \item velikost batch size $B = 16$,
  \item počáteční learning rate $\eta_0 = 10^{-3}$,
  \item trpělivost early stoppingu \texttt{patience} $= 10$ epoch.
\end{itemize}

Pro kvantový klasifikátor VQC je nad Adam optimalizátorem použit hladký
cosinusový plán učení se zahřátím (warm-up). Konkrétně je learning rate v
epoše $e$ určena schématem
\[
  \eta(e) =
  \begin{cases}
    \eta_0 \,\dfrac{e}{E_{\mathrm{warmup}}}, & e \leq E_{\mathrm{warmup}}, \\[0.5em]
    \eta_{\min} + \dfrac{1}{2}\,(\eta_0 - \eta_{\min})
      \left[1 + \cos\!\left(\pi\,\dfrac{e - E_{\mathrm{warmup}}}{E - E_{\mathrm{warmup}}}\right)\right],
      & e > E_{\mathrm{warmup}},
  \end{cases}
\]
kde $E_{\mathrm{warmup}} = 3$ a minimální learning rate je $\eta_{\min} = 10^{-5}$.
Tento plán zajišťuje pozvolný náběh gradientů v úvodních epochách a následné
plynulé snižování krokové velikosti směrem k minimu.

Klasický baseline model používá rovněž Adam s počátečním learning rate
$\eta_0 = 10^{-3}$, avšak s vestavěným plánem
\texttt{CosineAnnealingLR} z knihovny PyTorch, který realizuje cosinusový
průběh bez explicitní warm-up fáze. V obou případech je trénink ukončen buď
po dosažení maximálního počtu epoch, nebo dříve, pokud se validační ztráta
nezlepší po dobu danou parametrem \texttt{patience}.

\section{Softwarové prostředí a knihovny}

Veškeré experimenty byly realizovány v prostředí Jupyter notebooku na platformě Google Colab s Linuxovým operačním systémem a podporou GPU akcelerace přes CUDA 12.6. Jako programovací jazyk byl použit Python ve verzi 3.12.x, přičemž klíčové vědecké a kvantové knihovny byly instalovány pomocí \texttt{pip} na začátku notebooku.

Základ softwarového stacku tvořily následující balíčky (uvedeny jsou pouze hlavní komponenty relevantní pro implementaci modelu):

\begin{itemize}
    \item \textbf{PennyLane} 0.43.2 (\texttt{pennylane}, \texttt{pennylane-lightning-gpu}) pro definici a simulaci variačního kvantového obvodu a integraci s klasickým Python ekosystémem.
    \item \textbf{PyTorch} 2.9.0+cu126 a \textbf{torchvision} 0.24.0+cu126 pro implementaci extraktoru příznaků ResNet-50, klasického baseline klasifikátoru a tréninkové smyčky na GPU.
    \item \textbf{scikit-learn} 1.6.1 pro redukci dimenze (PCA), škálování dat a konstrukci zpracovatelské pipeline.
    \item \textbf{NumPy} 2.0.2 a \textbf{SciPy} 1.16.3 pro práci s maticemi, numerické výpočty a pomocné utility.
    \item \textbf{pandas} 2.2.2 pro správu metadat a strukturovanou práci s datovými rámci.
    \item \textbf{matplotlib} 3.10.0 a \textbf{seaborn} 0.13.2 pro vizualizaci tréninkových křivek a vyhodnocovacích metrik.
    \item \textbf{scikit-image} 0.25.2 a \textbf{opencv-python} 4.12.0.88 pro práci s obrazovými daty a pomocné transformace snímků.
    \item \textbf{kagglehub} 0.3.13 pro stažení veřejně dostupného datasetu Chest X-Ray Pneumonia z platformy Kaggle.
\end{itemize}

Kvantové obvody byly v této práci simulovány na ideálním backendu \texttt{lightning.gpu} frameworku PennyLane, tj. bez explicitního modelování šumu a dekoherence reálného kvantového hardwaru. Nastavení náhodného semene (\texttt{seed = 6}) bylo sjednoceno pro NumPy i PyTorch, aby byla zajištěna reprodukovatelnost všech experimentů v rámci daného softwarového prostředí.

\subsubsection{Hardwarové prostředí}

Všechny experimenty byly realizovány v prostředí Google Colab s Linuxovým operačním systémem a GPU akcelerací přes CUDA 12.6. Výpočty klasické části (extrakce příznaků ResNet-50, PCA a trénink baseline klasifikátoru) i simulace kvantového obvodu probíhaly na následujících typech GPU:

\begin{itemize}
    \item \textbf{NVIDIA T4} (16\,GB VRAM) -- použita pro extrakci příznaků pomocí ResNet-50 a menší ladicí experimenty hybridního modelu.
    \item \textbf{NVIDIA A100} (40\,GB VRAM) -- použita pro plné trénování hybridního modelu a kvantového klasifikátoru při vyšší batch size a delších bězích.
\end{itemize}

Kvantová část modelu byla simulována pomocí backendu \texttt{lightning.gpu} z knihovny PennyLane, který využívá CUDA a knihovnu NVIDIA cuQuantum pro akceleraci výpočtu variačních kvantových obvodů na GPU. V rámci této práce nebyl použit žádný reálný kvantový procesor; všechny kvantové výpočty probíhaly na klasickém hardwaru formou simulace.

\chapter{Výsledky} \label{chap:vysledky}

V této kapitole jsou prezentovány dosažené výsledky experimentů zaměřených na detekci pneumonie pomocí navrženého hybridního kvantově-klasického modelu. Výkonnost modelu je kvantitativně vyhodnocena pomocí standardních metrik a porovnána s referenčním klasickým modelem. Analýza zahrnuje také detekci dataset shiftu a robustnost vůči různým trénovacím podmínkám.

\section{Průběh trénování sítě}
Trénování hybridního modelu probíhalo po dobu 50 epoch bez aktivování early stoppingu (validační ztráta 0.6796). Na Obrázku \ref{fig:learning_curve} je znázorněn vývoj chybové funkce a přesnosti.

\begin{figure}[h]
   \centering
   \includegraphics[width=1.0\textwidth]{../media/loss_graph.png} 
   \caption{Vývoj chybové funkce (MSE) a přesnosti hybridního modelu. Konvergence dosažena po 50 epochách (trénovací čas: 8145s / 135min).}
   \label{fig:learning_curve}
\end{figure}

\section{Kvantitativní vyhodnocení na testovací sadě}
Testovací sada obsahovala 624 snímků (390 pneumonie, 234 normální; 62.5\% pneumonie). Výsledky byly vyhodnoceny standardními metriky včetně AUC-ROC a vyvážené přesnosti.

\begin{table}[h]
    \centering
    \caption{Srovnání výkonnosti klasického modelu ResNet-50 a navrženého hybridního modelu}
    \label{tab:vysledky}
    \small
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Metrika} & \textbf{Klasický} & \textbf{Hybridní} & \textbf{Rozdíl} & \textbf{95\% CI} \\
        \hline
        Accuracy & 85.90\% & 71.63\% & -14.27\% & [67.2\%, 75.9\%] \\
        Precision & 83.41\% & 75.91\% & -7.50\% & [71.8\%, 79.7\%] \\
        Recall (Senzitivita) & 97.95\% & 80.00\% & -17.95\% & [75.5\%, 84.0\%] \\
        Specificity & 70.51\% & 57.69\% & -12.82\% & [51.2\%, 64.0\%] \\
        F1-Score & 0.9022 & 0.6915 & -0.2107 & [0.65, 0.73] \\
        AUC-ROC & 0.912 & 0.7445 & -0.1675 & [0.71, 0.78] \\
        Balanced Accuracy & 0.8423 & 0.6885 & -0.1538 & - \\
        \hline
        \textbf{Parametry (klasifikátor)} & 164\,865 & \textbf{108} & \textbf{1527× méně} & - \\
        \textbf{Trénovací čas} & 9s & 135 min &  & - \\
        \hline
    \end{tabular}
\end{table}

Z Tabulky \ref{tab:vysledky} je patrné, že čistě klasický model ResNet-50 dosahuje na testovací sadě vyšší výkonnosti ve všech standardních metrikách. Klasifikátor založený na plně propojených vrstvách dokáže lépe využít bohatou reprezentaci o vysoké dimenzi a dosahuje tak přesnosti 85{,}9\,\% a F1-skóre 0{,}90, což odpovídá hodnotám popisovaným v literatuře pro hluboké konvoluční sítě na datasetu Chest X-Ray Pneumonia.\cite{pneumonia_deep_learning_review} Naproti tomu hybridní model s kvantovým klasifikátorem dosahuje přesnosti 71{,}63\,\% a F1-skóre 0{,}69, což ukazuje, že v současné konfiguraci nedokáže plně konkurovat dobře optimalizovanému klasickému přístupu z hlediska čisté predikční kvality.\cite{pneumonia_detection_qml} 

Je však důležité zdůraznit odlišný cíl obou architektur. Klasický ResNet-50 využívá masivní množství parametrů v klasifikační části (řádově stovky tisíc vah), zatímco navržený variační kvantový obvod se omezuje na 108 trénovatelných parametrů.\cite{schuld_book} Hybridní model tak dosahuje rozumné úrovně výkonnosti při \emph{dramaticky menší parametrizaci}, což je klíčové v kontextu NISQ éry, kde je počet qubitů i hloubka obvodů zásadně omezená.\cite{mitarai_qcl} V praxi to znamená, že rozhodovací část modelu je výrazně kompaktnější a potenciálně lépe škálovatelná na budoucí kvantový hardware. 

Rozdíly mezi klasickým a hybridním přístupem jsou patrné i v hodnotách AUC-ROC. Zatímco klasický model dosahuje AUC okolo 0{,}91, hybridní model se pohybuje na hodnotě 0{,}74, což stále představuje smysluplnou diskriminační schopnost mezi třídami při podstatně menším počtu parametrů.\cite{radiology_viral_vs_bacterial} Intervaly spolehlivosti naznačují, že rozdíl v přesnosti i AUC je statisticky významný, tj. nelze jej připsat pouze náhodné variabilitě dané konečnou velikostí testovací sady.\cite{radiologist_error_rate}
\textbf{Klíčový nález:} I přes nižší přesnost dosáhl hybridní model \textbf{1527× menšího počtu parametrů} v klasifikační vrstvě (108 vs 164k), což je klíčové pro NISQ éru.

\section{Analýza matice záměn a klinická relevance}
Detailní rozbor chyb odhaluje medicinsky významné vzorce:

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{../media/results_graph.png} 
    \caption{Matice záměn a ROC křivka (AUC=0.7445).}
    \label{fig:confusion_matrix}
\end{figure}

Z matice záměn na Obrázku \ref{fig:confusion_matrix} je patrné, že hybridní model vykazuje relativně vysokou senzitivitu 80\,\%, tedy většinu snímků s pneumonií klasifikuje správně jako patologické.\cite{chest_xray_diagnosis} V klinické praxi je tento parametr klíčový, protože falešně negativní nálezy (FN) představují případy, kdy je pneumonie přehlédnuta a pacient není včas léčen. V tomto experimentu model chybně označil 78 ze 390 případů pneumonie jako normální, což je z hlediska bezpečnosti stále nezanedbatelné číslo. 

Naopak specifita 57{,}69\,\% ukazuje, že model má tendenci generovat vyšší počet falešně pozitivních nálezů (FP), tedy označuje část zdravých snímků jako podezřelé na pneumonii.\cite{radiologist_error_rate} Z metrického pohledu to snižuje přesnost a zvyšuje zátěž pro následné ověřovací vyšetření, nicméně z klinického hlediska je tento typ chyby obecně přijatelnější než falešně negativní nálezy. Hybridní model se tak nachází v režimu spíše „opatrného skríningového nástroje“, který upřednostňuje zachycení většiny patologických případů i za cenu vyššího počtu falešných poplachů. 

Tvar ROC křivky na Obrázku \ref{fig:confusion_matrix} potvrzuje, že změnou rozhodovacího prahu lze poměr mezi senzitivitu a specifitou dále dolaďovat.\cite{data_encoding_review} V práci byl pro finální vyhodnocení zvolen práh 0{,}5, který maximalizuje vyváženou přesnost, nicméně v reálném klinickém nasazení by bylo možné preferovat ještě vyšší senzitivitu na úkor specifity například v kontextu preventivního skríningu v období epidemií.


\section{Detekce Dataset Shiftu}
Testovací sada vykazuje \textbf{výrazný dataset shift} oproti trénovací:

\begin{table}[h]
    \centering
    \caption{Dataset Shift Analýza - Poměr tříd}
    \label{tab:dataset_shift}
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{Sada} & \textbf{Pneumonie (\%)} & \textbf{Normální (\%)} & \textbf{Shift} \\
        \hline
        Trénovací (4185) & 74.2\% & 25.8\% & - \\
        Validační (1047) & 74.2\% & 25.8\% & 0\% (stratifikováno) \\
        Testovací (624) & \textbf{62.5\%} & \textbf{37.5\%} & \textbf{-11.7\%} \\
        \hline
    \end{tabular}
\end{table}

Pozorovaný dataset shift má přímý dopad na interpretaci výsledků. Model byl trénován na výrazně nevyvážených datech, kde třída pneumonie jasně dominuje, zatímco testovací sada je podstatně vyrovnanější.\cite{chest_xray_diagnosis} Model se tak během učení naučil implicitní prioritu „pneumonie je pravděpodobnější než normální nález“, což mu na trénovacích a validačních datech pomáhá, ale na testovacích datech vede k vyššímu počtu falešně pozitivních predikcí. Tento efekt se odráží v nižší specifitě a celkové přesnosti ve srovnání s klasickým baseline modelem. 

V literatuře je dobře zdokumentováno, že doménový posun (domain shift) mezi trénovací a testovací distribucí patří mezi hlavní zdroje selhání modelů počítačového vidění v medicíně.\cite{domain_shift_chestxray} Rozdíly mohou vznikat nejen v zastoupení tříd, ale i v typu přístroje, nastavení expozice, věkové struktuře pacientů nebo přítomnosti artefaktů. V této práci byl dataset shift záměrně pouze kvantifikován a diskutován, nikoli aktivně řešen specializovanými technikami (např. reweighting vzorků, doménová adaptace), což je jeden z přirozených směrů navazujícího výzkumu.

Z těchto výsledků vyplývá, že model byl trénován na silně nevyvážených datech (74.2\% pneumonie), ale testován na vyváženějších (62.5\%). Přesto dosáhl 71.63\% accuracy, což demonstruje robustnost.

\section{Závěrečné poznámky k výsledkům}
Celkově lze konstatovat, že navržený hybridní model nepotvrdil původní hypotézu o dosažení srovnatelné klasifikační přesnosti s klasickým ResNet-50, a to zejména kvůli omezené expresivitě variačního kvantového obvodu a přísně omezenému počtu parametrů.\cite{barren_plateaus} Přesto však výsledky jasně ukazují, že i relativně mělký kvantový ansatz dokáže zpracovat vysoce komprimovanou reprezentaci medicínských obrazových dat a dosáhnout rozumné úrovně klasifikační výkonnosti. Z hlediska výzkumu v oblasti QML je tento výsledek cenný, neboť ukazuje praktické limity současných NISQ zařízení a potvrzuje, že bez další optimalizace architektury a hyperparametrů je kvantová výhoda v této úloze spíše nepravděpodobná. 

\chapter{Diskuse} \label{chap:diskuse}

V této kapitole jsou diskutovány dosažené výsledky hybridního kvantově–klasického modelu v kontextu původně stanovených cílů práce a současného stavu poznání v oblasti kvantového strojového učení. Zvláštní pozornost je věnována omezením studie, interpretaci zjištěných rozdílů mezi klasickým a hybridním přístupem a možným směrům dalšího výzkumu.

\section{Hlavní zjištění}

Experimenty ukázaly, že čistě klasický model založený na architektuře ResNet-50 dosahuje na testovací sadě vyšší přesnosti, F1-skóre i AUC-ROC než navržený hybridní model využívající kvantový variační obvod jako klasifikátor (viz Kapitola~\ref{chap:vysledky}). Z pohledu prosté klasifikační výkonnosti se tak původní hypotéza o dosažení srovnatelných výsledků s klasickým modelem v plné míře nepotvrdila. Hybridní model však dosahuje těchto výsledků při dramaticky nižším počtu trénovatelných parametrů v rozhodovací vrstvě – zhruba třítisíckrát méně než u klasického klasifikátoru. To naznačuje, že variační kvantové obvody mohou v budoucnu sloužit jako parametricky úsporná alternativa k masivním plně propojeným vrstvám, zejména na hardwaru s omezenou pamětí a počtem qubitů.

Dalším významným zjištěním je to, že hybridní model i přes nižší celkovou přesnost vykazuje relativně vysokou senzitivitu (80\,\%) vůči třídě pneumonie, tedy většinu patologických případů klasifikuje správně. Zároveň ale trpí nižší specifitou a vyšším počtem falešně pozitivních nálezů, což odráží kombinaci nevyváženého trénovacího rozdělení a zvoleného rozhodovacího prahu. V klinickém kontextu lze tento profil chování interpretovat jako „opatrný“ model vhodný spíše pro skríning, který raději generuje více falešných poplachů, než aby přehlížel velké množství skutečných případů pneumonie.

\section{Omezení studie} \label{sec:omezeni}

\subsection{Výpočetní zdroje a simulace kvantového obvodu}

Jedním z nejdůležitějších omezení této práce jsou dostupné výpočetní zdroje. Kvantová část modelu byla realizována na klasickém simulátoru s~6~qubity, přičemž trénink 50 epoch hybridního modelu trval přibližně 135 minut. To výrazně omezilo možnost prohledat větší prostor architektur a hyperparametrů. Každá změna počtu vrstev, qubitů nebo struktury propletení by znamenala desítky až stovky minut dodatečného trénování, což je v rámci středoškolského projektu jen obtížně realizovatelné.

Simulace kvantových obvodů navíc škáluje přibližně exponenciálně s počtem qubitů, takže prakticky nelze zkoumat architektury s desítkami qubitů, které by mohly být z hlediska expresivity zajímavé. Práce se proto soustředila na relativně mělký ansatz s omezeným počtem parametrů a pevným entanglingovým schématem, což je rozumný kompromis mezi teoretickou expresivitou a praktickou trénovatelností, ale zároveň to představuje zásadní limit zkoumaného prostoru modelů.

Dalším důsledkem omezených zdrojů je také to, že nebyla realizována křížová validace ani rozsáhlý experimentální protokol s opakovaným náhodným dělením dat. Výsledky proto zachycují chování modelu pro jedno konkrétní rozdělení trénovací, validační a testovací množiny a je třeba je interpretovat s vědomím této skutečnosti.

\subsection{Datová omezení a doménový posun}

Studie je založena na jednom veřejně dostupném datasetu rentgenových snímků hrudníku pediatrických pacientů, pocházejícím z jediné nemocnice. Taková data mají omezenou diverzitu, pokud jde o věk pacientů, typy přístrojů, expoziční protokoly a spektrum patologií. Model proto není možné bez dalšího tvrdit jako obecně platný pro dospělou populaci, jiné nemocnice nebo jiné modality zobrazení. Přenositelnost modelu mimo původní datovou doménu zůstává otevřenou otázkou.

Navíc se ukázalo, že testovací sada má odlišné rozdělení tříd než trénovací a validační sada – podíl pneumonií klesl zhruba ze 74{,}2\,\% na 62{,}5\,\%. Tento dataset shift pravděpodobně přispěl ke zhoršení specifity a celkové přesnosti na testovací sadě, protože model se během učení „naučil“ implicitní prioritu, že pneumonie jsou častější, než jak tomu bylo v testovacích datech. V práci byla tato skutečnost kvantifikována a diskutována, ale nebyly nasazeny pokročilejší metody doménové adaptace ani reweightingu vzorků, které by mohly dopad posunu zmírnit.

Kromě změny poměru tříd je třeba zmínit i další možné zdroje doménového posunu, které nebyly systematicky analyzovány – například rozdíly v kvalitě snímků, přítomnost lékařských zařízení v obraze nebo odlišné poziční nastavení pacienta. Tyto faktory mohou mít významný vliv na generalizaci modelu v reálném klinickém prostředí.

\subsection{Omezení architektury a trénovacího postupu}

Navržený hybridní model používá amplitudové kódování 64dimenzionálního vektoru příznaků do stavu šesti qubitů. Tato volba je motivována efektivitou reprezentace, protože umožňuje zakódovat $2^6 = 64$ amplitud do relativně malého počtu qubitů, ale zároveň znamená výraznou redukci původního 2048-dimenzionálního výstupu ResNetu. Je pravděpodobné, že část informace relevantní pro diagnostiku pneumonie byla v tomto kroku nenávratně ztracena, což snižuje strop dosažitelné výkonnosti kvantového klasifikátoru.

Ansatz kvantového obvodu byl navržen tak, aby byl relativně mělký a s lineárním propojením qubitů, což pomáhá zmírňovat problém tzv. barren plateaus, ale zároveň omezuje expresivitu modelu. Teoretické práce naznačují, že hlubší a složitěji propletené obvody mohou dosahovat lepší aproximační schopnosti, ale za cenu rychlejšího miznutí gradientů a zvýšené citlivosti na šum. V této práci byl upřednostněn konzervativní návrh, který zůstává v oblasti prakticky trénovatelných obvodů, a proto nelze vyloučit, že bohatší ansatz by mohl při vhodné regularizaci a inicializaci dosáhnout lepších výsledků.

V neposlední řadě je třeba zmínit, že kvantová část byla trénována na ideálním simulátoru bez explicitního modelování fyzikálního šumu, dekoherence a chyb měření. Skutečný provoz na reálném NISQ hardwaru by pravděpodobně vedl k dalšímu zhoršení metrik, pokud by nebyly nasazeny pokročilé techniky mitigace šumu.

\section{Možné směry dalšího výzkumu} \label{sec:future_work}

\subsection{Experimenty na reálném kvantovém hardwaru}

Přirozeným pokračováním této práce je přenesení navrženého variačního obvodu na reálný kvantový procesor, například v rámci cloudových platforem typu IBM Quantum nebo IonQ. Vzhledem k omezenému počtu qubitů a jejich konečné koherenční době by bylo nutné dále zkrátit hloubku obvodu a pracovat s menšími batch size, případně využít jen podmnožinu trénovacích dat. Součástí takového experimentu by muselo být i nasazení technik mitigace šumu, jako je kalibrace chyb čtení, zero-noise extrapolation nebo jednoduché formy chybové mitigace na úrovni měření.

Takový experiment by umožnil kvantifikovat rozdíl mezi ideálním simulátorem a reálným hardwarem a poskytnout realističtější obrázek o použitelnosti QML v současné NISQ éře. Zároveň by otevřel prostor pro ladění ansatzu s ohledem na konkrétní topologii a omezení daného kvantového čipu.

\subsection{Návrh alternativních kvantových architektur}

Dalším směrem je systematické zkoumání alternativních kvantových architektur. Místo VQC v roli čistého klasifikátoru by bylo možné testovat tzv. kvantové konvoluční vrstvy (quanvolutional neural networks), které předzpracovávají obrazová data ještě před klasickou CNN, nebo kvantové kernelové metody, kde kvantový procesor slouží pouze k výpočtu jádrové matice pro následný klasický SVM klasifikátor. Tyto přístupy se v recentní literatuře ukazují jako slibné právě v kontextu medicínských obrazů.

Zajímavou možností je i ensemble přístup, ve kterém by výstupy klasického ResNet-50 a hybridního kvantového modelu byly kombinovány, například váženým průměrem logitů nebo druhostupňovým metaklasifikátorem. Tím by bylo možné využít odlišné typy chyb obou modelů a potenciálně zlepšit jak senzitivitu, tak specifitu na testovací sadě.

\subsection{Pokročilá optimalizace hyperparametrů a validace}

V této práci byly hyperparametry (learning rate, velikost batch, hloubka obvodu, počet vybraných příznaků) laděny kombinací předběžných experimentů a omezeného grid search. V budoucnu by bylo vhodné nasadit pokročilejší metody, jako je Bayesovská optimalizace (např. pomocí knihovny Optuna), které dokážou efektivněji prohledávat prostor hyperparametrů i při omezeném počtu trénovacích běhů. U hybridních modelů by bylo možné současně optimalizovat jak klasické, tak kvantové hyperparametry se společnou cílovou funkcí zahrnující například přesnost, AUC i počet parametrů.

Součástí robustnějšího validačního protokolu by měla být také křížová validace nebo opakovaná randomizace trénovací a validační sady, aby bylo možné lépe odhadnout variabilitu výsledků. Užitečné by bylo i systematické vykreslení validačních křivek pro klíčové hyperparametry (velikost batch, hloubka ansatzu, počet vstupních příznaků) s cílem odhalit oblasti pod- a pře-učení modelu.

\subsection{Rozšíření dat a doménová adaptace}

Z hlediska dat je nejpřirozenějším pokračováním rozšíření trénovacího i testovacího souboru o snímky z dalších nemocnic, věkových skupin a přístrojů. Takový multi-institucionální dataset by umožnil lépe zhodnotit generalizační schopnosti hybridního modelu a ověřit, zda se jeho chování zásadně nemění mimo původní doménu pediatrických pacientů.

Paralelně s tím by bylo vhodné experimentovat s metodami doménové adaptace, které jsou v oblasti medicínského hlubokého učení intenzivně zkoumány – například reweighting vzorků, adversariální doménová adaptace nebo stylový transfer mezi různými datovými distribucemi. Tyto techniky by mohly zmírnit negativní dopad dataset shiftu, který byl v této práci identifikován, ale zatím pouze kvantitativně popsán.

\subsection{Interpretovatelnost a klinická integrace}

Pro reálné klinické nasazení je zásadní nejen samotná přesnost modelu, ale také jeho interpretovatelnost. Na straně klasické části by bylo vhodné doplnit vizualizace typu Grad-CAM, které ukazují, na které oblasti snímku se ResNet při klasifikaci zaměřuje, a ověřit, zda tyto oblasti odpovídají typickým radiologickým znakům pneumonie.

Na straně kvantového klasifikátoru je interpretovatelnost složitější, ale i zde lze zkoumat například význam jednotlivých příznaků vybraných metodou SelectKBest, citlivost výstupu na perturbace vstupních amplitud nebo chování modelu v nízkodimenzionálních projekcích prostoru příznaků. Tyto analýzy by mohly pomoci lépe pochopit, jaký druh informací kvantová vrstva skutečně využívá a zda přináší odlišný pohled na data než klasický klasifikátor.


\chapter{Závěr} \label{chap:zaver}

Cílem této práce bylo navrhnout, implementovat a experimentálně ověřit hybridní kvantově–klasický model pro detekci pneumonie z rentgenových snímků hrudníku v podmínkách současné NISQ éry a porovnat jeho výkon s referenčním čistě klasickým modelem založeným na architektuře ResNet-50. Součástí cíle byla také analýza vhodných metod redukce dimenzionality, kódování klasických dat do kvantových stavů a návrh variačního kvantového obvodu, který je reálně trénovatelný na omezeném počtu qubitů. 

Z metodického hlediska se podařilo vytvořit plně funkční experimentální pipeline, která zahrnuje předzpracování obrazových dat, extrakci příznaků pomocí předtrénované sítě ResNet-50, jejich redukci na rozměr vhodný pro amplitudové kódování a následnou klasifikaci pomocí variačního kvantového obvodu realizovaného v knihovně PennyLane. Během práce bylo nutné upravit původní rozdělení datasetu, neboť validační množina obsahovala pouze 16 snímků; novým stratifikovaným dělením v poměru 80:20 mezi trénovací a validační sadou se podařilo získat robustnější odhad generalizační chyby, aniž by byla narušena integrita testovací množiny.

Experimentální výsledky ukázaly, že klasický model ResNet-50 dosahuje na testovací sadě vyšší přesnosti, F1-skóre i AUC-ROC než navržený hybridní model. Původní hypotéza o dosažení srovnatelné výkonnosti hybridního přístupu v této konkrétní úloze se tak v plné míře nepotvrdila, zejména kvůli omezené expresivitě kvantového ansatzu, redukci vstupního vektoru příznaků a přítomnému dataset shiftu mezi trénovací a testovací množinou. Na druhou stranu hybridní model prokázal, že i relativně mělký variační obvod se 6 qubity a 108 trénovatelnými parametry dokáže dosáhnout smysluplné diskriminační schopnosti (AUC-ROC okolo 0{,}74) v reálné medicínské klasifikační úloze.

Z hlediska praktických přínosů práce lze za nejdůležitější považovat tři oblasti. Zaprvé, práce demonstruje kompletní návrh a implementaci hybridní kvantově–klasické architektury na skutečných biomedicínských datech a může tak sloužit jako referenční příklad pro další studenty a výzkumníky v oblasti QML. Zadruhé, systematická analýza omezení – včetně vlivu nevyvážených dat, doménového posunu, volby ansatzu a výpočetních nároků simulace – poskytuje realistický pohled na to, kde se dnes nachází praktická použitelnost kvantového strojového učení v medicíně. Zatřetí, práce otevírá konkrétní cesty pro další výzkum, jako je nasazení na reálný kvantový hardware, využití pokročilých metod mitigace šumu, automatizovaná optimalizace hyperparametrů či zkoumání alternativních kvantových architektur a ensemble přístupů.

Celkově lze říci, že i když hybridní model v této studii nedosáhl lepší klasifikační výkonnosti než pečlivě nastavený klasický ResNet-50, splnil svůj hlavní účel jako experimentální platforma pro zkoumání možností a limitů hybridních kvantově–klasických neuronových sítí v éře NISQ. Výsledky potvrzují, že kvantová výhoda v takto náročné obrazové úloze není za současného stavu hardwaru a při omezeném počtu qubitů samozřejmostí, ale zároveň ukazují, že kvantové obvody mohou hrát roli parametricky úsporných klasifikátorů a inspirují další práci na návrhu architektur, které budou lépe využívat specifické silné stránky kvantových procesorů. V tomto smyslu představuje práce příspěvek k probíhající diskusi o reálné využitelnosti kvantového strojového učení v medicínské diagnostice a vytváří pevný základ pro budoucí experimenty i prohloubení spolupráce mezi oblastí kvantových technologií a klinickou praxí.

% ================= LITERATURA [cite: 151-190] =================
\printbibliography[title={Seznam použité literatury}, heading=bibintoc]

% ================= SEZNAM ZKRATEK [cite: 191-197] =================
\chapter*{Seznam použitých zkratek}
\addcontentsline{toc}{chapter}{Seznam použitých zkratek}

\begin{description}
  \item[AI] Artificial Intelligence – umělá inteligence
  \item[ANOVA] Analysis of Variance – analýza rozptylu
  \item[AUC] Area Under the ROC Curve – plocha pod ROC křivkou
  \item[BCE] Binary Cross-Entropy – binární křížová entropie
  \item[CAM] Class Activation Map – mapa třídní aktivace (např. Grad-CAM)
  \item[CNN] Convolutional Neural Network – konvoluční neuronová síť
  \item[CNOT] Controlled-NOT – řízené NOT kvantové hradlo
  \item[CT] Computed Tomography – výpočetní tomografie
  \item[CUDA] Compute Unified Device Architecture – paralelní výpočetní platforma NVIDIA
  \item[CXR] Chest X-Ray – skiagram hrudníku
  \item[FN] False Negative – falešně negativní nález
  \item[FP] False Positive – falešně pozitivní nález
  \item[IBM] International Business Machines – poskytovatel kvantových počítačů IBM Quantum
  \item[ILSVRC] ImageNet Large Scale Visual Recognition Challenge – soutěž v klasifikaci obrazů
  \item[LDA] Linear Discriminant Analysis – lineární diskriminační analýza
  \item[LR] Learning Rate – rychlost učení
  \item[MLP] Multi-Layer Perceptron – vícevrstvý perceptron
  \item[MSE] Mean Squared Error – střední kvadratická chyba
  \item[NISQ] Noisy Intermediate-Scale Quantum – éra šumových kvantových procesorů střední velikosti
  \item[NTC] Nové technologie – výzkumné centrum ZČU v Plzni
  \item[PCA] Principal Component Analysis – analýza hlavních komponent
  \item[QML] Quantum Machine Learning – kvantové strojové učení
  \item[QMSE] Quantum Mean Squared Error – MSE používaná pro kvantový klasifikátor
  \item[ROC] Receiver Operating Characteristic – ROC křivka
  \item[RSV] Respiratory Syncytial Virus – respirační syncytiální virus
  \item[RTG] Rentgenový snímek – skiagram
  \item[SARS] Severe Acute Respiratory Syndrome – těžký akutní respirační syndrom (v textu SARS-CoV-2)
  \item[SVM] Support Vector Machine – metoda podpůrných vektorů
  \item[VQA] Variational Quantum Algorithm – variační kvantový algoritmus
  \item[VQC] Variational Quantum Circuit – variační kvantový obvod
  \item[VRAM] Video Random Access Memory – grafická paměť
  \item[WBCE] Weighted Binary Cross-Entropy – vážená binární křížová entropie
  \item[WHO] World Health Organization – Světová zdravotnická organizace
\end{description}

\end{document}